{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pylab as plt\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TimeDistributed, Conv2D, Conv2DTranspose, MaxPooling2D, AveragePooling2D, BatchNormalization, concatenate, Input, ConvLSTM2D, Reshape, Conv3D, Flatten, LSTM, GRU, Dense,Dropout, Add\n",
    "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Bidirectional, Conv1D, MaxPooling1D, GlobalMaxPooling1D, GlobalMaxPool1D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import re \n",
    "\n",
    "import nltk # for stopwords \n",
    "from nltk.corpus import stopwords\n",
    "import gensim # for Word2Vec embeddings \n",
    "from gensim.models import KeyedVectors\n",
    "from sentencepiece import SentencePieceTrainer,SentencePieceProcessor\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bs4 import BeautifulSoup\n",
    "import googletrans \n",
    "from googletrans import Translator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./storage/writer/train.csv') \n",
    "test = pd.read_csv('./storage/writer/test_x.csv') \n",
    "ss = pd.read_csv('./storage/writer/sample_submission.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train['text'] \n",
    "y_train = train['author'] \n",
    "x_test = test['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.asarray(x_train) \n",
    "y_train = np.asarray(y_train) \n",
    "x_test = np.asarray(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54879,), (54879,), (19617,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54879,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "back_translated = np.load('./storage/sample_back_translate.npy') \n",
    "\n",
    "back_translated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(): \n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=maxlength),\n",
    "        tf.keras.layers.GlobalAveragePooling1D(),\n",
    "        tf.keras.layers.Dense(5, activation='softmax')\n",
    "    ])\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Iteration 1 ...\n",
      "... Preprocessing Data ... \n",
      "(98782, 256) (98782,)\n",
      "(5488, 256) (5488,)\n",
      "... Training Model by Validating on Fold 1 ...\n",
      "Train on 98782 samples, validate on 5488 samples\n",
      "Epoch 1/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 1.5617 - accuracy: 0.2751\n",
      "Epoch 00001: val_loss improved from inf to 1.53766, saving model to ./storage/writer_train_10/kfold1/epoch_001_val_1.538.h5\n",
      "98782/98782 [==============================] - 5s 55us/sample - loss: 1.5616 - accuracy: 0.2751 - val_loss: 1.5377 - val_accuracy: 0.2823\n",
      "Epoch 2/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 1.5113 - accuracy: 0.3374\n",
      "Epoch 00002: val_loss improved from 1.53766 to 1.46865, saving model to ./storage/writer_train_10/kfold1/epoch_002_val_1.469.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 1.5110 - accuracy: 0.3381 - val_loss: 1.4686 - val_accuracy: 0.4091\n",
      "Epoch 3/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 1.4336 - accuracy: 0.4361\n",
      "Epoch 00003: val_loss improved from 1.46865 to 1.37641, saving model to ./storage/writer_train_10/kfold1/epoch_003_val_1.376.h5\n",
      "98782/98782 [==============================] - 4s 44us/sample - loss: 1.4330 - accuracy: 0.4362 - val_loss: 1.3764 - val_accuracy: 0.4852\n",
      "Epoch 4/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 1.3461 - accuracy: 0.4907\n",
      "Epoch 00004: val_loss improved from 1.37641 to 1.28243, saving model to ./storage/writer_train_10/kfold1/epoch_004_val_1.282.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 1.3460 - accuracy: 0.4907 - val_loss: 1.2824 - val_accuracy: 0.5450\n",
      "Epoch 5/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 1.2630 - accuracy: 0.5329\n",
      "Epoch 00005: val_loss improved from 1.28243 to 1.19476, saving model to ./storage/writer_train_10/kfold1/epoch_005_val_1.195.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 1.2627 - accuracy: 0.5332 - val_loss: 1.1948 - val_accuracy: 0.5705\n",
      "Epoch 6/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 1.1884 - accuracy: 0.5697\n",
      "Epoch 00006: val_loss improved from 1.19476 to 1.11860, saving model to ./storage/writer_train_10/kfold1/epoch_006_val_1.119.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 1.1877 - accuracy: 0.5702 - val_loss: 1.1186 - val_accuracy: 0.5997\n",
      "Epoch 7/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 1.1218 - accuracy: 0.5968\n",
      "Epoch 00007: val_loss improved from 1.11860 to 1.05460, saving model to ./storage/writer_train_10/kfold1/epoch_007_val_1.055.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 1.1217 - accuracy: 0.5968 - val_loss: 1.0546 - val_accuracy: 0.6177\n",
      "Epoch 8/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 1.0649 - accuracy: 0.6180\n",
      "Epoch 00008: val_loss improved from 1.05460 to 1.00027, saving model to ./storage/writer_train_10/kfold1/epoch_008_val_1.000.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 1.0648 - accuracy: 0.6181 - val_loss: 1.0003 - val_accuracy: 0.6474\n",
      "Epoch 9/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 1.0155 - accuracy: 0.6379\n",
      "Epoch 00009: val_loss improved from 1.00027 to 0.95356, saving model to ./storage/writer_train_10/kfold1/epoch_009_val_0.954.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 1.0150 - accuracy: 0.6380 - val_loss: 0.9536 - val_accuracy: 0.6629\n",
      "Epoch 10/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.9711 - accuracy: 0.6553\n",
      "Epoch 00010: val_loss improved from 0.95356 to 0.91517, saving model to ./storage/writer_train_10/kfold1/epoch_010_val_0.915.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.9712 - accuracy: 0.6553 - val_loss: 0.9152 - val_accuracy: 0.6808\n",
      "Epoch 11/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.9324 - accuracy: 0.6700\n",
      "Epoch 00011: val_loss improved from 0.91517 to 0.87982, saving model to ./storage/writer_train_10/kfold1/epoch_011_val_0.880.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.9321 - accuracy: 0.6702 - val_loss: 0.8798 - val_accuracy: 0.6917\n",
      "Epoch 12/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.8969 - accuracy: 0.6827\n",
      "Epoch 00012: val_loss improved from 0.87982 to 0.84880, saving model to ./storage/writer_train_10/kfold1/epoch_012_val_0.849.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.8967 - accuracy: 0.6830 - val_loss: 0.8488 - val_accuracy: 0.7015\n",
      "Epoch 13/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.8645 - accuracy: 0.6965\n",
      "Epoch 00013: val_loss improved from 0.84880 to 0.82156, saving model to ./storage/writer_train_10/kfold1/epoch_013_val_0.822.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.8644 - accuracy: 0.6965 - val_loss: 0.8216 - val_accuracy: 0.7108\n",
      "Epoch 14/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.8354 - accuracy: 0.7086\n",
      "Epoch 00014: val_loss improved from 0.82156 to 0.79865, saving model to ./storage/writer_train_10/kfold1/epoch_014_val_0.799.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.8351 - accuracy: 0.7087 - val_loss: 0.7987 - val_accuracy: 0.7119\n",
      "Epoch 15/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.8081 - accuracy: 0.7184\n",
      "Epoch 00015: val_loss improved from 0.79865 to 0.77539, saving model to ./storage/writer_train_10/kfold1/epoch_015_val_0.775.h5\n",
      "98782/98782 [==============================] - 4s 45us/sample - loss: 0.8083 - accuracy: 0.7183 - val_loss: 0.7754 - val_accuracy: 0.7238\n",
      "Epoch 16/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.7838 - accuracy: 0.7285\n",
      "Epoch 00016: val_loss improved from 0.77539 to 0.75609, saving model to ./storage/writer_train_10/kfold1/epoch_016_val_0.756.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.7836 - accuracy: 0.7286 - val_loss: 0.7561 - val_accuracy: 0.7283\n",
      "Epoch 17/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.7603 - accuracy: 0.7363\n",
      "Epoch 00017: val_loss improved from 0.75609 to 0.73894, saving model to ./storage/writer_train_10/kfold1/epoch_017_val_0.739.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.7603 - accuracy: 0.7364 - val_loss: 0.7389 - val_accuracy: 0.7422\n",
      "Epoch 18/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.7391 - accuracy: 0.7433\n",
      "Epoch 00018: val_loss improved from 0.73894 to 0.72444, saving model to ./storage/writer_train_10/kfold1/epoch_018_val_0.724.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.7392 - accuracy: 0.7433 - val_loss: 0.7244 - val_accuracy: 0.7449\n",
      "Epoch 19/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.7199 - accuracy: 0.7499\n",
      "Epoch 00019: val_loss improved from 0.72444 to 0.70798, saving model to ./storage/writer_train_10/kfold1/epoch_019_val_0.708.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.7195 - accuracy: 0.7502 - val_loss: 0.7080 - val_accuracy: 0.7502\n",
      "Epoch 20/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.7010 - accuracy: 0.7563\n",
      "Epoch 00020: val_loss improved from 0.70798 to 0.69474, saving model to ./storage/writer_train_10/kfold1/epoch_020_val_0.695.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.7010 - accuracy: 0.7563 - val_loss: 0.6947 - val_accuracy: 0.7575\n",
      "Epoch 21/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.6839 - accuracy: 0.7630\n",
      "Epoch 00021: val_loss improved from 0.69474 to 0.68352, saving model to ./storage/writer_train_10/kfold1/epoch_021_val_0.684.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.6836 - accuracy: 0.7631 - val_loss: 0.6835 - val_accuracy: 0.7584\n",
      "Epoch 22/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.6674 - accuracy: 0.7677\n",
      "Epoch 00022: val_loss improved from 0.68352 to 0.67090, saving model to ./storage/writer_train_10/kfold1/epoch_022_val_0.671.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.6675 - accuracy: 0.7676 - val_loss: 0.6709 - val_accuracy: 0.7642\n",
      "Epoch 23/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.6523 - accuracy: 0.7722\n",
      "Epoch 00023: val_loss improved from 0.67090 to 0.66379, saving model to ./storage/writer_train_10/kfold1/epoch_023_val_0.664.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.6523 - accuracy: 0.7722 - val_loss: 0.6638 - val_accuracy: 0.7606\n",
      "Epoch 24/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.6379 - accuracy: 0.7780\n",
      "Epoch 00024: val_loss improved from 0.66379 to 0.65189, saving model to ./storage/writer_train_10/kfold1/epoch_024_val_0.652.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.6381 - accuracy: 0.7777 - val_loss: 0.6519 - val_accuracy: 0.7655\n",
      "Epoch 25/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.6248 - accuracy: 0.7819\n",
      "Epoch 00025: val_loss improved from 0.65189 to 0.64765, saving model to ./storage/writer_train_10/kfold1/epoch_025_val_0.648.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.6245 - accuracy: 0.7822 - val_loss: 0.6477 - val_accuracy: 0.7669\n",
      "Epoch 26/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.6113 - accuracy: 0.7866\n",
      "Epoch 00026: val_loss improved from 0.64765 to 0.63618, saving model to ./storage/writer_train_10/kfold1/epoch_026_val_0.636.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.6116 - accuracy: 0.7864 - val_loss: 0.6362 - val_accuracy: 0.7733\n",
      "Epoch 27/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.6001 - accuracy: 0.7898\n",
      "Epoch 00027: val_loss improved from 0.63618 to 0.62939, saving model to ./storage/writer_train_10/kfold1/epoch_027_val_0.629.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.5997 - accuracy: 0.7899 - val_loss: 0.6294 - val_accuracy: 0.7741\n",
      "Epoch 28/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.5886 - accuracy: 0.7938\n",
      "Epoch 00028: val_loss improved from 0.62939 to 0.62588, saving model to ./storage/writer_train_10/kfold1/epoch_028_val_0.626.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5886 - accuracy: 0.7940 - val_loss: 0.6259 - val_accuracy: 0.7744\n",
      "Epoch 29/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.5777 - accuracy: 0.7976\n",
      "Epoch 00029: val_loss improved from 0.62588 to 0.61801, saving model to ./storage/writer_train_10/kfold1/epoch_029_val_0.618.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5776 - accuracy: 0.7977 - val_loss: 0.6180 - val_accuracy: 0.7786\n",
      "Epoch 30/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.5674 - accuracy: 0.8009\n",
      "Epoch 00030: val_loss improved from 0.61801 to 0.61260, saving model to ./storage/writer_train_10/kfold1/epoch_030_val_0.613.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.5674 - accuracy: 0.8009 - val_loss: 0.6126 - val_accuracy: 0.7797\n",
      "Epoch 31/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.5580 - accuracy: 0.8036\n",
      "Epoch 00031: val_loss improved from 0.61260 to 0.61191, saving model to ./storage/writer_train_10/kfold1/epoch_031_val_0.612.h5\n",
      "98782/98782 [==============================] - 4s 45us/sample - loss: 0.5579 - accuracy: 0.8036 - val_loss: 0.6119 - val_accuracy: 0.7766\n",
      "Epoch 32/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.5488 - accuracy: 0.8071\n",
      "Epoch 00032: val_loss improved from 0.61191 to 0.60616, saving model to ./storage/writer_train_10/kfold1/epoch_032_val_0.606.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.5485 - accuracy: 0.8073 - val_loss: 0.6062 - val_accuracy: 0.7812\n",
      "Epoch 33/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.5395 - accuracy: 0.8098\n",
      "Epoch 00033: val_loss improved from 0.60616 to 0.60031, saving model to ./storage/writer_train_10/kfold1/epoch_033_val_0.600.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5393 - accuracy: 0.8098 - val_loss: 0.6003 - val_accuracy: 0.7837\n",
      "Epoch 34/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.5310 - accuracy: 0.8129\n",
      "Epoch 00034: val_loss improved from 0.60031 to 0.59701, saving model to ./storage/writer_train_10/kfold1/epoch_034_val_0.597.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.5309 - accuracy: 0.8129 - val_loss: 0.5970 - val_accuracy: 0.7839\n",
      "Epoch 35/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.5234 - accuracy: 0.8152\n",
      "Epoch 00035: val_loss improved from 0.59701 to 0.59416, saving model to ./storage/writer_train_10/kfold1/epoch_035_val_0.594.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.5232 - accuracy: 0.8154 - val_loss: 0.5942 - val_accuracy: 0.7864\n",
      "Epoch 36/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.5150 - accuracy: 0.8183\n",
      "Epoch 00036: val_loss improved from 0.59416 to 0.59242, saving model to ./storage/writer_train_10/kfold1/epoch_036_val_0.592.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.5155 - accuracy: 0.8184 - val_loss: 0.5924 - val_accuracy: 0.7832\n",
      "Epoch 37/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.5081 - accuracy: 0.8206\n",
      "Epoch 00037: val_loss improved from 0.59242 to 0.59094, saving model to ./storage/writer_train_10/kfold1/epoch_037_val_0.591.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5081 - accuracy: 0.8206 - val_loss: 0.5909 - val_accuracy: 0.7875\n",
      "Epoch 38/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.5008 - accuracy: 0.8235\n",
      "Epoch 00038: val_loss improved from 0.59094 to 0.58798, saving model to ./storage/writer_train_10/kfold1/epoch_038_val_0.588.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5009 - accuracy: 0.8234 - val_loss: 0.5880 - val_accuracy: 0.7832\n",
      "Epoch 39/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.4939 - accuracy: 0.8257\n",
      "Epoch 00039: val_loss improved from 0.58798 to 0.58465, saving model to ./storage/writer_train_10/kfold1/epoch_039_val_0.585.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.4939 - accuracy: 0.8256 - val_loss: 0.5847 - val_accuracy: 0.7861\n",
      "Epoch 40/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4876 - accuracy: 0.8276\n",
      "Epoch 00040: val_loss improved from 0.58465 to 0.58232, saving model to ./storage/writer_train_10/kfold1/epoch_040_val_0.582.h5\n",
      "98782/98782 [==============================] - 4s 45us/sample - loss: 0.4876 - accuracy: 0.8276 - val_loss: 0.5823 - val_accuracy: 0.7877\n",
      "Epoch 41/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.4810 - accuracy: 0.8307\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0007500000356230885.\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.58232\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4810 - accuracy: 0.8305 - val_loss: 0.5826 - val_accuracy: 0.7844\n",
      "Epoch 42/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4753 - accuracy: 0.8328\n",
      "Epoch 00042: val_loss improved from 0.58232 to 0.58087, saving model to ./storage/writer_train_10/kfold1/epoch_042_val_0.581.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.4752 - accuracy: 0.8329 - val_loss: 0.5809 - val_accuracy: 0.7903\n",
      "Epoch 43/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.4704 - accuracy: 0.8341\n",
      "Epoch 00043: val_loss improved from 0.58087 to 0.57995, saving model to ./storage/writer_train_10/kfold1/epoch_043_val_0.580.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.4705 - accuracy: 0.8340 - val_loss: 0.5800 - val_accuracy: 0.7874\n",
      "Epoch 44/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.4662 - accuracy: 0.8353\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0005625000048894435.\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.57995\n",
      "98782/98782 [==============================] - 4s 37us/sample - loss: 0.4662 - accuracy: 0.8353 - val_loss: 0.5807 - val_accuracy: 0.7863\n",
      "Epoch 45/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.4617 - accuracy: 0.8368\n",
      "Epoch 00045: val_loss improved from 0.57995 to 0.57945, saving model to ./storage/writer_train_10/kfold1/epoch_045_val_0.579.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.4617 - accuracy: 0.8368 - val_loss: 0.5795 - val_accuracy: 0.7888\n",
      "Epoch 46/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.4589 - accuracy: 0.8382\n",
      "Epoch 00046: val_loss improved from 0.57945 to 0.57793, saving model to ./storage/writer_train_10/kfold1/epoch_046_val_0.578.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.4587 - accuracy: 0.8383 - val_loss: 0.5779 - val_accuracy: 0.7895\n",
      "Epoch 47/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.4557 - accuracy: 0.8384\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0004218749818392098.\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.57793\n",
      "98782/98782 [==============================] - 4s 37us/sample - loss: 0.4557 - accuracy: 0.8384 - val_loss: 0.5787 - val_accuracy: 0.7890\n",
      "Epoch 48/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.4523 - accuracy: 0.8401\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.00031640623637940735.\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.57793\n",
      "98782/98782 [==============================] - 4s 39us/sample - loss: 0.4526 - accuracy: 0.8400 - val_loss: 0.5799 - val_accuracy: 0.7874\n",
      "Epoch 49/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.4497 - accuracy: 0.8413\n",
      "Epoch 00049: val_loss improved from 0.57793 to 0.57738, saving model to ./storage/writer_train_10/kfold1/epoch_049_val_0.577.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.4503 - accuracy: 0.8408 - val_loss: 0.5774 - val_accuracy: 0.7890\n",
      "Epoch 50/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.4488 - accuracy: 0.8410\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.00023730468819849193.\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.57738\n",
      "98782/98782 [==============================] - 4s 37us/sample - loss: 0.4485 - accuracy: 0.8412 - val_loss: 0.5788 - val_accuracy: 0.7888\n",
      "Epoch 51/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.4466 - accuracy: 0.8424\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.00017797851614886895.\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.57738\n",
      "98782/98782 [==============================] - 4s 39us/sample - loss: 0.4469 - accuracy: 0.8423 - val_loss: 0.5775 - val_accuracy: 0.7897\n",
      "Epoch 52/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4455 - accuracy: 0.8429\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.0001334838816546835.\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.57738\n",
      "98782/98782 [==============================] - 4s 39us/sample - loss: 0.4455 - accuracy: 0.8429 - val_loss: 0.5786 - val_accuracy: 0.7895\n",
      "Epoch 53/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.4447 - accuracy: 0.8431\n",
      "Epoch 00053: val_loss improved from 0.57738 to 0.57684, saving model to ./storage/writer_train_10/kfold1/epoch_053_val_0.577.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.4446 - accuracy: 0.8431 - val_loss: 0.5768 - val_accuracy: 0.7894\n",
      "Epoch 54/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4437 - accuracy: 0.8433\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.00010011290578404441.\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.57684\n",
      "98782/98782 [==============================] - 4s 37us/sample - loss: 0.4438 - accuracy: 0.8432 - val_loss: 0.5776 - val_accuracy: 0.7894\n",
      "Epoch 55/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.4434 - accuracy: 0.8438\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 7.508467933803331e-05.\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.57684\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4431 - accuracy: 0.8438 - val_loss: 0.5774 - val_accuracy: 0.7881\n",
      "Epoch 56/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.4426 - accuracy: 0.8440\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 5.6313510867767036e-05.\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.57684\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4426 - accuracy: 0.8440 - val_loss: 0.5775 - val_accuracy: 0.7892\n",
      "Epoch 57/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.4423 - accuracy: 0.8443\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 4.223513315082528e-05.\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.57684\n",
      "98782/98782 [==============================] - 4s 37us/sample - loss: 0.4422 - accuracy: 0.8442 - val_loss: 0.5769 - val_accuracy: 0.7886\n",
      "Epoch 58/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.4421 - accuracy: 0.8441\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 3.167634986311896e-05.\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.57684\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4419 - accuracy: 0.8441 - val_loss: 0.5776 - val_accuracy: 0.7883\n",
      "Epoch 59/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4420 - accuracy: 0.8441\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 2.3757263079460245e-05.\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.57684\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4417 - accuracy: 0.8442 - val_loss: 0.5771 - val_accuracy: 0.7894\n",
      "Epoch 60/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4414 - accuracy: 0.8445\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 1.781794799171621e-05.\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.57684\n",
      "98782/98782 [==============================] - 4s 37us/sample - loss: 0.4415 - accuracy: 0.8445 - val_loss: 0.5772 - val_accuracy: 0.7886\n",
      "Epoch 61/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.4411 - accuracy: 0.8444\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 1.3363460311666131e-05.\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.57684\n",
      "98782/98782 [==============================] - 4s 37us/sample - loss: 0.4414 - accuracy: 0.8445 - val_loss: 0.5769 - val_accuracy: 0.7897\n",
      "Epoch 62/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.4411 - accuracy: 0.8446\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 1.0022595233749598e-05.\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.57684\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4413 - accuracy: 0.8444 - val_loss: 0.5772 - val_accuracy: 0.7890\n",
      "Epoch 63/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4413 - accuracy: 0.8447\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 7.516946425312199e-06.\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.57684\n",
      "98782/98782 [==============================] - 4s 37us/sample - loss: 0.4412 - accuracy: 0.8448 - val_loss: 0.5771 - val_accuracy: 0.7892\n",
      "... Iteration 2 ...\n",
      "... Preprocessing Data ... \n",
      "(98782, 256) (98782,)\n",
      "(5488, 256) (5488,)\n",
      "... Training Model by Validating on Fold 2 ...\n",
      "Train on 98782 samples, validate on 5488 samples\n",
      "Epoch 1/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 1.5600 - accuracy: 0.2786\n",
      "Epoch 00001: val_loss improved from inf to 1.53881, saving model to ./storage/writer_train_10/kfold2/epoch_001_val_1.539.h5\n",
      "98782/98782 [==============================] - 5s 47us/sample - loss: 1.5599 - accuracy: 0.2785 - val_loss: 1.5388 - val_accuracy: 0.2903\n",
      "Epoch 2/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 1.5154 - accuracy: 0.3397\n",
      "Epoch 00002: val_loss improved from 1.53881 to 1.47166, saving model to ./storage/writer_train_10/kfold2/epoch_002_val_1.472.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 1.5148 - accuracy: 0.3410 - val_loss: 1.4717 - val_accuracy: 0.4410\n",
      "Epoch 3/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 1.4374 - accuracy: 0.4479\n",
      "Epoch 00003: val_loss improved from 1.47166 to 1.37395, saving model to ./storage/writer_train_10/kfold2/epoch_003_val_1.374.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 1.4371 - accuracy: 0.4483 - val_loss: 1.3740 - val_accuracy: 0.5281\n",
      "Epoch 4/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 1.3470 - accuracy: 0.5048\n",
      "Epoch 00004: val_loss improved from 1.37395 to 1.27332, saving model to ./storage/writer_train_10/kfold2/epoch_004_val_1.273.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 1.3464 - accuracy: 0.5048 - val_loss: 1.2733 - val_accuracy: 0.5461\n",
      "Epoch 5/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 1.2615 - accuracy: 0.5421\n",
      "Epoch 00005: val_loss improved from 1.27332 to 1.18425, saving model to ./storage/writer_train_10/kfold2/epoch_005_val_1.184.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 1.2611 - accuracy: 0.5420 - val_loss: 1.1842 - val_accuracy: 0.5853\n",
      "Epoch 6/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 1.1859 - accuracy: 0.5731\n",
      "Epoch 00006: val_loss improved from 1.18425 to 1.10812, saving model to ./storage/writer_train_10/kfold2/epoch_006_val_1.108.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 1.1858 - accuracy: 0.5733 - val_loss: 1.1081 - val_accuracy: 0.6221\n",
      "Epoch 7/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 1.1209 - accuracy: 0.5984\n",
      "Epoch 00007: val_loss improved from 1.10812 to 1.04485, saving model to ./storage/writer_train_10/kfold2/epoch_007_val_1.045.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 1.1201 - accuracy: 0.5986 - val_loss: 1.0448 - val_accuracy: 0.6423\n",
      "Epoch 8/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 1.0631 - accuracy: 0.6210\n",
      "Epoch 00008: val_loss improved from 1.04485 to 0.99083, saving model to ./storage/writer_train_10/kfold2/epoch_008_val_0.991.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 1.0631 - accuracy: 0.6210 - val_loss: 0.9908 - val_accuracy: 0.6538\n",
      "Epoch 9/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 1.0134 - accuracy: 0.6392\n",
      "Epoch 00009: val_loss improved from 0.99083 to 0.94502, saving model to ./storage/writer_train_10/kfold2/epoch_009_val_0.945.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 1.0133 - accuracy: 0.6392 - val_loss: 0.9450 - val_accuracy: 0.6695\n",
      "Epoch 10/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.9691 - accuracy: 0.6561\n",
      "Epoch 00010: val_loss improved from 0.94502 to 0.90794, saving model to ./storage/writer_train_10/kfold2/epoch_010_val_0.908.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.9691 - accuracy: 0.6561 - val_loss: 0.9079 - val_accuracy: 0.6848\n",
      "Epoch 11/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.9297 - accuracy: 0.6715\n",
      "Epoch 00011: val_loss improved from 0.90794 to 0.87337, saving model to ./storage/writer_train_10/kfold2/epoch_011_val_0.873.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.9297 - accuracy: 0.6715 - val_loss: 0.8734 - val_accuracy: 0.6999\n",
      "Epoch 12/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.8950 - accuracy: 0.6846\n",
      "Epoch 00012: val_loss improved from 0.87337 to 0.84308, saving model to ./storage/writer_train_10/kfold2/epoch_012_val_0.843.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.8949 - accuracy: 0.6848 - val_loss: 0.8431 - val_accuracy: 0.7101\n",
      "Epoch 13/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.8632 - accuracy: 0.6983\n",
      "Epoch 00013: val_loss improved from 0.84308 to 0.81622, saving model to ./storage/writer_train_10/kfold2/epoch_013_val_0.816.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.8630 - accuracy: 0.6985 - val_loss: 0.8162 - val_accuracy: 0.7177\n",
      "Epoch 14/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.8341 - accuracy: 0.7090\n",
      "Epoch 00014: val_loss improved from 0.81622 to 0.79566, saving model to ./storage/writer_train_10/kfold2/epoch_014_val_0.796.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.8339 - accuracy: 0.7091 - val_loss: 0.7957 - val_accuracy: 0.7223\n",
      "Epoch 15/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.8076 - accuracy: 0.7193\n",
      "Epoch 00015: val_loss improved from 0.79566 to 0.77146, saving model to ./storage/writer_train_10/kfold2/epoch_015_val_0.771.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.8074 - accuracy: 0.7192 - val_loss: 0.7715 - val_accuracy: 0.7320\n",
      "Epoch 16/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.7834 - accuracy: 0.7282\n",
      "Epoch 00016: val_loss improved from 0.77146 to 0.75279, saving model to ./storage/writer_train_10/kfold2/epoch_016_val_0.753.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.7830 - accuracy: 0.7283 - val_loss: 0.7528 - val_accuracy: 0.7378\n",
      "Epoch 17/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.7606 - accuracy: 0.7359\n",
      "Epoch 00017: val_loss improved from 0.75279 to 0.73586, saving model to ./storage/writer_train_10/kfold2/epoch_017_val_0.736.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.7606 - accuracy: 0.7359 - val_loss: 0.7359 - val_accuracy: 0.7474\n",
      "Epoch 18/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.7398 - accuracy: 0.7436\n",
      "Epoch 00018: val_loss improved from 0.73586 to 0.72427, saving model to ./storage/writer_train_10/kfold2/epoch_018_val_0.724.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.7395 - accuracy: 0.7435 - val_loss: 0.7243 - val_accuracy: 0.7451\n",
      "Epoch 19/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.7203 - accuracy: 0.7493\n",
      "Epoch 00019: val_loss improved from 0.72427 to 0.70849, saving model to ./storage/writer_train_10/kfold2/epoch_019_val_0.708.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.7199 - accuracy: 0.7496 - val_loss: 0.7085 - val_accuracy: 0.7489\n",
      "Epoch 20/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.7021 - accuracy: 0.7562\n",
      "Epoch 00020: val_loss improved from 0.70849 to 0.69475, saving model to ./storage/writer_train_10/kfold2/epoch_020_val_0.695.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.7019 - accuracy: 0.7564 - val_loss: 0.6948 - val_accuracy: 0.7580\n",
      "Epoch 21/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.6847 - accuracy: 0.7610\n",
      "Epoch 00021: val_loss improved from 0.69475 to 0.68607, saving model to ./storage/writer_train_10/kfold2/epoch_021_val_0.686.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.6848 - accuracy: 0.7611 - val_loss: 0.6861 - val_accuracy: 0.7618\n",
      "Epoch 22/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.6689 - accuracy: 0.7661\n",
      "Epoch 00022: val_loss improved from 0.68607 to 0.67465, saving model to ./storage/writer_train_10/kfold2/epoch_022_val_0.675.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.6690 - accuracy: 0.7661 - val_loss: 0.6746 - val_accuracy: 0.7615\n",
      "Epoch 23/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.6539 - accuracy: 0.7721\n",
      "Epoch 00023: val_loss improved from 0.67465 to 0.66416, saving model to ./storage/writer_train_10/kfold2/epoch_023_val_0.664.h5\n",
      "98782/98782 [==============================] - 4s 44us/sample - loss: 0.6538 - accuracy: 0.7721 - val_loss: 0.6642 - val_accuracy: 0.7651\n",
      "Epoch 24/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.6397 - accuracy: 0.7759\n",
      "Epoch 00024: val_loss improved from 0.66416 to 0.65661, saving model to ./storage/writer_train_10/kfold2/epoch_024_val_0.657.h5\n",
      "98782/98782 [==============================] - 5s 47us/sample - loss: 0.6397 - accuracy: 0.7760 - val_loss: 0.6566 - val_accuracy: 0.7677\n",
      "Epoch 25/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.6265 - accuracy: 0.7804\n",
      "Epoch 00025: val_loss improved from 0.65661 to 0.64991, saving model to ./storage/writer_train_10/kfold2/epoch_025_val_0.650.h5\n",
      "98782/98782 [==============================] - 4s 44us/sample - loss: 0.6265 - accuracy: 0.7804 - val_loss: 0.6499 - val_accuracy: 0.7720\n",
      "Epoch 26/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.6137 - accuracy: 0.7846\n",
      "Epoch 00026: val_loss improved from 0.64991 to 0.64301, saving model to ./storage/writer_train_10/kfold2/epoch_026_val_0.643.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.6139 - accuracy: 0.7846 - val_loss: 0.6430 - val_accuracy: 0.7708\n",
      "Epoch 27/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.6021 - accuracy: 0.7886\n",
      "Epoch 00027: val_loss improved from 0.64301 to 0.63614, saving model to ./storage/writer_train_10/kfold2/epoch_027_val_0.636.h5\n",
      "98782/98782 [==============================] - 5s 46us/sample - loss: 0.6021 - accuracy: 0.7886 - val_loss: 0.6361 - val_accuracy: 0.7735\n",
      "Epoch 28/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.5905 - accuracy: 0.7924\n",
      "Epoch 00028: val_loss improved from 0.63614 to 0.63138, saving model to ./storage/writer_train_10/kfold2/epoch_028_val_0.631.h5\n",
      "98782/98782 [==============================] - 5s 46us/sample - loss: 0.5906 - accuracy: 0.7924 - val_loss: 0.6314 - val_accuracy: 0.7746\n",
      "Epoch 29/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.5798 - accuracy: 0.7961\n",
      "Epoch 00029: val_loss improved from 0.63138 to 0.62590, saving model to ./storage/writer_train_10/kfold2/epoch_029_val_0.626.h5\n",
      "98782/98782 [==============================] - 4s 40us/sample - loss: 0.5797 - accuracy: 0.7961 - val_loss: 0.6259 - val_accuracy: 0.7777\n",
      "Epoch 30/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.5696 - accuracy: 0.7992\n",
      "Epoch 00030: val_loss improved from 0.62590 to 0.62047, saving model to ./storage/writer_train_10/kfold2/epoch_030_val_0.620.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.5693 - accuracy: 0.7993 - val_loss: 0.6205 - val_accuracy: 0.7795\n",
      "Epoch 31/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.5600 - accuracy: 0.8019\n",
      "Epoch 00031: val_loss improved from 0.62047 to 0.61795, saving model to ./storage/writer_train_10/kfold2/epoch_031_val_0.618.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.5598 - accuracy: 0.8022 - val_loss: 0.6180 - val_accuracy: 0.7788\n",
      "Epoch 32/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.5508 - accuracy: 0.8050\n",
      "Epoch 00032: val_loss improved from 0.61795 to 0.61442, saving model to ./storage/writer_train_10/kfold2/epoch_032_val_0.614.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5508 - accuracy: 0.8051 - val_loss: 0.6144 - val_accuracy: 0.7812\n",
      "Epoch 33/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.5413 - accuracy: 0.8088\n",
      "Epoch 00033: val_loss improved from 0.61442 to 0.61107, saving model to ./storage/writer_train_10/kfold2/epoch_033_val_0.611.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5415 - accuracy: 0.8085 - val_loss: 0.6111 - val_accuracy: 0.7843\n",
      "Epoch 34/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.5335 - accuracy: 0.8111\n",
      "Epoch 00034: val_loss improved from 0.61107 to 0.60819, saving model to ./storage/writer_train_10/kfold2/epoch_034_val_0.608.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.5333 - accuracy: 0.8112 - val_loss: 0.6082 - val_accuracy: 0.7832\n",
      "Epoch 35/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.5250 - accuracy: 0.8142\n",
      "Epoch 00035: val_loss improved from 0.60819 to 0.60473, saving model to ./storage/writer_train_10/kfold2/epoch_035_val_0.605.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5249 - accuracy: 0.8142 - val_loss: 0.6047 - val_accuracy: 0.7848\n",
      "Epoch 36/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.5174 - accuracy: 0.8167\n",
      "Epoch 00036: val_loss improved from 0.60473 to 0.60445, saving model to ./storage/writer_train_10/kfold2/epoch_036_val_0.604.h5\n",
      "98782/98782 [==============================] - 5s 49us/sample - loss: 0.5175 - accuracy: 0.8166 - val_loss: 0.6045 - val_accuracy: 0.7837\n",
      "Epoch 37/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.5102 - accuracy: 0.8190\n",
      "Epoch 00037: val_loss improved from 0.60445 to 0.60006, saving model to ./storage/writer_train_10/kfold2/epoch_037_val_0.600.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5101 - accuracy: 0.8191 - val_loss: 0.6001 - val_accuracy: 0.7848\n",
      "Epoch 38/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.5034 - accuracy: 0.8217\n",
      "Epoch 00038: val_loss improved from 0.60006 to 0.59781, saving model to ./storage/writer_train_10/kfold2/epoch_038_val_0.598.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.5031 - accuracy: 0.8218 - val_loss: 0.5978 - val_accuracy: 0.7870\n",
      "Epoch 39/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4961 - accuracy: 0.8242\n",
      "Epoch 00039: val_loss improved from 0.59781 to 0.59695, saving model to ./storage/writer_train_10/kfold2/epoch_039_val_0.597.h5\n",
      "98782/98782 [==============================] - 4s 44us/sample - loss: 0.4959 - accuracy: 0.8242 - val_loss: 0.5969 - val_accuracy: 0.7863\n",
      "Epoch 40/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4894 - accuracy: 0.8264\n",
      "Epoch 00040: val_loss improved from 0.59695 to 0.59586, saving model to ./storage/writer_train_10/kfold2/epoch_040_val_0.596.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.4897 - accuracy: 0.8264 - val_loss: 0.5959 - val_accuracy: 0.7864\n",
      "Epoch 41/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.4827 - accuracy: 0.8281\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0007500000356230885.\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.59586\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4830 - accuracy: 0.8282 - val_loss: 0.5985 - val_accuracy: 0.7835\n",
      "Epoch 42/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.4767 - accuracy: 0.8312\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0005625000048894435.\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.59586\n",
      "98782/98782 [==============================] - 4s 39us/sample - loss: 0.4768 - accuracy: 0.8311 - val_loss: 0.5960 - val_accuracy: 0.7894\n",
      "Epoch 43/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4725 - accuracy: 0.8327\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0004218749818392098.\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.59586\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4722 - accuracy: 0.8328 - val_loss: 0.5966 - val_accuracy: 0.7864\n",
      "Epoch 44/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.4687 - accuracy: 0.8341\n",
      "Epoch 00044: val_loss improved from 0.59586 to 0.59533, saving model to ./storage/writer_train_10/kfold2/epoch_044_val_0.595.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.4688 - accuracy: 0.8341 - val_loss: 0.5953 - val_accuracy: 0.7853\n",
      "Epoch 45/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.4662 - accuracy: 0.8353\n",
      "Epoch 00045: val_loss improved from 0.59533 to 0.59421, saving model to ./storage/writer_train_10/kfold2/epoch_045_val_0.594.h5\n",
      "98782/98782 [==============================] - 5s 50us/sample - loss: 0.4665 - accuracy: 0.8351 - val_loss: 0.5942 - val_accuracy: 0.7866\n",
      "Epoch 46/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4641 - accuracy: 0.8357\n",
      "Epoch 00046: val_loss improved from 0.59421 to 0.59316, saving model to ./storage/writer_train_10/kfold2/epoch_046_val_0.593.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.4642 - accuracy: 0.8357 - val_loss: 0.5932 - val_accuracy: 0.7874\n",
      "Epoch 47/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.4617 - accuracy: 0.8364\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.00031640623637940735.\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.59316\n",
      "98782/98782 [==============================] - 4s 37us/sample - loss: 0.4617 - accuracy: 0.8364 - val_loss: 0.5938 - val_accuracy: 0.7884\n",
      "Epoch 48/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.4592 - accuracy: 0.8378\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.00023730468819849193.\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.59316\n",
      "98782/98782 [==============================] - 4s 37us/sample - loss: 0.4592 - accuracy: 0.8377 - val_loss: 0.5934 - val_accuracy: 0.7872\n",
      "Epoch 49/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4568 - accuracy: 0.8386\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.00017797851614886895.\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.59316\n",
      "98782/98782 [==============================] - 4s 37us/sample - loss: 0.4573 - accuracy: 0.8383 - val_loss: 0.5932 - val_accuracy: 0.7870\n",
      "Epoch 50/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.4563 - accuracy: 0.8390\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0001334838816546835.\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.59316\n",
      "98782/98782 [==============================] - 4s 37us/sample - loss: 0.4560 - accuracy: 0.8391 - val_loss: 0.5937 - val_accuracy: 0.7872\n",
      "Epoch 51/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4550 - accuracy: 0.8391\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.00010011290578404441.\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.59316\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.4550 - accuracy: 0.8391 - val_loss: 0.5935 - val_accuracy: 0.7852\n",
      "Epoch 52/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.4542 - accuracy: 0.8396\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 7.508467933803331e-05.\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.59316\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4543 - accuracy: 0.8396 - val_loss: 0.5938 - val_accuracy: 0.7866\n",
      "Epoch 53/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4532 - accuracy: 0.8399\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 5.6313510867767036e-05.\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.59316\n",
      "98782/98782 [==============================] - 4s 40us/sample - loss: 0.4537 - accuracy: 0.8399 - val_loss: 0.5940 - val_accuracy: 0.7863\n",
      "Epoch 54/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4536 - accuracy: 0.8396\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 4.223513315082528e-05.\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.59316\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.4533 - accuracy: 0.8398 - val_loss: 0.5937 - val_accuracy: 0.7874\n",
      "Epoch 55/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.4531 - accuracy: 0.8397\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 3.167634986311896e-05.\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.59316\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4529 - accuracy: 0.8398 - val_loss: 0.5936 - val_accuracy: 0.7861\n",
      "Epoch 56/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4527 - accuracy: 0.8399\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 2.3757263079460245e-05.\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.59316\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4527 - accuracy: 0.8399 - val_loss: 0.5934 - val_accuracy: 0.7859\n",
      "... Iteration 3 ...\n",
      "... Preprocessing Data ... \n",
      "(98782, 256) (98782,)\n",
      "(5488, 256) (5488,)\n",
      "... Training Model by Validating on Fold 3 ...\n",
      "Train on 98782 samples, validate on 5488 samples\n",
      "Epoch 1/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 1.5624 - accuracy: 0.2751\n",
      "Epoch 00001: val_loss improved from inf to 1.54009, saving model to ./storage/writer_train_10/kfold3/epoch_001_val_1.540.h5\n",
      "98782/98782 [==============================] - 5s 47us/sample - loss: 1.5623 - accuracy: 0.2752 - val_loss: 1.5401 - val_accuracy: 0.2863\n",
      "Epoch 2/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 1.5142 - accuracy: 0.3370\n",
      "Epoch 00002: val_loss improved from 1.54009 to 1.46962, saving model to ./storage/writer_train_10/kfold3/epoch_002_val_1.470.h5\n",
      "98782/98782 [==============================] - 4s 45us/sample - loss: 1.5139 - accuracy: 0.3380 - val_loss: 1.4696 - val_accuracy: 0.4506\n",
      "Epoch 3/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 1.4337 - accuracy: 0.4491\n",
      "Epoch 00003: val_loss improved from 1.46962 to 1.36767, saving model to ./storage/writer_train_10/kfold3/epoch_003_val_1.368.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 1.4330 - accuracy: 0.4496 - val_loss: 1.3677 - val_accuracy: 0.5066\n",
      "Epoch 4/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 1.3393 - accuracy: 0.5093\n",
      "Epoch 00004: val_loss improved from 1.36767 to 1.26558, saving model to ./storage/writer_train_10/kfold3/epoch_004_val_1.266.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 1.3387 - accuracy: 0.5097 - val_loss: 1.2656 - val_accuracy: 0.5649\n",
      "Epoch 5/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 1.2504 - accuracy: 0.5528\n",
      "Epoch 00005: val_loss improved from 1.26558 to 1.17428, saving model to ./storage/writer_train_10/kfold3/epoch_005_val_1.174.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 1.2499 - accuracy: 0.5532 - val_loss: 1.1743 - val_accuracy: 0.6024\n",
      "Epoch 6/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 1.1717 - accuracy: 0.5866\n",
      "Epoch 00006: val_loss improved from 1.17428 to 1.10106, saving model to ./storage/writer_train_10/kfold3/epoch_006_val_1.101.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 1.1716 - accuracy: 0.5865 - val_loss: 1.1011 - val_accuracy: 0.6317\n",
      "Epoch 7/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 1.1040 - accuracy: 0.6120\n",
      "Epoch 00007: val_loss improved from 1.10106 to 1.03437, saving model to ./storage/writer_train_10/kfold3/epoch_007_val_1.034.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 1.1041 - accuracy: 0.6120 - val_loss: 1.0344 - val_accuracy: 0.6554\n",
      "Epoch 8/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 1.0460 - accuracy: 0.6333\n",
      "Epoch 00008: val_loss improved from 1.03437 to 0.97885, saving model to ./storage/writer_train_10/kfold3/epoch_008_val_0.979.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 1.0458 - accuracy: 0.6334 - val_loss: 0.9788 - val_accuracy: 0.6682\n",
      "Epoch 9/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.9959 - accuracy: 0.6517\n",
      "Epoch 00009: val_loss improved from 0.97885 to 0.93546, saving model to ./storage/writer_train_10/kfold3/epoch_009_val_0.935.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.9959 - accuracy: 0.6516 - val_loss: 0.9355 - val_accuracy: 0.6859\n",
      "Epoch 10/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.9524 - accuracy: 0.6674\n",
      "Epoch 00010: val_loss improved from 0.93546 to 0.89750, saving model to ./storage/writer_train_10/kfold3/epoch_010_val_0.898.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.9522 - accuracy: 0.6674 - val_loss: 0.8975 - val_accuracy: 0.6995\n",
      "Epoch 11/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.9136 - accuracy: 0.6824\n",
      "Epoch 00011: val_loss improved from 0.89750 to 0.86775, saving model to ./storage/writer_train_10/kfold3/epoch_011_val_0.868.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.9134 - accuracy: 0.6824 - val_loss: 0.8677 - val_accuracy: 0.7101\n",
      "Epoch 12/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.8793 - accuracy: 0.6951\n",
      "Epoch 00012: val_loss improved from 0.86775 to 0.83500, saving model to ./storage/writer_train_10/kfold3/epoch_012_val_0.835.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.8793 - accuracy: 0.6950 - val_loss: 0.8350 - val_accuracy: 0.7185\n",
      "Epoch 13/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.8479 - accuracy: 0.7064\n",
      "Epoch 00013: val_loss improved from 0.83500 to 0.81080, saving model to ./storage/writer_train_10/kfold3/epoch_013_val_0.811.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.8480 - accuracy: 0.7064 - val_loss: 0.8108 - val_accuracy: 0.7301\n",
      "Epoch 14/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.8198 - accuracy: 0.7161\n",
      "Epoch 00014: val_loss improved from 0.81080 to 0.78532, saving model to ./storage/writer_train_10/kfold3/epoch_014_val_0.785.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.8198 - accuracy: 0.7160 - val_loss: 0.7853 - val_accuracy: 0.7338\n",
      "Epoch 15/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.7939 - accuracy: 0.7263\n",
      "Epoch 00015: val_loss improved from 0.78532 to 0.76639, saving model to ./storage/writer_train_10/kfold3/epoch_015_val_0.766.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.7939 - accuracy: 0.7263 - val_loss: 0.7664 - val_accuracy: 0.7420\n",
      "Epoch 16/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.7704 - accuracy: 0.7342\n",
      "Epoch 00016: val_loss improved from 0.76639 to 0.74814, saving model to ./storage/writer_train_10/kfold3/epoch_016_val_0.748.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.7703 - accuracy: 0.7342 - val_loss: 0.7481 - val_accuracy: 0.7413\n",
      "Epoch 17/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.7484 - accuracy: 0.7418\n",
      "Epoch 00017: val_loss improved from 0.74814 to 0.73603, saving model to ./storage/writer_train_10/kfold3/epoch_017_val_0.736.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.7483 - accuracy: 0.7418 - val_loss: 0.7360 - val_accuracy: 0.7420\n",
      "Epoch 18/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.7285 - accuracy: 0.7480\n",
      "Epoch 00018: val_loss improved from 0.73603 to 0.71912, saving model to ./storage/writer_train_10/kfold3/epoch_018_val_0.719.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.7282 - accuracy: 0.7481 - val_loss: 0.7191 - val_accuracy: 0.7558\n",
      "Epoch 19/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.7101 - accuracy: 0.7541\n",
      "Epoch 00019: val_loss improved from 0.71912 to 0.70392, saving model to ./storage/writer_train_10/kfold3/epoch_019_val_0.704.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.7094 - accuracy: 0.7545 - val_loss: 0.7039 - val_accuracy: 0.7584\n",
      "Epoch 20/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.6916 - accuracy: 0.7596\n",
      "Epoch 00020: val_loss improved from 0.70392 to 0.69474, saving model to ./storage/writer_train_10/kfold3/epoch_020_val_0.695.h5\n",
      "98782/98782 [==============================] - 5s 47us/sample - loss: 0.6916 - accuracy: 0.7596 - val_loss: 0.6947 - val_accuracy: 0.7600\n",
      "Epoch 21/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.6755 - accuracy: 0.7657\n",
      "Epoch 00021: val_loss improved from 0.69474 to 0.68605, saving model to ./storage/writer_train_10/kfold3/epoch_021_val_0.686.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.6753 - accuracy: 0.7657 - val_loss: 0.6861 - val_accuracy: 0.7644\n",
      "Epoch 22/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.6600 - accuracy: 0.7704\n",
      "Epoch 00022: val_loss improved from 0.68605 to 0.67254, saving model to ./storage/writer_train_10/kfold3/epoch_022_val_0.673.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.6599 - accuracy: 0.7704 - val_loss: 0.6725 - val_accuracy: 0.7669\n",
      "Epoch 23/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.6453 - accuracy: 0.7752\n",
      "Epoch 00023: val_loss improved from 0.67254 to 0.66409, saving model to ./storage/writer_train_10/kfold3/epoch_023_val_0.664.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.6452 - accuracy: 0.7752 - val_loss: 0.6641 - val_accuracy: 0.7671\n",
      "Epoch 24/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.6316 - accuracy: 0.7800\n",
      "Epoch 00024: val_loss improved from 0.66409 to 0.65798, saving model to ./storage/writer_train_10/kfold3/epoch_024_val_0.658.h5\n",
      "98782/98782 [==============================] - 4s 45us/sample - loss: 0.6316 - accuracy: 0.7800 - val_loss: 0.6580 - val_accuracy: 0.7708\n",
      "Epoch 25/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.6187 - accuracy: 0.7843\n",
      "Epoch 00025: val_loss improved from 0.65798 to 0.65006, saving model to ./storage/writer_train_10/kfold3/epoch_025_val_0.650.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.6186 - accuracy: 0.7842 - val_loss: 0.6501 - val_accuracy: 0.7748\n",
      "Epoch 26/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.6065 - accuracy: 0.7882\n",
      "Epoch 00026: val_loss improved from 0.65006 to 0.64126, saving model to ./storage/writer_train_10/kfold3/epoch_026_val_0.641.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.6065 - accuracy: 0.7881 - val_loss: 0.6413 - val_accuracy: 0.7759\n",
      "Epoch 27/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.5952 - accuracy: 0.7917\n",
      "Epoch 00027: val_loss improved from 0.64126 to 0.63931, saving model to ./storage/writer_train_10/kfold3/epoch_027_val_0.639.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5951 - accuracy: 0.7917 - val_loss: 0.6393 - val_accuracy: 0.7739\n",
      "Epoch 28/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.5837 - accuracy: 0.7952\n",
      "Epoch 00028: val_loss improved from 0.63931 to 0.62942, saving model to ./storage/writer_train_10/kfold3/epoch_028_val_0.629.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5840 - accuracy: 0.7950 - val_loss: 0.6294 - val_accuracy: 0.7775\n",
      "Epoch 29/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.5735 - accuracy: 0.7991\n",
      "Epoch 00029: val_loss improved from 0.62942 to 0.62808, saving model to ./storage/writer_train_10/kfold3/epoch_029_val_0.628.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.5737 - accuracy: 0.7990 - val_loss: 0.6281 - val_accuracy: 0.7775\n",
      "Epoch 30/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.5638 - accuracy: 0.8018\n",
      "Epoch 00030: val_loss improved from 0.62808 to 0.62168, saving model to ./storage/writer_train_10/kfold3/epoch_030_val_0.622.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.5638 - accuracy: 0.8019 - val_loss: 0.6217 - val_accuracy: 0.7786\n",
      "Epoch 31/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.5544 - accuracy: 0.8052\n",
      "Epoch 00031: val_loss improved from 0.62168 to 0.61753, saving model to ./storage/writer_train_10/kfold3/epoch_031_val_0.618.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5544 - accuracy: 0.8051 - val_loss: 0.6175 - val_accuracy: 0.7795\n",
      "Epoch 32/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.5459 - accuracy: 0.8078\n",
      "Epoch 00032: val_loss improved from 0.61753 to 0.61532, saving model to ./storage/writer_train_10/kfold3/epoch_032_val_0.615.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5454 - accuracy: 0.8081 - val_loss: 0.6153 - val_accuracy: 0.7821\n",
      "Epoch 33/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.5367 - accuracy: 0.8114\n",
      "Epoch 00033: val_loss improved from 0.61532 to 0.61510, saving model to ./storage/writer_train_10/kfold3/epoch_033_val_0.615.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.5370 - accuracy: 0.8113 - val_loss: 0.6151 - val_accuracy: 0.7821\n",
      "Epoch 34/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.5291 - accuracy: 0.8138\n",
      "Epoch 00034: val_loss improved from 0.61510 to 0.61134, saving model to ./storage/writer_train_10/kfold3/epoch_034_val_0.611.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5288 - accuracy: 0.8140 - val_loss: 0.6113 - val_accuracy: 0.7795\n",
      "Epoch 35/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.5208 - accuracy: 0.8165\n",
      "Epoch 00035: val_loss improved from 0.61134 to 0.60841, saving model to ./storage/writer_train_10/kfold3/epoch_035_val_0.608.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5209 - accuracy: 0.8165 - val_loss: 0.6084 - val_accuracy: 0.7853\n",
      "Epoch 36/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.5136 - accuracy: 0.8189\n",
      "Epoch 00036: val_loss improved from 0.60841 to 0.60342, saving model to ./storage/writer_train_10/kfold3/epoch_036_val_0.603.h5\n",
      "98782/98782 [==============================] - 4s 44us/sample - loss: 0.5135 - accuracy: 0.8190 - val_loss: 0.6034 - val_accuracy: 0.7837\n",
      "Epoch 37/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.5063 - accuracy: 0.8217\n",
      "Epoch 00037: val_loss improved from 0.60342 to 0.60119, saving model to ./storage/writer_train_10/kfold3/epoch_037_val_0.601.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.5066 - accuracy: 0.8217 - val_loss: 0.6012 - val_accuracy: 0.7841\n",
      "Epoch 38/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.4995 - accuracy: 0.8234\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0007500000356230885.\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.60119\n",
      "98782/98782 [==============================] - 4s 39us/sample - loss: 0.4994 - accuracy: 0.8233 - val_loss: 0.6048 - val_accuracy: 0.7833\n",
      "Epoch 39/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.4927 - accuracy: 0.8263\n",
      "Epoch 00039: val_loss improved from 0.60119 to 0.59850, saving model to ./storage/writer_train_10/kfold3/epoch_039_val_0.598.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.4929 - accuracy: 0.8262 - val_loss: 0.5985 - val_accuracy: 0.7863\n",
      "Epoch 40/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4882 - accuracy: 0.8278\n",
      "Epoch 00040: val_loss improved from 0.59850 to 0.59798, saving model to ./storage/writer_train_10/kfold3/epoch_040_val_0.598.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.4880 - accuracy: 0.8279 - val_loss: 0.5980 - val_accuracy: 0.7859\n",
      "Epoch 41/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4835 - accuracy: 0.8296\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0005625000048894435.\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.59798\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4831 - accuracy: 0.8298 - val_loss: 0.5987 - val_accuracy: 0.7866\n",
      "Epoch 42/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4787 - accuracy: 0.8315\n",
      "Epoch 00042: val_loss improved from 0.59798 to 0.59568, saving model to ./storage/writer_train_10/kfold3/epoch_042_val_0.596.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.4786 - accuracy: 0.8315 - val_loss: 0.5957 - val_accuracy: 0.7872\n",
      "Epoch 43/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.4755 - accuracy: 0.8316\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0004218749818392098.\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.59568\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4754 - accuracy: 0.8318 - val_loss: 0.5981 - val_accuracy: 0.7857\n",
      "Epoch 44/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.4718 - accuracy: 0.8342\n",
      "Epoch 00044: val_loss improved from 0.59568 to 0.59447, saving model to ./storage/writer_train_10/kfold3/epoch_044_val_0.594.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.4719 - accuracy: 0.8340 - val_loss: 0.5945 - val_accuracy: 0.7881\n",
      "Epoch 45/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.4693 - accuracy: 0.8348\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.00031640623637940735.\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.59447\n",
      "98782/98782 [==============================] - 4s 40us/sample - loss: 0.4693 - accuracy: 0.8346 - val_loss: 0.5955 - val_accuracy: 0.7857\n",
      "Epoch 46/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.4667 - accuracy: 0.8355\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.00023730468819849193.\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.59447 to 0.59442, saving model to ./storage/writer_train_10/kfold3/epoch_046_val_0.594.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.4668 - accuracy: 0.8355 - val_loss: 0.5944 - val_accuracy: 0.7864\n",
      "Epoch 47/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4651 - accuracy: 0.8357\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.00017797851614886895.\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.59442\n",
      "98782/98782 [==============================] - 4s 39us/sample - loss: 0.4650 - accuracy: 0.8357 - val_loss: 0.5956 - val_accuracy: 0.7852\n",
      "Epoch 48/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.4639 - accuracy: 0.8364\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.0001334838816546835.\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.59442\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4636 - accuracy: 0.8365 - val_loss: 0.5953 - val_accuracy: 0.7850\n",
      "Epoch 49/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4627 - accuracy: 0.8370\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.00010011290578404441.\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.59442\n",
      "98782/98782 [==============================] - 4s 40us/sample - loss: 0.4625 - accuracy: 0.8371 - val_loss: 0.5958 - val_accuracy: 0.7872\n",
      "Epoch 50/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4617 - accuracy: 0.8374\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 7.508467933803331e-05.\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.59442\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4618 - accuracy: 0.8375 - val_loss: 0.5953 - val_accuracy: 0.7859\n",
      "Epoch 51/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.4609 - accuracy: 0.8377\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 5.6313510867767036e-05.\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.59442\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4612 - accuracy: 0.8375 - val_loss: 0.5949 - val_accuracy: 0.7872\n",
      "Epoch 52/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4608 - accuracy: 0.8377\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 4.223513315082528e-05.\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.59442\n",
      "98782/98782 [==============================] - 4s 39us/sample - loss: 0.4608 - accuracy: 0.8377 - val_loss: 0.5951 - val_accuracy: 0.7853\n",
      "Epoch 53/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.4603 - accuracy: 0.8378\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 3.167634986311896e-05.\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.59442\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4605 - accuracy: 0.8377 - val_loss: 0.5951 - val_accuracy: 0.7859\n",
      "Epoch 54/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.4604 - accuracy: 0.8380\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 2.3757263079460245e-05.\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.59442\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4602 - accuracy: 0.8381 - val_loss: 0.5949 - val_accuracy: 0.7861\n",
      "Epoch 55/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4593 - accuracy: 0.8385\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 1.781794799171621e-05.\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.59442\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4600 - accuracy: 0.8381 - val_loss: 0.5949 - val_accuracy: 0.7857\n",
      "Epoch 56/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.4600 - accuracy: 0.8379\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 1.3363460311666131e-05.\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.59442\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4599 - accuracy: 0.8379 - val_loss: 0.5949 - val_accuracy: 0.7850\n",
      "... Iteration 4 ...\n",
      "... Preprocessing Data ... \n",
      "(98782, 256) (98782,)\n",
      "(5488, 256) (5488,)\n",
      "... Training Model by Validating on Fold 4 ...\n",
      "Train on 98782 samples, validate on 5488 samples\n",
      "Epoch 1/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 1.5616 - accuracy: 0.2741\n",
      "Epoch 00001: val_loss improved from inf to 1.53667, saving model to ./storage/writer_train_10/kfold4/epoch_001_val_1.537.h5\n",
      "98782/98782 [==============================] - 5s 48us/sample - loss: 1.5614 - accuracy: 0.2741 - val_loss: 1.5367 - val_accuracy: 0.2806\n",
      "Epoch 2/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 1.5118 - accuracy: 0.3287\n",
      "Epoch 00002: val_loss improved from 1.53667 to 1.46918, saving model to ./storage/writer_train_10/kfold4/epoch_002_val_1.469.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 1.5117 - accuracy: 0.3291 - val_loss: 1.4692 - val_accuracy: 0.4124\n",
      "Epoch 3/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 1.4376 - accuracy: 0.4300\n",
      "Epoch 00003: val_loss improved from 1.46918 to 1.37701, saving model to ./storage/writer_train_10/kfold4/epoch_003_val_1.377.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 1.4374 - accuracy: 0.4300 - val_loss: 1.3770 - val_accuracy: 0.4947\n",
      "Epoch 4/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 1.3522 - accuracy: 0.4983\n",
      "Epoch 00004: val_loss improved from 1.37701 to 1.28124, saving model to ./storage/writer_train_10/kfold4/epoch_004_val_1.281.h5\n",
      "98782/98782 [==============================] - 5s 47us/sample - loss: 1.3517 - accuracy: 0.4986 - val_loss: 1.2812 - val_accuracy: 0.5465\n",
      "Epoch 5/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 1.2676 - accuracy: 0.5446\n",
      "Epoch 00005: val_loss improved from 1.28124 to 1.19312, saving model to ./storage/writer_train_10/kfold4/epoch_005_val_1.193.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 1.2675 - accuracy: 0.5446 - val_loss: 1.1931 - val_accuracy: 0.5774\n",
      "Epoch 6/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 1.1911 - accuracy: 0.5787\n",
      "Epoch 00006: val_loss improved from 1.19312 to 1.11712, saving model to ./storage/writer_train_10/kfold4/epoch_006_val_1.117.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 1.1905 - accuracy: 0.5788 - val_loss: 1.1171 - val_accuracy: 0.6221\n",
      "Epoch 7/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 1.1232 - accuracy: 0.6023\n",
      "Epoch 00007: val_loss improved from 1.11712 to 1.05419, saving model to ./storage/writer_train_10/kfold4/epoch_007_val_1.054.h5\n",
      "98782/98782 [==============================] - 4s 44us/sample - loss: 1.1229 - accuracy: 0.6024 - val_loss: 1.0542 - val_accuracy: 0.6472\n",
      "Epoch 8/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 1.0643 - accuracy: 0.6243\n",
      "Epoch 00008: val_loss improved from 1.05419 to 1.00174, saving model to ./storage/writer_train_10/kfold4/epoch_008_val_1.002.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 1.0639 - accuracy: 0.6245 - val_loss: 1.0017 - val_accuracy: 0.6602\n",
      "Epoch 9/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 1.0122 - accuracy: 0.6427\n",
      "Epoch 00009: val_loss improved from 1.00174 to 0.95307, saving model to ./storage/writer_train_10/kfold4/epoch_009_val_0.953.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 1.0120 - accuracy: 0.6428 - val_loss: 0.9531 - val_accuracy: 0.6780\n",
      "Epoch 10/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.9664 - accuracy: 0.6601\n",
      "Epoch 00010: val_loss improved from 0.95307 to 0.91217, saving model to ./storage/writer_train_10/kfold4/epoch_010_val_0.912.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.9663 - accuracy: 0.6602 - val_loss: 0.9122 - val_accuracy: 0.6910\n",
      "Epoch 11/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.9257 - accuracy: 0.6757\n",
      "Epoch 00011: val_loss improved from 0.91217 to 0.88001, saving model to ./storage/writer_train_10/kfold4/epoch_011_val_0.880.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.9255 - accuracy: 0.6758 - val_loss: 0.8800 - val_accuracy: 0.6959\n",
      "Epoch 12/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.8897 - accuracy: 0.6883\n",
      "Epoch 00012: val_loss improved from 0.88001 to 0.84895, saving model to ./storage/writer_train_10/kfold4/epoch_012_val_0.849.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.8895 - accuracy: 0.6885 - val_loss: 0.8489 - val_accuracy: 0.7130\n",
      "Epoch 13/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.8564 - accuracy: 0.7015\n",
      "Epoch 00013: val_loss improved from 0.84895 to 0.82251, saving model to ./storage/writer_train_10/kfold4/epoch_013_val_0.823.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.8564 - accuracy: 0.7015 - val_loss: 0.8225 - val_accuracy: 0.7192\n",
      "Epoch 14/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.8268 - accuracy: 0.7123\n",
      "Epoch 00014: val_loss improved from 0.82251 to 0.80060, saving model to ./storage/writer_train_10/kfold4/epoch_014_val_0.801.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.8267 - accuracy: 0.7124 - val_loss: 0.8006 - val_accuracy: 0.7269\n",
      "Epoch 15/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.7998 - accuracy: 0.7226\n",
      "Epoch 00015: val_loss improved from 0.80060 to 0.77749, saving model to ./storage/writer_train_10/kfold4/epoch_015_val_0.777.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.7997 - accuracy: 0.7226 - val_loss: 0.7775 - val_accuracy: 0.7332\n",
      "Epoch 16/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.7747 - accuracy: 0.7320\n",
      "Epoch 00016: val_loss improved from 0.77749 to 0.76013, saving model to ./storage/writer_train_10/kfold4/epoch_016_val_0.760.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.7748 - accuracy: 0.7319 - val_loss: 0.7601 - val_accuracy: 0.7409\n",
      "Epoch 17/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.7520 - accuracy: 0.7392\n",
      "Epoch 00017: val_loss improved from 0.76013 to 0.74275, saving model to ./storage/writer_train_10/kfold4/epoch_017_val_0.743.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.7521 - accuracy: 0.7390 - val_loss: 0.7428 - val_accuracy: 0.7484\n",
      "Epoch 18/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.7310 - accuracy: 0.7457\n",
      "Epoch 00018: val_loss improved from 0.74275 to 0.72694, saving model to ./storage/writer_train_10/kfold4/epoch_018_val_0.727.h5\n",
      "98782/98782 [==============================] - 4s 45us/sample - loss: 0.7307 - accuracy: 0.7459 - val_loss: 0.7269 - val_accuracy: 0.7504\n",
      "Epoch 19/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.7113 - accuracy: 0.7521\n",
      "Epoch 00019: val_loss improved from 0.72694 to 0.71422, saving model to ./storage/writer_train_10/kfold4/epoch_019_val_0.714.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.7111 - accuracy: 0.7522 - val_loss: 0.7142 - val_accuracy: 0.7577\n",
      "Epoch 20/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.6936 - accuracy: 0.7585\n",
      "Epoch 00020: val_loss improved from 0.71422 to 0.70208, saving model to ./storage/writer_train_10/kfold4/epoch_020_val_0.702.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.6930 - accuracy: 0.7588 - val_loss: 0.7021 - val_accuracy: 0.7613\n",
      "Epoch 21/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.6754 - accuracy: 0.7647\n",
      "Epoch 00021: val_loss improved from 0.70208 to 0.69273, saving model to ./storage/writer_train_10/kfold4/epoch_021_val_0.693.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.6757 - accuracy: 0.7646 - val_loss: 0.6927 - val_accuracy: 0.7622\n",
      "Epoch 22/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.6599 - accuracy: 0.7692\n",
      "Epoch 00022: val_loss improved from 0.69273 to 0.68213, saving model to ./storage/writer_train_10/kfold4/epoch_022_val_0.682.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.6599 - accuracy: 0.7692 - val_loss: 0.6821 - val_accuracy: 0.7655\n",
      "Epoch 23/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.6449 - accuracy: 0.7739\n",
      "Epoch 00023: val_loss improved from 0.68213 to 0.67311, saving model to ./storage/writer_train_10/kfold4/epoch_023_val_0.673.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.6448 - accuracy: 0.7740 - val_loss: 0.6731 - val_accuracy: 0.7671\n",
      "Epoch 24/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.6309 - accuracy: 0.7794\n",
      "Epoch 00024: val_loss improved from 0.67311 to 0.66502, saving model to ./storage/writer_train_10/kfold4/epoch_024_val_0.665.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.6310 - accuracy: 0.7793 - val_loss: 0.6650 - val_accuracy: 0.7728\n",
      "Epoch 25/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.6175 - accuracy: 0.7839\n",
      "Epoch 00025: val_loss improved from 0.66502 to 0.65947, saving model to ./storage/writer_train_10/kfold4/epoch_025_val_0.659.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.6177 - accuracy: 0.7837 - val_loss: 0.6595 - val_accuracy: 0.7684\n",
      "Epoch 26/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.6054 - accuracy: 0.7874\n",
      "Epoch 00026: val_loss improved from 0.65947 to 0.65192, saving model to ./storage/writer_train_10/kfold4/epoch_026_val_0.652.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.6054 - accuracy: 0.7875 - val_loss: 0.6519 - val_accuracy: 0.7742\n",
      "Epoch 27/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.5930 - accuracy: 0.7913\n",
      "Epoch 00027: val_loss improved from 0.65192 to 0.64514, saving model to ./storage/writer_train_10/kfold4/epoch_027_val_0.645.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5932 - accuracy: 0.7913 - val_loss: 0.6451 - val_accuracy: 0.7766\n",
      "Epoch 28/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.5817 - accuracy: 0.7956\n",
      "Epoch 00028: val_loss improved from 0.64514 to 0.64057, saving model to ./storage/writer_train_10/kfold4/epoch_028_val_0.641.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5820 - accuracy: 0.7953 - val_loss: 0.6406 - val_accuracy: 0.7761\n",
      "Epoch 29/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.5717 - accuracy: 0.7981\n",
      "Epoch 00029: val_loss improved from 0.64057 to 0.63745, saving model to ./storage/writer_train_10/kfold4/epoch_029_val_0.637.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5713 - accuracy: 0.7982 - val_loss: 0.6374 - val_accuracy: 0.7777\n",
      "Epoch 30/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.5614 - accuracy: 0.8024\n",
      "Epoch 00030: val_loss improved from 0.63745 to 0.63261, saving model to ./storage/writer_train_10/kfold4/epoch_030_val_0.633.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5613 - accuracy: 0.8024 - val_loss: 0.6326 - val_accuracy: 0.7810\n",
      "Epoch 31/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.5520 - accuracy: 0.8045\n",
      "Epoch 00031: val_loss improved from 0.63261 to 0.62697, saving model to ./storage/writer_train_10/kfold4/epoch_031_val_0.627.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.5520 - accuracy: 0.8044 - val_loss: 0.6270 - val_accuracy: 0.7815\n",
      "Epoch 32/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.5429 - accuracy: 0.8082\n",
      "Epoch 00032: val_loss improved from 0.62697 to 0.62613, saving model to ./storage/writer_train_10/kfold4/epoch_032_val_0.626.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5428 - accuracy: 0.8081 - val_loss: 0.6261 - val_accuracy: 0.7804\n",
      "Epoch 33/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.5339 - accuracy: 0.8109\n",
      "Epoch 00033: val_loss improved from 0.62613 to 0.62338, saving model to ./storage/writer_train_10/kfold4/epoch_033_val_0.623.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5339 - accuracy: 0.8109 - val_loss: 0.6234 - val_accuracy: 0.7835\n",
      "Epoch 34/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.5254 - accuracy: 0.8142\n",
      "Epoch 00034: val_loss improved from 0.62338 to 0.61838, saving model to ./storage/writer_train_10/kfold4/epoch_034_val_0.618.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.5254 - accuracy: 0.8142 - val_loss: 0.6184 - val_accuracy: 0.7857\n",
      "Epoch 35/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.5179 - accuracy: 0.8165\n",
      "Epoch 00035: val_loss improved from 0.61838 to 0.61698, saving model to ./storage/writer_train_10/kfold4/epoch_035_val_0.617.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5174 - accuracy: 0.8167 - val_loss: 0.6170 - val_accuracy: 0.7866\n",
      "Epoch 36/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.5096 - accuracy: 0.8199\n",
      "Epoch 00036: val_loss improved from 0.61698 to 0.61576, saving model to ./storage/writer_train_10/kfold4/epoch_036_val_0.616.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5097 - accuracy: 0.8198 - val_loss: 0.6158 - val_accuracy: 0.7850\n",
      "Epoch 37/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.5025 - accuracy: 0.8218\n",
      "Epoch 00037: val_loss improved from 0.61576 to 0.61406, saving model to ./storage/writer_train_10/kfold4/epoch_037_val_0.614.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.5024 - accuracy: 0.8218 - val_loss: 0.6141 - val_accuracy: 0.7855\n",
      "Epoch 38/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4953 - accuracy: 0.8241\n",
      "Epoch 00038: val_loss improved from 0.61406 to 0.61253, saving model to ./storage/writer_train_10/kfold4/epoch_038_val_0.613.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.4955 - accuracy: 0.8240 - val_loss: 0.6125 - val_accuracy: 0.7857\n",
      "Epoch 39/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.4889 - accuracy: 0.8265\n",
      "Epoch 00039: val_loss improved from 0.61253 to 0.61125, saving model to ./storage/writer_train_10/kfold4/epoch_039_val_0.611.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.4889 - accuracy: 0.8265 - val_loss: 0.6112 - val_accuracy: 0.7864\n",
      "Epoch 40/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.4826 - accuracy: 0.8290\n",
      "Epoch 00040: val_loss improved from 0.61125 to 0.61073, saving model to ./storage/writer_train_10/kfold4/epoch_040_val_0.611.h5\n",
      "98782/98782 [==============================] - 4s 45us/sample - loss: 0.4823 - accuracy: 0.8290 - val_loss: 0.6107 - val_accuracy: 0.7864\n",
      "Epoch 41/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.4759 - accuracy: 0.8312\n",
      "Epoch 00041: val_loss improved from 0.61073 to 0.60957, saving model to ./storage/writer_train_10/kfold4/epoch_041_val_0.610.h5\n",
      "98782/98782 [==============================] - 4s 44us/sample - loss: 0.4758 - accuracy: 0.8311 - val_loss: 0.6096 - val_accuracy: 0.7877\n",
      "Epoch 42/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4703 - accuracy: 0.8328\n",
      "Epoch 00042: val_loss improved from 0.60957 to 0.60797, saving model to ./storage/writer_train_10/kfold4/epoch_042_val_0.608.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.4704 - accuracy: 0.8328 - val_loss: 0.6080 - val_accuracy: 0.7883\n",
      "Epoch 43/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4641 - accuracy: 0.8351\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0007500000356230885.\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.60797\n",
      "98782/98782 [==============================] - 4s 39us/sample - loss: 0.4640 - accuracy: 0.8350 - val_loss: 0.6128 - val_accuracy: 0.7872\n",
      "Epoch 44/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.4584 - accuracy: 0.8373\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0005625000048894435.\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.60797\n",
      "98782/98782 [==============================] - 4s 37us/sample - loss: 0.4584 - accuracy: 0.8372 - val_loss: 0.6084 - val_accuracy: 0.7875\n",
      "Epoch 45/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4542 - accuracy: 0.8387\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0004218749818392098.\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.60797\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4540 - accuracy: 0.8388 - val_loss: 0.6085 - val_accuracy: 0.7875\n",
      "Epoch 46/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.4510 - accuracy: 0.8400\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.00031640623637940735.\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.60797\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4509 - accuracy: 0.8401 - val_loss: 0.6095 - val_accuracy: 0.7886\n",
      "Epoch 47/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4486 - accuracy: 0.8413\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.00023730468819849193.\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.60797\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4486 - accuracy: 0.8412 - val_loss: 0.6090 - val_accuracy: 0.7881\n",
      "Epoch 48/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.4469 - accuracy: 0.8416\n",
      "Epoch 00048: val_loss improved from 0.60797 to 0.60785, saving model to ./storage/writer_train_10/kfold4/epoch_048_val_0.608.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.4468 - accuracy: 0.8418 - val_loss: 0.6078 - val_accuracy: 0.7899\n",
      "Epoch 49/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.4456 - accuracy: 0.8424\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.00017797851614886895.\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.60785\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4455 - accuracy: 0.8424 - val_loss: 0.6099 - val_accuracy: 0.7870\n",
      "Epoch 50/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4443 - accuracy: 0.8424\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0001334838816546835.\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.60785\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4442 - accuracy: 0.8425 - val_loss: 0.6087 - val_accuracy: 0.7890\n",
      "Epoch 51/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4435 - accuracy: 0.8430\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.00010011290578404441.\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.60785\n",
      "98782/98782 [==============================] - 4s 39us/sample - loss: 0.4433 - accuracy: 0.8431 - val_loss: 0.6093 - val_accuracy: 0.7877\n",
      "Epoch 52/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.4425 - accuracy: 0.8434\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 7.508467933803331e-05.\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.60785\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4425 - accuracy: 0.8433 - val_loss: 0.6085 - val_accuracy: 0.7895\n",
      "Epoch 53/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.4420 - accuracy: 0.8435\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 5.6313510867767036e-05.\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.60785\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4419 - accuracy: 0.8436 - val_loss: 0.6086 - val_accuracy: 0.7892\n",
      "Epoch 54/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4415 - accuracy: 0.8436\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 4.223513315082528e-05.\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.60785\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4415 - accuracy: 0.8436 - val_loss: 0.6087 - val_accuracy: 0.7886\n",
      "Epoch 55/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4410 - accuracy: 0.8441\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 3.167634986311896e-05.\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.60785\n",
      "98782/98782 [==============================] - 4s 37us/sample - loss: 0.4412 - accuracy: 0.8439 - val_loss: 0.6087 - val_accuracy: 0.7886\n",
      "Epoch 56/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.4407 - accuracy: 0.8440\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 2.3757263079460245e-05.\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.60785\n",
      "98782/98782 [==============================] - 4s 37us/sample - loss: 0.4410 - accuracy: 0.8438 - val_loss: 0.6087 - val_accuracy: 0.7888\n",
      "Epoch 57/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4409 - accuracy: 0.8439\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 1.781794799171621e-05.\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.60785\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4408 - accuracy: 0.8439 - val_loss: 0.6090 - val_accuracy: 0.7884\n",
      "Epoch 58/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.4410 - accuracy: 0.8438\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1.3363460311666131e-05.\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.60785\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4407 - accuracy: 0.8439 - val_loss: 0.6090 - val_accuracy: 0.7888\n",
      "... Iteration 5 ...\n",
      "... Preprocessing Data ... \n",
      "(98782, 256) (98782,)\n",
      "(5488, 256) (5488,)\n",
      "... Training Model by Validating on Fold 5 ...\n",
      "Train on 98782 samples, validate on 5488 samples\n",
      "Epoch 1/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 1.5605 - accuracy: 0.2729\n",
      "Epoch 00001: val_loss improved from inf to 1.53773, saving model to ./storage/writer_train_10/kfold5/epoch_001_val_1.538.h5\n",
      "98782/98782 [==============================] - 5s 49us/sample - loss: 1.5604 - accuracy: 0.2729 - val_loss: 1.5377 - val_accuracy: 0.2804\n",
      "Epoch 2/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 1.5117 - accuracy: 0.3450\n",
      "Epoch 00002: val_loss improved from 1.53773 to 1.47161, saving model to ./storage/writer_train_10/kfold5/epoch_002_val_1.472.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 1.5115 - accuracy: 0.3453 - val_loss: 1.4716 - val_accuracy: 0.4249\n",
      "Epoch 3/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 1.4360 - accuracy: 0.4427\n",
      "Epoch 00003: val_loss improved from 1.47161 to 1.37680, saving model to ./storage/writer_train_10/kfold5/epoch_003_val_1.377.h5\n",
      "98782/98782 [==============================] - 4s 44us/sample - loss: 1.4356 - accuracy: 0.4430 - val_loss: 1.3768 - val_accuracy: 0.5118\n",
      "Epoch 4/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 1.3463 - accuracy: 0.5050\n",
      "Epoch 00004: val_loss improved from 1.37680 to 1.27763, saving model to ./storage/writer_train_10/kfold5/epoch_004_val_1.278.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 1.3464 - accuracy: 0.5048 - val_loss: 1.2776 - val_accuracy: 0.5641\n",
      "Epoch 5/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 1.2607 - accuracy: 0.5485\n",
      "Epoch 00005: val_loss improved from 1.27763 to 1.18754, saving model to ./storage/writer_train_10/kfold5/epoch_005_val_1.188.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 1.2603 - accuracy: 0.5486 - val_loss: 1.1875 - val_accuracy: 0.6004\n",
      "Epoch 6/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 1.1835 - accuracy: 0.5818\n",
      "Epoch 00006: val_loss improved from 1.18754 to 1.11022, saving model to ./storage/writer_train_10/kfold5/epoch_006_val_1.110.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 1.1829 - accuracy: 0.5818 - val_loss: 1.1102 - val_accuracy: 0.6224\n",
      "Epoch 7/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 1.1157 - accuracy: 0.6055\n",
      "Epoch 00007: val_loss improved from 1.11022 to 1.04594, saving model to ./storage/writer_train_10/kfold5/epoch_007_val_1.046.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 1.1155 - accuracy: 0.6056 - val_loss: 1.0459 - val_accuracy: 0.6306\n",
      "Epoch 8/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 1.0571 - accuracy: 0.6260\n",
      "Epoch 00008: val_loss improved from 1.04594 to 0.99050, saving model to ./storage/writer_train_10/kfold5/epoch_008_val_0.991.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 1.0572 - accuracy: 0.6259 - val_loss: 0.9905 - val_accuracy: 0.6536\n",
      "Epoch 9/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 1.0067 - accuracy: 0.6443\n",
      "Epoch 00009: val_loss improved from 0.99050 to 0.94505, saving model to ./storage/writer_train_10/kfold5/epoch_009_val_0.945.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 1.0064 - accuracy: 0.6445 - val_loss: 0.9450 - val_accuracy: 0.6682\n",
      "Epoch 10/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.9620 - accuracy: 0.6592\n",
      "Epoch 00010: val_loss improved from 0.94505 to 0.90598, saving model to ./storage/writer_train_10/kfold5/epoch_010_val_0.906.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.9618 - accuracy: 0.6592 - val_loss: 0.9060 - val_accuracy: 0.6890\n",
      "Epoch 11/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.9224 - accuracy: 0.6750\n",
      "Epoch 00011: val_loss improved from 0.90598 to 0.87372, saving model to ./storage/writer_train_10/kfold5/epoch_011_val_0.874.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.9221 - accuracy: 0.6752 - val_loss: 0.8737 - val_accuracy: 0.6941\n",
      "Epoch 12/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.8871 - accuracy: 0.6889\n",
      "Epoch 00012: val_loss improved from 0.87372 to 0.84171, saving model to ./storage/writer_train_10/kfold5/epoch_012_val_0.842.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.8867 - accuracy: 0.6891 - val_loss: 0.8417 - val_accuracy: 0.7103\n",
      "Epoch 13/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.8545 - accuracy: 0.7021\n",
      "Epoch 00013: val_loss improved from 0.84171 to 0.81424, saving model to ./storage/writer_train_10/kfold5/epoch_013_val_0.814.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.8545 - accuracy: 0.7020 - val_loss: 0.8142 - val_accuracy: 0.7228\n",
      "Epoch 14/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.8253 - accuracy: 0.7118\n",
      "Epoch 00014: val_loss improved from 0.81424 to 0.79067, saving model to ./storage/writer_train_10/kfold5/epoch_014_val_0.791.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.8254 - accuracy: 0.7117 - val_loss: 0.7907 - val_accuracy: 0.7280\n",
      "Epoch 15/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.7986 - accuracy: 0.7223\n",
      "Epoch 00015: val_loss improved from 0.79067 to 0.76909, saving model to ./storage/writer_train_10/kfold5/epoch_015_val_0.769.h5\n",
      "98782/98782 [==============================] - 4s 44us/sample - loss: 0.7986 - accuracy: 0.7223 - val_loss: 0.7691 - val_accuracy: 0.7363\n",
      "Epoch 16/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.7743 - accuracy: 0.7307\n",
      "Epoch 00016: val_loss improved from 0.76909 to 0.74995, saving model to ./storage/writer_train_10/kfold5/epoch_016_val_0.750.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.7741 - accuracy: 0.7309 - val_loss: 0.7500 - val_accuracy: 0.7423\n",
      "Epoch 17/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.7517 - accuracy: 0.7385\n",
      "Epoch 00017: val_loss improved from 0.74995 to 0.73215, saving model to ./storage/writer_train_10/kfold5/epoch_017_val_0.732.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.7515 - accuracy: 0.7386 - val_loss: 0.7321 - val_accuracy: 0.7422\n",
      "Epoch 18/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.7302 - accuracy: 0.7460\n",
      "Epoch 00018: val_loss improved from 0.73215 to 0.71514, saving model to ./storage/writer_train_10/kfold5/epoch_018_val_0.715.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.7305 - accuracy: 0.7460 - val_loss: 0.7151 - val_accuracy: 0.7505\n",
      "Epoch 19/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.7111 - accuracy: 0.7521\n",
      "Epoch 00019: val_loss improved from 0.71514 to 0.70176, saving model to ./storage/writer_train_10/kfold5/epoch_019_val_0.702.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.7112 - accuracy: 0.7520 - val_loss: 0.7018 - val_accuracy: 0.7564\n",
      "Epoch 20/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.6931 - accuracy: 0.7577\n",
      "Epoch 00020: val_loss improved from 0.70176 to 0.68741, saving model to ./storage/writer_train_10/kfold5/epoch_020_val_0.687.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.6931 - accuracy: 0.7578 - val_loss: 0.6874 - val_accuracy: 0.7611\n",
      "Epoch 21/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.6761 - accuracy: 0.7640\n",
      "Epoch 00021: val_loss improved from 0.68741 to 0.67555, saving model to ./storage/writer_train_10/kfold5/epoch_021_val_0.676.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.6762 - accuracy: 0.7640 - val_loss: 0.6755 - val_accuracy: 0.7675\n",
      "Epoch 22/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.6603 - accuracy: 0.7688\n",
      "Epoch 00022: val_loss improved from 0.67555 to 0.66721, saving model to ./storage/writer_train_10/kfold5/epoch_022_val_0.667.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.6604 - accuracy: 0.7687 - val_loss: 0.6672 - val_accuracy: 0.7704\n",
      "Epoch 23/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.6454 - accuracy: 0.7747\n",
      "Epoch 00023: val_loss improved from 0.66721 to 0.65549, saving model to ./storage/writer_train_10/kfold5/epoch_023_val_0.655.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.6454 - accuracy: 0.7747 - val_loss: 0.6555 - val_accuracy: 0.7722\n",
      "Epoch 24/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.6313 - accuracy: 0.7790\n",
      "Epoch 00024: val_loss improved from 0.65549 to 0.64556, saving model to ./storage/writer_train_10/kfold5/epoch_024_val_0.646.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.6314 - accuracy: 0.7789 - val_loss: 0.6456 - val_accuracy: 0.7770\n",
      "Epoch 25/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.6182 - accuracy: 0.7836\n",
      "Epoch 00025: val_loss improved from 0.64556 to 0.63778, saving model to ./storage/writer_train_10/kfold5/epoch_025_val_0.638.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.6185 - accuracy: 0.7834 - val_loss: 0.6378 - val_accuracy: 0.7759\n",
      "Epoch 26/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.6056 - accuracy: 0.7873\n",
      "Epoch 00026: val_loss improved from 0.63778 to 0.63332, saving model to ./storage/writer_train_10/kfold5/epoch_026_val_0.633.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.6058 - accuracy: 0.7873 - val_loss: 0.6333 - val_accuracy: 0.7819\n",
      "Epoch 27/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.5943 - accuracy: 0.7907\n",
      "Epoch 00027: val_loss improved from 0.63332 to 0.62622, saving model to ./storage/writer_train_10/kfold5/epoch_027_val_0.626.h5\n",
      "98782/98782 [==============================] - 5s 47us/sample - loss: 0.5942 - accuracy: 0.7909 - val_loss: 0.6262 - val_accuracy: 0.7812\n",
      "Epoch 28/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.5830 - accuracy: 0.7950\n",
      "Epoch 00028: val_loss improved from 0.62622 to 0.61794, saving model to ./storage/writer_train_10/kfold5/epoch_028_val_0.618.h5\n",
      "98782/98782 [==============================] - 4s 46us/sample - loss: 0.5829 - accuracy: 0.7951 - val_loss: 0.6179 - val_accuracy: 0.7802\n",
      "Epoch 29/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.5728 - accuracy: 0.7986\n",
      "Epoch 00029: val_loss improved from 0.61794 to 0.61217, saving model to ./storage/writer_train_10/kfold5/epoch_029_val_0.612.h5\n",
      "98782/98782 [==============================] - 4s 44us/sample - loss: 0.5727 - accuracy: 0.7986 - val_loss: 0.6122 - val_accuracy: 0.7830\n",
      "Epoch 30/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.5627 - accuracy: 0.8022\n",
      "Epoch 00030: val_loss improved from 0.61217 to 0.60702, saving model to ./storage/writer_train_10/kfold5/epoch_030_val_0.607.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.5624 - accuracy: 0.8023 - val_loss: 0.6070 - val_accuracy: 0.7828\n",
      "Epoch 31/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.5533 - accuracy: 0.8050\n",
      "Epoch 00031: val_loss improved from 0.60702 to 0.60291, saving model to ./storage/writer_train_10/kfold5/epoch_031_val_0.603.h5\n",
      "98782/98782 [==============================] - 5s 48us/sample - loss: 0.5530 - accuracy: 0.8052 - val_loss: 0.6029 - val_accuracy: 0.7846\n",
      "Epoch 32/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.5436 - accuracy: 0.8083\n",
      "Epoch 00032: val_loss improved from 0.60291 to 0.60167, saving model to ./storage/writer_train_10/kfold5/epoch_032_val_0.602.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.5437 - accuracy: 0.8082 - val_loss: 0.6017 - val_accuracy: 0.7895\n",
      "Epoch 33/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.5351 - accuracy: 0.8115\n",
      "Epoch 00033: val_loss improved from 0.60167 to 0.59725, saving model to ./storage/writer_train_10/kfold5/epoch_033_val_0.597.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5354 - accuracy: 0.8111 - val_loss: 0.5973 - val_accuracy: 0.7897\n",
      "Epoch 34/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.5269 - accuracy: 0.8141\n",
      "Epoch 00034: val_loss improved from 0.59725 to 0.59132, saving model to ./storage/writer_train_10/kfold5/epoch_034_val_0.591.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.5271 - accuracy: 0.8139 - val_loss: 0.5913 - val_accuracy: 0.7894\n",
      "Epoch 35/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.5192 - accuracy: 0.8167\n",
      "Epoch 00035: val_loss improved from 0.59132 to 0.59005, saving model to ./storage/writer_train_10/kfold5/epoch_035_val_0.590.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5191 - accuracy: 0.8167 - val_loss: 0.5901 - val_accuracy: 0.7923\n",
      "Epoch 36/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.5111 - accuracy: 0.8199\n",
      "Epoch 00036: val_loss improved from 0.59005 to 0.58556, saving model to ./storage/writer_train_10/kfold5/epoch_036_val_0.586.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.5114 - accuracy: 0.8197 - val_loss: 0.5856 - val_accuracy: 0.7914\n",
      "Epoch 37/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.5039 - accuracy: 0.8227\n",
      "Epoch 00037: val_loss improved from 0.58556 to 0.58322, saving model to ./storage/writer_train_10/kfold5/epoch_037_val_0.583.h5\n",
      "98782/98782 [==============================] - 4s 45us/sample - loss: 0.5040 - accuracy: 0.8226 - val_loss: 0.5832 - val_accuracy: 0.7910\n",
      "Epoch 38/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4974 - accuracy: 0.8241\n",
      "Epoch 00038: val_loss improved from 0.58322 to 0.58162, saving model to ./storage/writer_train_10/kfold5/epoch_038_val_0.582.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.4975 - accuracy: 0.8241 - val_loss: 0.5816 - val_accuracy: 0.7930\n",
      "Epoch 39/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.4908 - accuracy: 0.8269\n",
      "Epoch 00039: val_loss improved from 0.58162 to 0.58143, saving model to ./storage/writer_train_10/kfold5/epoch_039_val_0.581.h5\n",
      "98782/98782 [==============================] - 5s 46us/sample - loss: 0.4906 - accuracy: 0.8270 - val_loss: 0.5814 - val_accuracy: 0.7935\n",
      "Epoch 40/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.4840 - accuracy: 0.8289\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0007500000356230885.\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.58143 to 0.58137, saving model to ./storage/writer_train_10/kfold5/epoch_040_val_0.581.h5\n",
      "98782/98782 [==============================] - 5s 46us/sample - loss: 0.4842 - accuracy: 0.8290 - val_loss: 0.5814 - val_accuracy: 0.7950\n",
      "Epoch 41/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.4778 - accuracy: 0.8314\n",
      "Epoch 00041: val_loss improved from 0.58137 to 0.57809, saving model to ./storage/writer_train_10/kfold5/epoch_041_val_0.578.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.4778 - accuracy: 0.8315 - val_loss: 0.5781 - val_accuracy: 0.7946\n",
      "Epoch 42/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4733 - accuracy: 0.8330\n",
      "Epoch 00042: val_loss improved from 0.57809 to 0.57731, saving model to ./storage/writer_train_10/kfold5/epoch_042_val_0.577.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.4733 - accuracy: 0.8330 - val_loss: 0.5773 - val_accuracy: 0.7939\n",
      "Epoch 43/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4685 - accuracy: 0.8349\n",
      "Epoch 00043: val_loss improved from 0.57731 to 0.57569, saving model to ./storage/writer_train_10/kfold5/epoch_043_val_0.576.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.4688 - accuracy: 0.8347 - val_loss: 0.5757 - val_accuracy: 0.7945\n",
      "Epoch 44/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4647 - accuracy: 0.8363\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0005625000048894435.\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.57569\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4646 - accuracy: 0.8364 - val_loss: 0.5758 - val_accuracy: 0.7948\n",
      "Epoch 45/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4601 - accuracy: 0.8380\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0004218749818392098.\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.57569\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4601 - accuracy: 0.8379 - val_loss: 0.5768 - val_accuracy: 0.7939\n",
      "Epoch 46/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.4574 - accuracy: 0.8385\n",
      "Epoch 00046: val_loss improved from 0.57569 to 0.57515, saving model to ./storage/writer_train_10/kfold5/epoch_046_val_0.575.h5\n",
      "98782/98782 [==============================] - 4s 46us/sample - loss: 0.4571 - accuracy: 0.8386 - val_loss: 0.5752 - val_accuracy: 0.7956\n",
      "Epoch 47/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.4551 - accuracy: 0.8394\n",
      "Epoch 00047: val_loss improved from 0.57515 to 0.57484, saving model to ./storage/writer_train_10/kfold5/epoch_047_val_0.575.h5\n",
      "98782/98782 [==============================] - 4s 44us/sample - loss: 0.4548 - accuracy: 0.8396 - val_loss: 0.5748 - val_accuracy: 0.7945\n",
      "Epoch 48/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.4524 - accuracy: 0.8405\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.00031640623637940735.\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.57484\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.4525 - accuracy: 0.8404 - val_loss: 0.5752 - val_accuracy: 0.7943\n",
      "Epoch 49/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4501 - accuracy: 0.8409\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.00023730468819849193.\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.57484\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.4502 - accuracy: 0.8409 - val_loss: 0.5750 - val_accuracy: 0.7943\n",
      "Epoch 50/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.4484 - accuracy: 0.8415\n",
      "Epoch 00050: val_loss improved from 0.57484 to 0.57461, saving model to ./storage/writer_train_10/kfold5/epoch_050_val_0.575.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.4484 - accuracy: 0.8416 - val_loss: 0.5746 - val_accuracy: 0.7946\n",
      "Epoch 51/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.4470 - accuracy: 0.8425\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.00017797851614886895.\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.57461\n",
      "98782/98782 [==============================] - 4s 37us/sample - loss: 0.4472 - accuracy: 0.8424 - val_loss: 0.5748 - val_accuracy: 0.7961\n",
      "Epoch 52/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4460 - accuracy: 0.8426\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.0001334838816546835.\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.57461\n",
      "98782/98782 [==============================] - 4s 37us/sample - loss: 0.4458 - accuracy: 0.8428 - val_loss: 0.5749 - val_accuracy: 0.7948\n",
      "Epoch 53/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.4446 - accuracy: 0.8434\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.00010011290578404441.\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.57461\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4448 - accuracy: 0.8433 - val_loss: 0.5750 - val_accuracy: 0.7961\n",
      "Epoch 54/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4442 - accuracy: 0.8433\n",
      "Epoch 00054: val_loss improved from 0.57461 to 0.57415, saving model to ./storage/writer_train_10/kfold5/epoch_054_val_0.574.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.4441 - accuracy: 0.8433 - val_loss: 0.5741 - val_accuracy: 0.7970\n",
      "Epoch 55/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.4434 - accuracy: 0.8435\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 7.508467933803331e-05.\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.57415\n",
      "98782/98782 [==============================] - 4s 40us/sample - loss: 0.4436 - accuracy: 0.8434 - val_loss: 0.5747 - val_accuracy: 0.7939\n",
      "Epoch 56/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.4427 - accuracy: 0.8438\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 5.6313510867767036e-05.\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.57415\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4431 - accuracy: 0.8437 - val_loss: 0.5742 - val_accuracy: 0.7950\n",
      "Epoch 57/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.4429 - accuracy: 0.8441\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 4.223513315082528e-05.\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.57415 to 0.57414, saving model to ./storage/writer_train_10/kfold5/epoch_057_val_0.574.h5\n",
      "98782/98782 [==============================] - 4s 45us/sample - loss: 0.4427 - accuracy: 0.8441 - val_loss: 0.5741 - val_accuracy: 0.7954\n",
      "Epoch 58/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4422 - accuracy: 0.8441\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 3.167634986311896e-05.\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.57414\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.4424 - accuracy: 0.8441 - val_loss: 0.5746 - val_accuracy: 0.7957\n",
      "Epoch 59/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.4417 - accuracy: 0.8443\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 2.3757263079460245e-05.\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.57414\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4421 - accuracy: 0.8442 - val_loss: 0.5746 - val_accuracy: 0.7959\n",
      "Epoch 60/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.4424 - accuracy: 0.8437\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 1.781794799171621e-05.\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.57414\n",
      "98782/98782 [==============================] - 4s 37us/sample - loss: 0.4419 - accuracy: 0.8440 - val_loss: 0.5742 - val_accuracy: 0.7957\n",
      "Epoch 61/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.4419 - accuracy: 0.8444\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 1.3363460311666131e-05.\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.57414\n",
      "98782/98782 [==============================] - 4s 37us/sample - loss: 0.4418 - accuracy: 0.8443 - val_loss: 0.5743 - val_accuracy: 0.7959\n",
      "Epoch 62/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4418 - accuracy: 0.8442\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 1.0022595233749598e-05.\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.57414\n",
      "98782/98782 [==============================] - 4s 39us/sample - loss: 0.4417 - accuracy: 0.8442 - val_loss: 0.5743 - val_accuracy: 0.7957\n",
      "Epoch 63/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.4413 - accuracy: 0.8446\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 7.516946425312199e-06.\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.57414\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4417 - accuracy: 0.8443 - val_loss: 0.5743 - val_accuracy: 0.7954\n",
      "Epoch 64/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4415 - accuracy: 0.8443\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 5.637709818984149e-06.\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.57414\n",
      "98782/98782 [==============================] - 4s 39us/sample - loss: 0.4416 - accuracy: 0.8443 - val_loss: 0.5743 - val_accuracy: 0.7957\n",
      "Epoch 65/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4414 - accuracy: 0.8444\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 4.228282364238112e-06.\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.57414\n",
      "98782/98782 [==============================] - 4s 39us/sample - loss: 0.4416 - accuracy: 0.8443 - val_loss: 0.5743 - val_accuracy: 0.7957\n",
      "Epoch 66/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.4414 - accuracy: 0.8444\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 3.1712116879134555e-06.\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.57414\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4415 - accuracy: 0.8443 - val_loss: 0.5744 - val_accuracy: 0.7957\n",
      "Epoch 67/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.4415 - accuracy: 0.8444\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 2.3784086806699634e-06.\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.57414\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4415 - accuracy: 0.8444 - val_loss: 0.5744 - val_accuracy: 0.7957\n",
      "... Iteration 6 ...\n",
      "... Preprocessing Data ... \n",
      "(98782, 256) (98782,)\n",
      "(5488, 256) (5488,)\n",
      "... Training Model by Validating on Fold 6 ...\n",
      "Train on 98782 samples, validate on 5488 samples\n",
      "Epoch 1/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 1.5618 - accuracy: 0.2742\n",
      "Epoch 00001: val_loss improved from inf to 1.53967, saving model to ./storage/writer_train_10/kfold6/epoch_001_val_1.540.h5\n",
      "98782/98782 [==============================] - 5s 47us/sample - loss: 1.5616 - accuracy: 0.2742 - val_loss: 1.5397 - val_accuracy: 0.2897\n",
      "Epoch 2/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 1.5152 - accuracy: 0.3295\n",
      "Epoch 00002: val_loss improved from 1.53967 to 1.47353, saving model to ./storage/writer_train_10/kfold6/epoch_002_val_1.474.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 1.5148 - accuracy: 0.3304 - val_loss: 1.4735 - val_accuracy: 0.4304\n",
      "Epoch 3/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 1.4396 - accuracy: 0.4354\n",
      "Epoch 00003: val_loss improved from 1.47353 to 1.37877, saving model to ./storage/writer_train_10/kfold6/epoch_003_val_1.379.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 1.4391 - accuracy: 0.4357 - val_loss: 1.3788 - val_accuracy: 0.4940\n",
      "Epoch 4/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 1.3511 - accuracy: 0.5012\n",
      "Epoch 00004: val_loss improved from 1.37877 to 1.28159, saving model to ./storage/writer_train_10/kfold6/epoch_004_val_1.282.h5\n",
      "98782/98782 [==============================] - 4s 45us/sample - loss: 1.3508 - accuracy: 0.5014 - val_loss: 1.2816 - val_accuracy: 0.5634\n",
      "Epoch 5/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 1.2665 - accuracy: 0.5465\n",
      "Epoch 00005: val_loss improved from 1.28159 to 1.19162, saving model to ./storage/writer_train_10/kfold6/epoch_005_val_1.192.h5\n",
      "98782/98782 [==============================] - 4s 45us/sample - loss: 1.2658 - accuracy: 0.5468 - val_loss: 1.1916 - val_accuracy: 0.5869\n",
      "Epoch 6/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 1.1899 - accuracy: 0.5787\n",
      "Epoch 00006: val_loss improved from 1.19162 to 1.11409, saving model to ./storage/writer_train_10/kfold6/epoch_006_val_1.114.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 1.1894 - accuracy: 0.5789 - val_loss: 1.1141 - val_accuracy: 0.6217\n",
      "Epoch 7/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 1.1226 - accuracy: 0.6040\n",
      "Epoch 00007: val_loss improved from 1.11409 to 1.04858, saving model to ./storage/writer_train_10/kfold6/epoch_007_val_1.049.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 1.1223 - accuracy: 0.6041 - val_loss: 1.0486 - val_accuracy: 0.6394\n",
      "Epoch 8/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 1.0644 - accuracy: 0.6239\n",
      "Epoch 00008: val_loss improved from 1.04858 to 0.99244, saving model to ./storage/writer_train_10/kfold6/epoch_008_val_0.992.h5\n",
      "98782/98782 [==============================] - 4s 44us/sample - loss: 1.0642 - accuracy: 0.6240 - val_loss: 0.9924 - val_accuracy: 0.6480\n",
      "Epoch 9/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 1.0130 - accuracy: 0.6416\n",
      "Epoch 00009: val_loss improved from 0.99244 to 0.94534, saving model to ./storage/writer_train_10/kfold6/epoch_009_val_0.945.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 1.0132 - accuracy: 0.6415 - val_loss: 0.9453 - val_accuracy: 0.6740\n",
      "Epoch 10/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.9688 - accuracy: 0.6581\n",
      "Epoch 00010: val_loss improved from 0.94534 to 0.90765, saving model to ./storage/writer_train_10/kfold6/epoch_010_val_0.908.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.9687 - accuracy: 0.6582 - val_loss: 0.9076 - val_accuracy: 0.6831\n",
      "Epoch 11/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.9289 - accuracy: 0.6735\n",
      "Epoch 00011: val_loss improved from 0.90765 to 0.86996, saving model to ./storage/writer_train_10/kfold6/epoch_011_val_0.870.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.9291 - accuracy: 0.6733 - val_loss: 0.8700 - val_accuracy: 0.6959\n",
      "Epoch 12/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.8938 - accuracy: 0.6868\n",
      "Epoch 00012: val_loss improved from 0.86996 to 0.83901, saving model to ./storage/writer_train_10/kfold6/epoch_012_val_0.839.h5\n",
      "98782/98782 [==============================] - 4s 44us/sample - loss: 0.8937 - accuracy: 0.6868 - val_loss: 0.8390 - val_accuracy: 0.7043\n",
      "Epoch 13/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.8615 - accuracy: 0.6995\n",
      "Epoch 00013: val_loss improved from 0.83901 to 0.81173, saving model to ./storage/writer_train_10/kfold6/epoch_013_val_0.812.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.8615 - accuracy: 0.6995 - val_loss: 0.8117 - val_accuracy: 0.7212\n",
      "Epoch 14/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.8326 - accuracy: 0.7102\n",
      "Epoch 00014: val_loss improved from 0.81173 to 0.78650, saving model to ./storage/writer_train_10/kfold6/epoch_014_val_0.786.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.8322 - accuracy: 0.7104 - val_loss: 0.7865 - val_accuracy: 0.7270\n",
      "Epoch 15/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.8057 - accuracy: 0.7201\n",
      "Epoch 00015: val_loss improved from 0.78650 to 0.76299, saving model to ./storage/writer_train_10/kfold6/epoch_015_val_0.763.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.8057 - accuracy: 0.7201 - val_loss: 0.7630 - val_accuracy: 0.7363\n",
      "Epoch 16/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.7813 - accuracy: 0.7283\n",
      "Epoch 00016: val_loss improved from 0.76299 to 0.74335, saving model to ./storage/writer_train_10/kfold6/epoch_016_val_0.743.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.7812 - accuracy: 0.7285 - val_loss: 0.7433 - val_accuracy: 0.7425\n",
      "Epoch 17/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.7588 - accuracy: 0.7359\n",
      "Epoch 00017: val_loss improved from 0.74335 to 0.72568, saving model to ./storage/writer_train_10/kfold6/epoch_017_val_0.726.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.7586 - accuracy: 0.7360 - val_loss: 0.7257 - val_accuracy: 0.7549\n",
      "Epoch 18/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.7380 - accuracy: 0.7441\n",
      "Epoch 00018: val_loss improved from 0.72568 to 0.71069, saving model to ./storage/writer_train_10/kfold6/epoch_018_val_0.711.h5\n",
      "98782/98782 [==============================] - 4s 45us/sample - loss: 0.7378 - accuracy: 0.7440 - val_loss: 0.7107 - val_accuracy: 0.7564\n",
      "Epoch 19/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.7179 - accuracy: 0.7501\n",
      "Epoch 00019: val_loss improved from 0.71069 to 0.69519, saving model to ./storage/writer_train_10/kfold6/epoch_019_val_0.695.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.7183 - accuracy: 0.7501 - val_loss: 0.6952 - val_accuracy: 0.7648\n",
      "Epoch 20/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.7004 - accuracy: 0.7567\n",
      "Epoch 00020: val_loss improved from 0.69519 to 0.68214, saving model to ./storage/writer_train_10/kfold6/epoch_020_val_0.682.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.7004 - accuracy: 0.7567 - val_loss: 0.6821 - val_accuracy: 0.7657\n",
      "Epoch 21/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.6831 - accuracy: 0.7619\n",
      "Epoch 00021: val_loss improved from 0.68214 to 0.67484, saving model to ./storage/writer_train_10/kfold6/epoch_021_val_0.675.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.6834 - accuracy: 0.7617 - val_loss: 0.6748 - val_accuracy: 0.7659\n",
      "Epoch 22/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.6680 - accuracy: 0.7672\n",
      "Epoch 00022: val_loss improved from 0.67484 to 0.65942, saving model to ./storage/writer_train_10/kfold6/epoch_022_val_0.659.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.6679 - accuracy: 0.7673 - val_loss: 0.6594 - val_accuracy: 0.7726\n",
      "Epoch 23/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.6531 - accuracy: 0.7726\n",
      "Epoch 00023: val_loss improved from 0.65942 to 0.65441, saving model to ./storage/writer_train_10/kfold6/epoch_023_val_0.654.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.6529 - accuracy: 0.7726 - val_loss: 0.6544 - val_accuracy: 0.7742\n",
      "Epoch 24/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.6393 - accuracy: 0.7767\n",
      "Epoch 00024: val_loss improved from 0.65441 to 0.64471, saving model to ./storage/writer_train_10/kfold6/epoch_024_val_0.645.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.6393 - accuracy: 0.7765 - val_loss: 0.6447 - val_accuracy: 0.7726\n",
      "Epoch 25/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.6260 - accuracy: 0.7806\n",
      "Epoch 00025: val_loss improved from 0.64471 to 0.63381, saving model to ./storage/writer_train_10/kfold6/epoch_025_val_0.634.h5\n",
      "98782/98782 [==============================] - 4s 44us/sample - loss: 0.6260 - accuracy: 0.7807 - val_loss: 0.6338 - val_accuracy: 0.7782\n",
      "Epoch 26/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.6132 - accuracy: 0.7852\n",
      "Epoch 00026: val_loss improved from 0.63381 to 0.62720, saving model to ./storage/writer_train_10/kfold6/epoch_026_val_0.627.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.6136 - accuracy: 0.7848 - val_loss: 0.6272 - val_accuracy: 0.7788\n",
      "Epoch 27/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.6026 - accuracy: 0.7892\n",
      "Epoch 00027: val_loss improved from 0.62720 to 0.61983, saving model to ./storage/writer_train_10/kfold6/epoch_027_val_0.620.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.6021 - accuracy: 0.7893 - val_loss: 0.6198 - val_accuracy: 0.7823\n",
      "Epoch 28/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.5908 - accuracy: 0.7926\n",
      "Epoch 00028: val_loss improved from 0.61983 to 0.61388, saving model to ./storage/writer_train_10/kfold6/epoch_028_val_0.614.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5907 - accuracy: 0.7925 - val_loss: 0.6139 - val_accuracy: 0.7841\n",
      "Epoch 29/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.5806 - accuracy: 0.7961\n",
      "Epoch 00029: val_loss improved from 0.61388 to 0.60853, saving model to ./storage/writer_train_10/kfold6/epoch_029_val_0.609.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5804 - accuracy: 0.7961 - val_loss: 0.6085 - val_accuracy: 0.7859\n",
      "Epoch 30/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.5703 - accuracy: 0.7993\n",
      "Epoch 00030: val_loss improved from 0.60853 to 0.60361, saving model to ./storage/writer_train_10/kfold6/epoch_030_val_0.604.h5\n",
      "98782/98782 [==============================] - 5s 46us/sample - loss: 0.5703 - accuracy: 0.7993 - val_loss: 0.6036 - val_accuracy: 0.7844\n",
      "Epoch 31/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.5607 - accuracy: 0.8023\n",
      "Epoch 00031: val_loss improved from 0.60361 to 0.59910, saving model to ./storage/writer_train_10/kfold6/epoch_031_val_0.599.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5608 - accuracy: 0.8023 - val_loss: 0.5991 - val_accuracy: 0.7870\n",
      "Epoch 32/250\n",
      "97024/98782 [============================>.] - ETA: 0s - loss: 0.5523 - accuracy: 0.8055\n",
      "Epoch 00032: val_loss improved from 0.59910 to 0.59735, saving model to ./storage/writer_train_10/kfold6/epoch_032_val_0.597.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5518 - accuracy: 0.8058 - val_loss: 0.5973 - val_accuracy: 0.7850\n",
      "Epoch 33/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.5429 - accuracy: 0.8080\n",
      "Epoch 00033: val_loss improved from 0.59735 to 0.59082, saving model to ./storage/writer_train_10/kfold6/epoch_033_val_0.591.h5\n",
      "98782/98782 [==============================] - 4s 44us/sample - loss: 0.5431 - accuracy: 0.8080 - val_loss: 0.5908 - val_accuracy: 0.7905\n",
      "Epoch 34/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.5346 - accuracy: 0.8113\n",
      "Epoch 00034: val_loss improved from 0.59082 to 0.58810, saving model to ./storage/writer_train_10/kfold6/epoch_034_val_0.588.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5345 - accuracy: 0.8113 - val_loss: 0.5881 - val_accuracy: 0.7892\n",
      "Epoch 35/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.5270 - accuracy: 0.8141\n",
      "Epoch 00035: val_loss improved from 0.58810 to 0.58629, saving model to ./storage/writer_train_10/kfold6/epoch_035_val_0.586.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5269 - accuracy: 0.8141 - val_loss: 0.5863 - val_accuracy: 0.7910\n",
      "Epoch 36/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.5194 - accuracy: 0.8167\n",
      "Epoch 00036: val_loss improved from 0.58629 to 0.58313, saving model to ./storage/writer_train_10/kfold6/epoch_036_val_0.583.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5192 - accuracy: 0.8167 - val_loss: 0.5831 - val_accuracy: 0.7921\n",
      "Epoch 37/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.5120 - accuracy: 0.8197\n",
      "Epoch 00037: val_loss improved from 0.58313 to 0.58179, saving model to ./storage/writer_train_10/kfold6/epoch_037_val_0.582.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.5118 - accuracy: 0.8198 - val_loss: 0.5818 - val_accuracy: 0.7894\n",
      "Epoch 38/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.5052 - accuracy: 0.8212\n",
      "Epoch 00038: val_loss improved from 0.58179 to 0.57808, saving model to ./storage/writer_train_10/kfold6/epoch_038_val_0.578.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5050 - accuracy: 0.8213 - val_loss: 0.5781 - val_accuracy: 0.7932\n",
      "Epoch 39/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4981 - accuracy: 0.8239\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0007500000356230885.\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.57808\n",
      "98782/98782 [==============================] - 4s 37us/sample - loss: 0.4982 - accuracy: 0.8239 - val_loss: 0.5781 - val_accuracy: 0.7935\n",
      "Epoch 40/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.4915 - accuracy: 0.8266\n",
      "Epoch 00040: val_loss improved from 0.57808 to 0.57619, saving model to ./storage/writer_train_10/kfold6/epoch_040_val_0.576.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.4917 - accuracy: 0.8266 - val_loss: 0.5762 - val_accuracy: 0.7948\n",
      "Epoch 41/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4873 - accuracy: 0.8274\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0005625000048894435.\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.57619 to 0.57617, saving model to ./storage/writer_train_10/kfold6/epoch_041_val_0.576.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.4870 - accuracy: 0.8276 - val_loss: 0.5762 - val_accuracy: 0.7943\n",
      "Epoch 42/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.4823 - accuracy: 0.8289\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0004218749818392098.\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.57617\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4826 - accuracy: 0.8288 - val_loss: 0.5762 - val_accuracy: 0.7935\n",
      "Epoch 43/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.4789 - accuracy: 0.8306\n",
      "Epoch 00043: val_loss improved from 0.57617 to 0.57327, saving model to ./storage/writer_train_10/kfold6/epoch_043_val_0.573.h5\n",
      "98782/98782 [==============================] - 4s 44us/sample - loss: 0.4789 - accuracy: 0.8306 - val_loss: 0.5733 - val_accuracy: 0.7961\n",
      "Epoch 44/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.4763 - accuracy: 0.8317\n",
      "Epoch 00044: val_loss improved from 0.57327 to 0.57287, saving model to ./storage/writer_train_10/kfold6/epoch_044_val_0.573.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.4764 - accuracy: 0.8316 - val_loss: 0.5729 - val_accuracy: 0.7965\n",
      "Epoch 45/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4740 - accuracy: 0.8320\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.00031640623637940735.\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.57287\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4739 - accuracy: 0.8321 - val_loss: 0.5732 - val_accuracy: 0.7963\n",
      "Epoch 46/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.4712 - accuracy: 0.8336\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.00023730468819849193.\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.57287\n",
      "98782/98782 [==============================] - 4s 37us/sample - loss: 0.4715 - accuracy: 0.8334 - val_loss: 0.5732 - val_accuracy: 0.7963\n",
      "Epoch 47/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.4694 - accuracy: 0.8339\n",
      "Epoch 00047: val_loss improved from 0.57287 to 0.57229, saving model to ./storage/writer_train_10/kfold6/epoch_047_val_0.572.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.4695 - accuracy: 0.8339 - val_loss: 0.5723 - val_accuracy: 0.7961\n",
      "Epoch 48/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4683 - accuracy: 0.8343\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.00017797851614886895.\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.57229 to 0.57220, saving model to ./storage/writer_train_10/kfold6/epoch_048_val_0.572.h5\n",
      "98782/98782 [==============================] - 4s 45us/sample - loss: 0.4681 - accuracy: 0.8344 - val_loss: 0.5722 - val_accuracy: 0.7963\n",
      "Epoch 49/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4668 - accuracy: 0.8350\n",
      "Epoch 00049: val_loss improved from 0.57220 to 0.57195, saving model to ./storage/writer_train_10/kfold6/epoch_049_val_0.572.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.4667 - accuracy: 0.8351 - val_loss: 0.5719 - val_accuracy: 0.7970\n",
      "Epoch 50/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.4656 - accuracy: 0.8353\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0001334838816546835.\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.57195\n",
      "98782/98782 [==============================] - 4s 37us/sample - loss: 0.4657 - accuracy: 0.8352 - val_loss: 0.5724 - val_accuracy: 0.7968\n",
      "Epoch 51/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4645 - accuracy: 0.8358\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.00010011290578404441.\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.57195\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4648 - accuracy: 0.8357 - val_loss: 0.5724 - val_accuracy: 0.7970\n",
      "Epoch 52/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4639 - accuracy: 0.8361\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 7.508467933803331e-05.\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.57195\n",
      "98782/98782 [==============================] - 4s 39us/sample - loss: 0.4639 - accuracy: 0.8361 - val_loss: 0.5725 - val_accuracy: 0.7966\n",
      "Epoch 53/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.4633 - accuracy: 0.8363\n",
      "Epoch 00053: val_loss improved from 0.57195 to 0.57158, saving model to ./storage/writer_train_10/kfold6/epoch_053_val_0.572.h5\n",
      "98782/98782 [==============================] - 4s 45us/sample - loss: 0.4633 - accuracy: 0.8363 - val_loss: 0.5716 - val_accuracy: 0.7972\n",
      "Epoch 54/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.4631 - accuracy: 0.8364\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 5.6313510867767036e-05.\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.57158\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4629 - accuracy: 0.8362 - val_loss: 0.5719 - val_accuracy: 0.7977\n",
      "Epoch 55/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.4625 - accuracy: 0.8363\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 4.223513315082528e-05.\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.57158 to 0.57158, saving model to ./storage/writer_train_10/kfold6/epoch_055_val_0.572.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.4625 - accuracy: 0.8363 - val_loss: 0.5716 - val_accuracy: 0.7979\n",
      "Epoch 56/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.4622 - accuracy: 0.8365\n",
      "Epoch 00056: val_loss improved from 0.57158 to 0.57117, saving model to ./storage/writer_train_10/kfold6/epoch_056_val_0.571.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.4621 - accuracy: 0.8365 - val_loss: 0.5712 - val_accuracy: 0.7974\n",
      "Epoch 57/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.4620 - accuracy: 0.8363\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 3.167634986311896e-05.\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.57117\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4619 - accuracy: 0.8363 - val_loss: 0.5715 - val_accuracy: 0.7976\n",
      "Epoch 58/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4617 - accuracy: 0.8369\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 2.3757263079460245e-05.\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.57117\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4617 - accuracy: 0.8369 - val_loss: 0.5715 - val_accuracy: 0.7970\n",
      "Epoch 59/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.4612 - accuracy: 0.8371\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 1.781794799171621e-05.\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.57117\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4615 - accuracy: 0.8369 - val_loss: 0.5717 - val_accuracy: 0.7972\n",
      "Epoch 60/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.4617 - accuracy: 0.8368\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 1.3363460311666131e-05.\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.57117\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4614 - accuracy: 0.8369 - val_loss: 0.5716 - val_accuracy: 0.7970\n",
      "Epoch 61/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.4613 - accuracy: 0.8370\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 1.0022595233749598e-05.\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.57117\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4612 - accuracy: 0.8368 - val_loss: 0.5715 - val_accuracy: 0.7970\n",
      "Epoch 62/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.4614 - accuracy: 0.8367\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 7.516946425312199e-06.\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.57117\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4612 - accuracy: 0.8369 - val_loss: 0.5714 - val_accuracy: 0.7972\n",
      "Epoch 63/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.4610 - accuracy: 0.8370\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 5.637709818984149e-06.\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.57117\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4611 - accuracy: 0.8370 - val_loss: 0.5715 - val_accuracy: 0.7970\n",
      "Epoch 64/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.4607 - accuracy: 0.8371\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 4.228282364238112e-06.\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.57117\n",
      "98782/98782 [==============================] - 4s 37us/sample - loss: 0.4611 - accuracy: 0.8370 - val_loss: 0.5714 - val_accuracy: 0.7972\n",
      "Epoch 65/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4611 - accuracy: 0.8368\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 3.1712116879134555e-06.\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.57117\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4610 - accuracy: 0.8369 - val_loss: 0.5715 - val_accuracy: 0.7974\n",
      "Epoch 66/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.4610 - accuracy: 0.8368\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 2.3784086806699634e-06.\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.57117\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4610 - accuracy: 0.8369 - val_loss: 0.5715 - val_accuracy: 0.7974\n",
      "... Iteration 7 ...\n",
      "... Preprocessing Data ... \n",
      "(98782, 256) (98782,)\n",
      "(5488, 256) (5488,)\n",
      "... Training Model by Validating on Fold 7 ...\n",
      "Train on 98782 samples, validate on 5488 samples\n",
      "Epoch 1/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 1.5626 - accuracy: 0.2728\n",
      "Epoch 00001: val_loss improved from inf to 1.53982, saving model to ./storage/writer_train_10/kfold7/epoch_001_val_1.540.h5\n",
      "98782/98782 [==============================] - 5s 48us/sample - loss: 1.5626 - accuracy: 0.2728 - val_loss: 1.5398 - val_accuracy: 0.2844\n",
      "Epoch 2/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 1.5165 - accuracy: 0.3314\n",
      "Epoch 00002: val_loss improved from 1.53982 to 1.47807, saving model to ./storage/writer_train_10/kfold7/epoch_002_val_1.478.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 1.5164 - accuracy: 0.3315 - val_loss: 1.4781 - val_accuracy: 0.3978\n",
      "Epoch 3/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 1.4439 - accuracy: 0.4351\n",
      "Epoch 00003: val_loss improved from 1.47807 to 1.38862, saving model to ./storage/writer_train_10/kfold7/epoch_003_val_1.389.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 1.4430 - accuracy: 0.4359 - val_loss: 1.3886 - val_accuracy: 0.4887\n",
      "Epoch 4/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 1.3557 - accuracy: 0.4999\n",
      "Epoch 00004: val_loss improved from 1.38862 to 1.29512, saving model to ./storage/writer_train_10/kfold7/epoch_004_val_1.295.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 1.3552 - accuracy: 0.5002 - val_loss: 1.2951 - val_accuracy: 0.5417\n",
      "Epoch 5/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 1.2699 - accuracy: 0.5421\n",
      "Epoch 00005: val_loss improved from 1.29512 to 1.20836, saving model to ./storage/writer_train_10/kfold7/epoch_005_val_1.208.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 1.2697 - accuracy: 0.5422 - val_loss: 1.2084 - val_accuracy: 0.5678\n",
      "Epoch 6/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 1.1928 - accuracy: 0.5745\n",
      "Epoch 00006: val_loss improved from 1.20836 to 1.13325, saving model to ./storage/writer_train_10/kfold7/epoch_006_val_1.133.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 1.1926 - accuracy: 0.5744 - val_loss: 1.1333 - val_accuracy: 0.5951\n",
      "Epoch 7/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 1.1254 - accuracy: 0.5990\n",
      "Epoch 00007: val_loss improved from 1.13325 to 1.07097, saving model to ./storage/writer_train_10/kfold7/epoch_007_val_1.071.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 1.1251 - accuracy: 0.5992 - val_loss: 1.0710 - val_accuracy: 0.6279\n",
      "Epoch 8/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 1.0659 - accuracy: 0.6212\n",
      "Epoch 00008: val_loss improved from 1.07097 to 1.01616, saving model to ./storage/writer_train_10/kfold7/epoch_008_val_1.016.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 1.0659 - accuracy: 0.6211 - val_loss: 1.0162 - val_accuracy: 0.6416\n",
      "Epoch 9/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 1.0145 - accuracy: 0.6408\n",
      "Epoch 00009: val_loss improved from 1.01616 to 0.96880, saving model to ./storage/writer_train_10/kfold7/epoch_009_val_0.969.h5\n",
      "98782/98782 [==============================] - 5s 46us/sample - loss: 1.0142 - accuracy: 0.6411 - val_loss: 0.9688 - val_accuracy: 0.6640\n",
      "Epoch 10/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.9690 - accuracy: 0.6584\n",
      "Epoch 00010: val_loss improved from 0.96880 to 0.92909, saving model to ./storage/writer_train_10/kfold7/epoch_010_val_0.929.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.9685 - accuracy: 0.6588 - val_loss: 0.9291 - val_accuracy: 0.6749\n",
      "Epoch 11/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.9278 - accuracy: 0.6738\n",
      "Epoch 00011: val_loss improved from 0.92909 to 0.89415, saving model to ./storage/writer_train_10/kfold7/epoch_011_val_0.894.h5\n",
      "98782/98782 [==============================] - 4s 44us/sample - loss: 0.9278 - accuracy: 0.6738 - val_loss: 0.8941 - val_accuracy: 0.6859\n",
      "Epoch 12/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.8917 - accuracy: 0.6878\n",
      "Epoch 00012: val_loss improved from 0.89415 to 0.86472, saving model to ./storage/writer_train_10/kfold7/epoch_012_val_0.865.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.8916 - accuracy: 0.6880 - val_loss: 0.8647 - val_accuracy: 0.6968\n",
      "Epoch 13/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.8590 - accuracy: 0.7009\n",
      "Epoch 00013: val_loss improved from 0.86472 to 0.83688, saving model to ./storage/writer_train_10/kfold7/epoch_013_val_0.837.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.8588 - accuracy: 0.7011 - val_loss: 0.8369 - val_accuracy: 0.7105\n",
      "Epoch 14/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.8293 - accuracy: 0.7115\n",
      "Epoch 00014: val_loss improved from 0.83688 to 0.81367, saving model to ./storage/writer_train_10/kfold7/epoch_014_val_0.814.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.8292 - accuracy: 0.7116 - val_loss: 0.8137 - val_accuracy: 0.7205\n",
      "Epoch 15/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.8025 - accuracy: 0.7210\n",
      "Epoch 00015: val_loss improved from 0.81367 to 0.79259, saving model to ./storage/writer_train_10/kfold7/epoch_015_val_0.793.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.8022 - accuracy: 0.7208 - val_loss: 0.7926 - val_accuracy: 0.7176\n",
      "Epoch 16/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.7776 - accuracy: 0.7304\n",
      "Epoch 00016: val_loss improved from 0.79259 to 0.77356, saving model to ./storage/writer_train_10/kfold7/epoch_016_val_0.774.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.7775 - accuracy: 0.7304 - val_loss: 0.7736 - val_accuracy: 0.7290\n",
      "Epoch 17/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.7547 - accuracy: 0.7379\n",
      "Epoch 00017: val_loss improved from 0.77356 to 0.75863, saving model to ./storage/writer_train_10/kfold7/epoch_017_val_0.759.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.7545 - accuracy: 0.7379 - val_loss: 0.7586 - val_accuracy: 0.7374\n",
      "Epoch 18/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.7332 - accuracy: 0.7452\n",
      "Epoch 00018: val_loss improved from 0.75863 to 0.74290, saving model to ./storage/writer_train_10/kfold7/epoch_018_val_0.743.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.7333 - accuracy: 0.7452 - val_loss: 0.7429 - val_accuracy: 0.7414\n",
      "Epoch 19/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.7139 - accuracy: 0.7521\n",
      "Epoch 00019: val_loss improved from 0.74290 to 0.72789, saving model to ./storage/writer_train_10/kfold7/epoch_019_val_0.728.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.7142 - accuracy: 0.7519 - val_loss: 0.7279 - val_accuracy: 0.7423\n",
      "Epoch 20/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.6958 - accuracy: 0.7582\n",
      "Epoch 00020: val_loss improved from 0.72789 to 0.71602, saving model to ./storage/writer_train_10/kfold7/epoch_020_val_0.716.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.6959 - accuracy: 0.7580 - val_loss: 0.7160 - val_accuracy: 0.7453\n",
      "Epoch 21/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.6786 - accuracy: 0.7640\n",
      "Epoch 00021: val_loss improved from 0.71602 to 0.70732, saving model to ./storage/writer_train_10/kfold7/epoch_021_val_0.707.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.6787 - accuracy: 0.7639 - val_loss: 0.7073 - val_accuracy: 0.7509\n",
      "Epoch 22/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.6630 - accuracy: 0.7689\n",
      "Epoch 00022: val_loss improved from 0.70732 to 0.69695, saving model to ./storage/writer_train_10/kfold7/epoch_022_val_0.697.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.6629 - accuracy: 0.7689 - val_loss: 0.6970 - val_accuracy: 0.7526\n",
      "Epoch 23/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.6482 - accuracy: 0.7736\n",
      "Epoch 00023: val_loss improved from 0.69695 to 0.68719, saving model to ./storage/writer_train_10/kfold7/epoch_023_val_0.687.h5\n",
      "98782/98782 [==============================] - 4s 45us/sample - loss: 0.6483 - accuracy: 0.7736 - val_loss: 0.6872 - val_accuracy: 0.7562\n",
      "Epoch 24/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.6348 - accuracy: 0.7776\n",
      "Epoch 00024: val_loss improved from 0.68719 to 0.67972, saving model to ./storage/writer_train_10/kfold7/epoch_024_val_0.680.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.6343 - accuracy: 0.7777 - val_loss: 0.6797 - val_accuracy: 0.7589\n",
      "Epoch 25/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.6214 - accuracy: 0.7828\n",
      "Epoch 00025: val_loss improved from 0.67972 to 0.67345, saving model to ./storage/writer_train_10/kfold7/epoch_025_val_0.673.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.6212 - accuracy: 0.7829 - val_loss: 0.6734 - val_accuracy: 0.7615\n",
      "Epoch 26/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.6086 - accuracy: 0.7871\n",
      "Epoch 00026: val_loss improved from 0.67345 to 0.66666, saving model to ./storage/writer_train_10/kfold7/epoch_026_val_0.667.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.6089 - accuracy: 0.7870 - val_loss: 0.6667 - val_accuracy: 0.7604\n",
      "Epoch 27/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.5968 - accuracy: 0.7910\n",
      "Epoch 00027: val_loss improved from 0.66666 to 0.65918, saving model to ./storage/writer_train_10/kfold7/epoch_027_val_0.659.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.5970 - accuracy: 0.7909 - val_loss: 0.6592 - val_accuracy: 0.7646\n",
      "Epoch 28/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.5862 - accuracy: 0.7950\n",
      "Epoch 00028: val_loss improved from 0.65918 to 0.65350, saving model to ./storage/writer_train_10/kfold7/epoch_028_val_0.654.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.5863 - accuracy: 0.7950 - val_loss: 0.6535 - val_accuracy: 0.7668\n",
      "Epoch 29/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.5751 - accuracy: 0.7987\n",
      "Epoch 00029: val_loss improved from 0.65350 to 0.64854, saving model to ./storage/writer_train_10/kfold7/epoch_029_val_0.649.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5751 - accuracy: 0.7988 - val_loss: 0.6485 - val_accuracy: 0.7657\n",
      "Epoch 30/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.5650 - accuracy: 0.8013\n",
      "Epoch 00030: val_loss improved from 0.64854 to 0.64586, saving model to ./storage/writer_train_10/kfold7/epoch_030_val_0.646.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.5654 - accuracy: 0.8010 - val_loss: 0.6459 - val_accuracy: 0.7675\n",
      "Epoch 31/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.5560 - accuracy: 0.8041\n",
      "Epoch 00031: val_loss improved from 0.64586 to 0.64269, saving model to ./storage/writer_train_10/kfold7/epoch_031_val_0.643.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.5559 - accuracy: 0.8041 - val_loss: 0.6427 - val_accuracy: 0.7704\n",
      "Epoch 32/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.5470 - accuracy: 0.8069\n",
      "Epoch 00032: val_loss improved from 0.64269 to 0.64168, saving model to ./storage/writer_train_10/kfold7/epoch_032_val_0.642.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5467 - accuracy: 0.8071 - val_loss: 0.6417 - val_accuracy: 0.7693\n",
      "Epoch 33/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.5377 - accuracy: 0.8102\n",
      "Epoch 00033: val_loss improved from 0.64168 to 0.63734, saving model to ./storage/writer_train_10/kfold7/epoch_033_val_0.637.h5\n",
      "98782/98782 [==============================] - 4s 44us/sample - loss: 0.5382 - accuracy: 0.8102 - val_loss: 0.6373 - val_accuracy: 0.7706\n",
      "Epoch 34/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.5301 - accuracy: 0.8128\n",
      "Epoch 00034: val_loss improved from 0.63734 to 0.63356, saving model to ./storage/writer_train_10/kfold7/epoch_034_val_0.634.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.5299 - accuracy: 0.8128 - val_loss: 0.6336 - val_accuracy: 0.7697\n",
      "Epoch 35/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.5220 - accuracy: 0.8157\n",
      "Epoch 00035: val_loss improved from 0.63356 to 0.63094, saving model to ./storage/writer_train_10/kfold7/epoch_035_val_0.631.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.5220 - accuracy: 0.8157 - val_loss: 0.6309 - val_accuracy: 0.7739\n",
      "Epoch 36/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.5142 - accuracy: 0.8185\n",
      "Epoch 00036: val_loss improved from 0.63094 to 0.62853, saving model to ./storage/writer_train_10/kfold7/epoch_036_val_0.629.h5\n",
      "98782/98782 [==============================] - 4s 44us/sample - loss: 0.5145 - accuracy: 0.8184 - val_loss: 0.6285 - val_accuracy: 0.7730\n",
      "Epoch 37/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.5072 - accuracy: 0.8212\n",
      "Epoch 00037: val_loss improved from 0.62853 to 0.62704, saving model to ./storage/writer_train_10/kfold7/epoch_037_val_0.627.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.5071 - accuracy: 0.8211 - val_loss: 0.6270 - val_accuracy: 0.7753\n",
      "Epoch 38/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.5000 - accuracy: 0.8231\n",
      "Epoch 00038: val_loss improved from 0.62704 to 0.62410, saving model to ./storage/writer_train_10/kfold7/epoch_038_val_0.624.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5000 - accuracy: 0.8232 - val_loss: 0.6241 - val_accuracy: 0.7777\n",
      "Epoch 39/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4937 - accuracy: 0.8255\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0007500000356230885.\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.62410\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4937 - accuracy: 0.8255 - val_loss: 0.6247 - val_accuracy: 0.7757\n",
      "Epoch 40/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.4871 - accuracy: 0.8280\n",
      "Epoch 00040: val_loss improved from 0.62410 to 0.62284, saving model to ./storage/writer_train_10/kfold7/epoch_040_val_0.623.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.4871 - accuracy: 0.8280 - val_loss: 0.6228 - val_accuracy: 0.7781\n",
      "Epoch 41/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4822 - accuracy: 0.8291\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0005625000048894435.\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.62284\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4822 - accuracy: 0.8291 - val_loss: 0.6245 - val_accuracy: 0.7773\n",
      "Epoch 42/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4774 - accuracy: 0.8311\n",
      "Epoch 00042: val_loss improved from 0.62284 to 0.62209, saving model to ./storage/writer_train_10/kfold7/epoch_042_val_0.622.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.4776 - accuracy: 0.8310 - val_loss: 0.6221 - val_accuracy: 0.7786\n",
      "Epoch 43/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4742 - accuracy: 0.8320\n",
      "Epoch 00043: val_loss improved from 0.62209 to 0.62117, saving model to ./storage/writer_train_10/kfold7/epoch_043_val_0.621.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.4743 - accuracy: 0.8319 - val_loss: 0.6212 - val_accuracy: 0.7781\n",
      "Epoch 44/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4710 - accuracy: 0.8335\n",
      "Epoch 00044: val_loss improved from 0.62117 to 0.62020, saving model to ./storage/writer_train_10/kfold7/epoch_044_val_0.620.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.4709 - accuracy: 0.8336 - val_loss: 0.6202 - val_accuracy: 0.7786\n",
      "Epoch 45/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.4682 - accuracy: 0.8339\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0004218749818392098.\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.62020\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4678 - accuracy: 0.8340 - val_loss: 0.6217 - val_accuracy: 0.7793\n",
      "Epoch 46/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.4644 - accuracy: 0.8356\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.00031640623637940735.\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.62020\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4644 - accuracy: 0.8355 - val_loss: 0.6216 - val_accuracy: 0.7793\n",
      "Epoch 47/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4619 - accuracy: 0.8364\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.00023730468819849193.\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.62020 to 0.62015, saving model to ./storage/writer_train_10/kfold7/epoch_047_val_0.620.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.4619 - accuracy: 0.8367 - val_loss: 0.6201 - val_accuracy: 0.7788\n",
      "Epoch 48/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.4608 - accuracy: 0.8369\n",
      "Epoch 00048: val_loss improved from 0.62015 to 0.61994, saving model to ./storage/writer_train_10/kfold7/epoch_048_val_0.620.h5\n",
      "98782/98782 [==============================] - 4s 44us/sample - loss: 0.4603 - accuracy: 0.8370 - val_loss: 0.6199 - val_accuracy: 0.7792\n",
      "Epoch 49/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.4591 - accuracy: 0.8377\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.00017797851614886895.\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.61994\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4588 - accuracy: 0.8378 - val_loss: 0.6209 - val_accuracy: 0.7781\n",
      "Epoch 50/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.4577 - accuracy: 0.8384\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0001334838816546835.\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.61994\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4575 - accuracy: 0.8384 - val_loss: 0.6200 - val_accuracy: 0.7801\n",
      "Epoch 51/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.4566 - accuracy: 0.8386\n",
      "Epoch 00051: val_loss improved from 0.61994 to 0.61975, saving model to ./storage/writer_train_10/kfold7/epoch_051_val_0.620.h5\n",
      "98782/98782 [==============================] - 4s 45us/sample - loss: 0.4565 - accuracy: 0.8388 - val_loss: 0.6198 - val_accuracy: 0.7786\n",
      "Epoch 52/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.4557 - accuracy: 0.8390\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.00010011290578404441.\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.61975\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4558 - accuracy: 0.8389 - val_loss: 0.6208 - val_accuracy: 0.7790\n",
      "Epoch 53/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4550 - accuracy: 0.8392\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 7.508467933803331e-05.\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.61975\n",
      "98782/98782 [==============================] - 4s 37us/sample - loss: 0.4550 - accuracy: 0.8393 - val_loss: 0.6205 - val_accuracy: 0.7795\n",
      "Epoch 54/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4543 - accuracy: 0.8394\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 5.6313510867767036e-05.\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.61975\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4544 - accuracy: 0.8393 - val_loss: 0.6202 - val_accuracy: 0.7793\n",
      "Epoch 55/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.4539 - accuracy: 0.8400\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 4.223513315082528e-05.\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.61975\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4540 - accuracy: 0.8398 - val_loss: 0.6198 - val_accuracy: 0.7786\n",
      "Epoch 56/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.4536 - accuracy: 0.8397\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 3.167634986311896e-05.\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.61975\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4537 - accuracy: 0.8397 - val_loss: 0.6198 - val_accuracy: 0.7786\n",
      "Epoch 57/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.4538 - accuracy: 0.8399\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 2.3757263079460245e-05.\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.61975\n",
      "98782/98782 [==============================] - 4s 37us/sample - loss: 0.4535 - accuracy: 0.8400 - val_loss: 0.6199 - val_accuracy: 0.7786\n",
      "Epoch 58/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4534 - accuracy: 0.8396\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1.781794799171621e-05.\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.61975\n",
      "98782/98782 [==============================] - 4s 39us/sample - loss: 0.4533 - accuracy: 0.8396 - val_loss: 0.6199 - val_accuracy: 0.7792\n",
      "Epoch 59/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4532 - accuracy: 0.8398\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 1.3363460311666131e-05.\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.61975\n",
      "98782/98782 [==============================] - 4s 39us/sample - loss: 0.4531 - accuracy: 0.8399 - val_loss: 0.6199 - val_accuracy: 0.7782\n",
      "Epoch 60/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.4531 - accuracy: 0.8401\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 1.0022595233749598e-05.\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.61975\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4530 - accuracy: 0.8400 - val_loss: 0.6200 - val_accuracy: 0.7790\n",
      "Epoch 61/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4529 - accuracy: 0.8401\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 7.516946425312199e-06.\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.61975\n",
      "98782/98782 [==============================] - 4s 40us/sample - loss: 0.4530 - accuracy: 0.8400 - val_loss: 0.6199 - val_accuracy: 0.7793\n",
      "... Iteration 8 ...\n",
      "... Preprocessing Data ... \n",
      "(98782, 256) (98782,)\n",
      "(5488, 256) (5488,)\n",
      "... Training Model by Validating on Fold 8 ...\n",
      "Train on 98782 samples, validate on 5488 samples\n",
      "Epoch 1/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 1.5614 - accuracy: 0.2768\n",
      "Epoch 00001: val_loss improved from inf to 1.53912, saving model to ./storage/writer_train_10/kfold8/epoch_001_val_1.539.h5\n",
      "98782/98782 [==============================] - 5s 47us/sample - loss: 1.5614 - accuracy: 0.2767 - val_loss: 1.5391 - val_accuracy: 0.2868\n",
      "Epoch 2/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 1.5192 - accuracy: 0.3298\n",
      "Epoch 00002: val_loss improved from 1.53912 to 1.47369, saving model to ./storage/writer_train_10/kfold8/epoch_002_val_1.474.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 1.5186 - accuracy: 0.3302 - val_loss: 1.4737 - val_accuracy: 0.3664\n",
      "Epoch 3/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 1.4442 - accuracy: 0.4384\n",
      "Epoch 00003: val_loss improved from 1.47369 to 1.37688, saving model to ./storage/writer_train_10/kfold8/epoch_003_val_1.377.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 1.4437 - accuracy: 0.4390 - val_loss: 1.3769 - val_accuracy: 0.5022\n",
      "Epoch 4/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 1.3549 - accuracy: 0.4988\n",
      "Epoch 00004: val_loss improved from 1.37688 to 1.28004, saving model to ./storage/writer_train_10/kfold8/epoch_004_val_1.280.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 1.3545 - accuracy: 0.4989 - val_loss: 1.2800 - val_accuracy: 0.5326\n",
      "Epoch 5/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 1.2705 - accuracy: 0.5419\n",
      "Epoch 00005: val_loss improved from 1.28004 to 1.19347, saving model to ./storage/writer_train_10/kfold8/epoch_005_val_1.193.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 1.2700 - accuracy: 0.5424 - val_loss: 1.1935 - val_accuracy: 0.5851\n",
      "Epoch 6/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 1.1954 - accuracy: 0.5742\n",
      "Epoch 00006: val_loss improved from 1.19347 to 1.11939, saving model to ./storage/writer_train_10/kfold8/epoch_006_val_1.119.h5\n",
      "98782/98782 [==============================] - 4s 44us/sample - loss: 1.1949 - accuracy: 0.5744 - val_loss: 1.1194 - val_accuracy: 0.6172\n",
      "Epoch 7/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 1.1292 - accuracy: 0.5990\n",
      "Epoch 00007: val_loss improved from 1.11939 to 1.05666, saving model to ./storage/writer_train_10/kfold8/epoch_007_val_1.057.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 1.1290 - accuracy: 0.5991 - val_loss: 1.0567 - val_accuracy: 0.6385\n",
      "Epoch 8/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 1.0717 - accuracy: 0.6193\n",
      "Epoch 00008: val_loss improved from 1.05666 to 1.00270, saving model to ./storage/writer_train_10/kfold8/epoch_008_val_1.003.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 1.0715 - accuracy: 0.6194 - val_loss: 1.0027 - val_accuracy: 0.6507\n",
      "Epoch 9/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 1.0214 - accuracy: 0.6371\n",
      "Epoch 00009: val_loss improved from 1.00270 to 0.95502, saving model to ./storage/writer_train_10/kfold8/epoch_009_val_0.955.h5\n",
      "98782/98782 [==============================] - 5s 48us/sample - loss: 1.0212 - accuracy: 0.6371 - val_loss: 0.9550 - val_accuracy: 0.6678\n",
      "Epoch 10/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.9775 - accuracy: 0.6524\n",
      "Epoch 00010: val_loss improved from 0.95502 to 0.91687, saving model to ./storage/writer_train_10/kfold8/epoch_010_val_0.917.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.9768 - accuracy: 0.6527 - val_loss: 0.9169 - val_accuracy: 0.6820\n",
      "Epoch 11/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.9372 - accuracy: 0.6685\n",
      "Epoch 00011: val_loss improved from 0.91687 to 0.88101, saving model to ./storage/writer_train_10/kfold8/epoch_011_val_0.881.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.9371 - accuracy: 0.6683 - val_loss: 0.8810 - val_accuracy: 0.6915\n",
      "Epoch 12/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.9017 - accuracy: 0.6815\n",
      "Epoch 00012: val_loss improved from 0.88101 to 0.85150, saving model to ./storage/writer_train_10/kfold8/epoch_012_val_0.851.h5\n",
      "98782/98782 [==============================] - 5s 47us/sample - loss: 0.9015 - accuracy: 0.6817 - val_loss: 0.8515 - val_accuracy: 0.7105\n",
      "Epoch 13/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.8695 - accuracy: 0.6950\n",
      "Epoch 00013: val_loss improved from 0.85150 to 0.82301, saving model to ./storage/writer_train_10/kfold8/epoch_013_val_0.823.h5\n",
      "98782/98782 [==============================] - 5s 48us/sample - loss: 0.8693 - accuracy: 0.6950 - val_loss: 0.8230 - val_accuracy: 0.7128\n",
      "Epoch 14/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.8397 - accuracy: 0.7059\n",
      "Epoch 00014: val_loss improved from 0.82301 to 0.79875, saving model to ./storage/writer_train_10/kfold8/epoch_014_val_0.799.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.8398 - accuracy: 0.7060 - val_loss: 0.7987 - val_accuracy: 0.7250\n",
      "Epoch 15/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.8131 - accuracy: 0.7162\n",
      "Epoch 00015: val_loss improved from 0.79875 to 0.77890, saving model to ./storage/writer_train_10/kfold8/epoch_015_val_0.779.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.8130 - accuracy: 0.7164 - val_loss: 0.7789 - val_accuracy: 0.7305\n",
      "Epoch 16/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.7883 - accuracy: 0.7251\n",
      "Epoch 00016: val_loss improved from 0.77890 to 0.75942, saving model to ./storage/writer_train_10/kfold8/epoch_016_val_0.759.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.7882 - accuracy: 0.7253 - val_loss: 0.7594 - val_accuracy: 0.7398\n",
      "Epoch 17/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.7656 - accuracy: 0.7336\n",
      "Epoch 00017: val_loss improved from 0.75942 to 0.74114, saving model to ./storage/writer_train_10/kfold8/epoch_017_val_0.741.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.7655 - accuracy: 0.7336 - val_loss: 0.7411 - val_accuracy: 0.7467\n",
      "Epoch 18/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.7445 - accuracy: 0.7411\n",
      "Epoch 00018: val_loss improved from 0.74114 to 0.72665, saving model to ./storage/writer_train_10/kfold8/epoch_018_val_0.727.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.7441 - accuracy: 0.7415 - val_loss: 0.7267 - val_accuracy: 0.7496\n",
      "Epoch 19/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.7247 - accuracy: 0.7478\n",
      "Epoch 00019: val_loss improved from 0.72665 to 0.71066, saving model to ./storage/writer_train_10/kfold8/epoch_019_val_0.711.h5\n",
      "98782/98782 [==============================] - 5s 47us/sample - loss: 0.7247 - accuracy: 0.7479 - val_loss: 0.7107 - val_accuracy: 0.7533\n",
      "Epoch 20/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.7062 - accuracy: 0.7538\n",
      "Epoch 00020: val_loss improved from 0.71066 to 0.69960, saving model to ./storage/writer_train_10/kfold8/epoch_020_val_0.700.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.7061 - accuracy: 0.7538 - val_loss: 0.6996 - val_accuracy: 0.7551\n",
      "Epoch 21/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.6890 - accuracy: 0.7591\n",
      "Epoch 00021: val_loss improved from 0.69960 to 0.68707, saving model to ./storage/writer_train_10/kfold8/epoch_021_val_0.687.h5\n",
      "98782/98782 [==============================] - 5s 49us/sample - loss: 0.6890 - accuracy: 0.7592 - val_loss: 0.6871 - val_accuracy: 0.7637\n",
      "Epoch 22/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.6732 - accuracy: 0.7644\n",
      "Epoch 00022: val_loss improved from 0.68707 to 0.67783, saving model to ./storage/writer_train_10/kfold8/epoch_022_val_0.678.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.6729 - accuracy: 0.7646 - val_loss: 0.6778 - val_accuracy: 0.7648\n",
      "Epoch 23/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.6581 - accuracy: 0.7701\n",
      "Epoch 00023: val_loss improved from 0.67783 to 0.66710, saving model to ./storage/writer_train_10/kfold8/epoch_023_val_0.667.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.6578 - accuracy: 0.7702 - val_loss: 0.6671 - val_accuracy: 0.7706\n",
      "Epoch 24/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.6435 - accuracy: 0.7747\n",
      "Epoch 00024: val_loss improved from 0.66710 to 0.65904, saving model to ./storage/writer_train_10/kfold8/epoch_024_val_0.659.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.6437 - accuracy: 0.7746 - val_loss: 0.6590 - val_accuracy: 0.7713\n",
      "Epoch 25/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.6304 - accuracy: 0.7790\n",
      "Epoch 00025: val_loss improved from 0.65904 to 0.65013, saving model to ./storage/writer_train_10/kfold8/epoch_025_val_0.650.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.6302 - accuracy: 0.7790 - val_loss: 0.6501 - val_accuracy: 0.7751\n",
      "Epoch 26/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.6178 - accuracy: 0.7833\n",
      "Epoch 00026: val_loss improved from 0.65013 to 0.64260, saving model to ./storage/writer_train_10/kfold8/epoch_026_val_0.643.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.6178 - accuracy: 0.7832 - val_loss: 0.6426 - val_accuracy: 0.7753\n",
      "Epoch 27/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.6058 - accuracy: 0.7862\n",
      "Epoch 00027: val_loss improved from 0.64260 to 0.64044, saving model to ./storage/writer_train_10/kfold8/epoch_027_val_0.640.h5\n",
      "98782/98782 [==============================] - 5s 46us/sample - loss: 0.6055 - accuracy: 0.7863 - val_loss: 0.6404 - val_accuracy: 0.7775\n",
      "Epoch 28/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.5944 - accuracy: 0.7901\n",
      "Epoch 00028: val_loss improved from 0.64044 to 0.62995, saving model to ./storage/writer_train_10/kfold8/epoch_028_val_0.630.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.5942 - accuracy: 0.7901 - val_loss: 0.6299 - val_accuracy: 0.7795\n",
      "Epoch 29/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.5833 - accuracy: 0.7947\n",
      "Epoch 00029: val_loss improved from 0.62995 to 0.62496, saving model to ./storage/writer_train_10/kfold8/epoch_029_val_0.625.h5\n",
      "98782/98782 [==============================] - 5s 46us/sample - loss: 0.5833 - accuracy: 0.7946 - val_loss: 0.6250 - val_accuracy: 0.7804\n",
      "Epoch 30/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.5728 - accuracy: 0.7981\n",
      "Epoch 00030: val_loss improved from 0.62496 to 0.62053, saving model to ./storage/writer_train_10/kfold8/epoch_030_val_0.621.h5\n",
      "98782/98782 [==============================] - 5s 46us/sample - loss: 0.5731 - accuracy: 0.7980 - val_loss: 0.6205 - val_accuracy: 0.7819\n",
      "Epoch 31/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.5630 - accuracy: 0.8013\n",
      "Epoch 00031: val_loss improved from 0.62053 to 0.61529, saving model to ./storage/writer_train_10/kfold8/epoch_031_val_0.615.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5631 - accuracy: 0.8012 - val_loss: 0.6153 - val_accuracy: 0.7839\n",
      "Epoch 32/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.5539 - accuracy: 0.8045\n",
      "Epoch 00032: val_loss improved from 0.61529 to 0.61327, saving model to ./storage/writer_train_10/kfold8/epoch_032_val_0.613.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.5538 - accuracy: 0.8044 - val_loss: 0.6133 - val_accuracy: 0.7812\n",
      "Epoch 33/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.5449 - accuracy: 0.8077\n",
      "Epoch 00033: val_loss improved from 0.61327 to 0.60778, saving model to ./storage/writer_train_10/kfold8/epoch_033_val_0.608.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.5451 - accuracy: 0.8076 - val_loss: 0.6078 - val_accuracy: 0.7848\n",
      "Epoch 34/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.5362 - accuracy: 0.8111\n",
      "Epoch 00034: val_loss improved from 0.60778 to 0.60559, saving model to ./storage/writer_train_10/kfold8/epoch_034_val_0.606.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.5365 - accuracy: 0.8109 - val_loss: 0.6056 - val_accuracy: 0.7861\n",
      "Epoch 35/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.5287 - accuracy: 0.8127\n",
      "Epoch 00035: val_loss improved from 0.60559 to 0.60192, saving model to ./storage/writer_train_10/kfold8/epoch_035_val_0.602.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.5285 - accuracy: 0.8129 - val_loss: 0.6019 - val_accuracy: 0.7877\n",
      "Epoch 36/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.5201 - accuracy: 0.8163\n",
      "Epoch 00036: val_loss improved from 0.60192 to 0.60007, saving model to ./storage/writer_train_10/kfold8/epoch_036_val_0.600.h5\n",
      "98782/98782 [==============================] - 4s 45us/sample - loss: 0.5203 - accuracy: 0.8161 - val_loss: 0.6001 - val_accuracy: 0.7866\n",
      "Epoch 37/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.5137 - accuracy: 0.8181\n",
      "Epoch 00037: val_loss improved from 0.60007 to 0.59609, saving model to ./storage/writer_train_10/kfold8/epoch_037_val_0.596.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.5134 - accuracy: 0.8182 - val_loss: 0.5961 - val_accuracy: 0.7861\n",
      "Epoch 38/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.5061 - accuracy: 0.8203\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0007500000356230885.\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.59609\n",
      "98782/98782 [==============================] - 4s 45us/sample - loss: 0.5059 - accuracy: 0.8205 - val_loss: 0.5969 - val_accuracy: 0.7864\n",
      "Epoch 39/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4991 - accuracy: 0.8238\n",
      "Epoch 00039: val_loss improved from 0.59609 to 0.59418, saving model to ./storage/writer_train_10/kfold8/epoch_039_val_0.594.h5\n",
      "98782/98782 [==============================] - 5s 48us/sample - loss: 0.4991 - accuracy: 0.8239 - val_loss: 0.5942 - val_accuracy: 0.7897\n",
      "Epoch 40/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.4939 - accuracy: 0.8253\n",
      "Epoch 00040: val_loss improved from 0.59418 to 0.59249, saving model to ./storage/writer_train_10/kfold8/epoch_040_val_0.592.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.4939 - accuracy: 0.8253 - val_loss: 0.5925 - val_accuracy: 0.7894\n",
      "Epoch 41/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.4894 - accuracy: 0.8273\n",
      "Epoch 00041: val_loss improved from 0.59249 to 0.59164, saving model to ./storage/writer_train_10/kfold8/epoch_041_val_0.592.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.4891 - accuracy: 0.8275 - val_loss: 0.5916 - val_accuracy: 0.7912\n",
      "Epoch 42/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4843 - accuracy: 0.8287\n",
      "Epoch 00042: val_loss improved from 0.59164 to 0.59013, saving model to ./storage/writer_train_10/kfold8/epoch_042_val_0.590.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.4844 - accuracy: 0.8286 - val_loss: 0.5901 - val_accuracy: 0.7892\n",
      "Epoch 43/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4797 - accuracy: 0.8302\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0005625000048894435.\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.59013\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4799 - accuracy: 0.8301 - val_loss: 0.5929 - val_accuracy: 0.7874\n",
      "Epoch 44/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.4753 - accuracy: 0.8321\n",
      "Epoch 00044: val_loss improved from 0.59013 to 0.58884, saving model to ./storage/writer_train_10/kfold8/epoch_044_val_0.589.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.4754 - accuracy: 0.8321 - val_loss: 0.5888 - val_accuracy: 0.7910\n",
      "Epoch 45/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.4716 - accuracy: 0.8333\n",
      "Epoch 00045: val_loss improved from 0.58884 to 0.58867, saving model to ./storage/writer_train_10/kfold8/epoch_045_val_0.589.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.4717 - accuracy: 0.8333 - val_loss: 0.5887 - val_accuracy: 0.7926\n",
      "Epoch 46/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.4685 - accuracy: 0.8344\n",
      "Epoch 00046: val_loss improved from 0.58867 to 0.58847, saving model to ./storage/writer_train_10/kfold8/epoch_046_val_0.588.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.4686 - accuracy: 0.8344 - val_loss: 0.5885 - val_accuracy: 0.7908\n",
      "Epoch 47/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.4654 - accuracy: 0.8354\n",
      "Epoch 00047: val_loss improved from 0.58847 to 0.58714, saving model to ./storage/writer_train_10/kfold8/epoch_047_val_0.587.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.4654 - accuracy: 0.8354 - val_loss: 0.5871 - val_accuracy: 0.7901\n",
      "Epoch 48/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4622 - accuracy: 0.8365\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.0004218749818392098.\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.58714\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4622 - accuracy: 0.8364 - val_loss: 0.5878 - val_accuracy: 0.7910\n",
      "Epoch 49/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4588 - accuracy: 0.8377\n",
      "Epoch 00049: val_loss improved from 0.58714 to 0.58629, saving model to ./storage/writer_train_10/kfold8/epoch_049_val_0.586.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.4591 - accuracy: 0.8376 - val_loss: 0.5863 - val_accuracy: 0.7912\n",
      "Epoch 50/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.4563 - accuracy: 0.8389\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.00031640623637940735.\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.58629\n",
      "98782/98782 [==============================] - 4s 39us/sample - loss: 0.4566 - accuracy: 0.8388 - val_loss: 0.5866 - val_accuracy: 0.7912\n",
      "Epoch 51/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.4547 - accuracy: 0.8396\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.00023730468819849193.\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.58629\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4544 - accuracy: 0.8397 - val_loss: 0.5866 - val_accuracy: 0.7906\n",
      "Epoch 52/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4525 - accuracy: 0.8405\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.00017797851614886895.\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.58629\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4526 - accuracy: 0.8404 - val_loss: 0.5872 - val_accuracy: 0.7919\n",
      "Epoch 53/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.4514 - accuracy: 0.8413\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0001334838816546835.\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.58629\n",
      "98782/98782 [==============================] - 4s 39us/sample - loss: 0.4513 - accuracy: 0.8413 - val_loss: 0.5870 - val_accuracy: 0.7910\n",
      "Epoch 54/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.4502 - accuracy: 0.8414\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.00010011290578404441.\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.58629 to 0.58621, saving model to ./storage/writer_train_10/kfold8/epoch_054_val_0.586.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.4503 - accuracy: 0.8414 - val_loss: 0.5862 - val_accuracy: 0.7905\n",
      "Epoch 55/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.4494 - accuracy: 0.8417\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 7.508467933803331e-05.\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.58621\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4496 - accuracy: 0.8416 - val_loss: 0.5864 - val_accuracy: 0.7910\n",
      "Epoch 56/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4493 - accuracy: 0.8419\n",
      "Epoch 00056: val_loss improved from 0.58621 to 0.58598, saving model to ./storage/writer_train_10/kfold8/epoch_056_val_0.586.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.4491 - accuracy: 0.8418 - val_loss: 0.5860 - val_accuracy: 0.7905\n",
      "Epoch 57/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4489 - accuracy: 0.8419\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 5.6313510867767036e-05.\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.58598 to 0.58595, saving model to ./storage/writer_train_10/kfold8/epoch_057_val_0.586.h5\n",
      "98782/98782 [==============================] - 4s 45us/sample - loss: 0.4486 - accuracy: 0.8420 - val_loss: 0.5860 - val_accuracy: 0.7906\n",
      "Epoch 58/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.4481 - accuracy: 0.8419\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 4.223513315082528e-05.\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.58595\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4483 - accuracy: 0.8419 - val_loss: 0.5863 - val_accuracy: 0.7899\n",
      "Epoch 59/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4480 - accuracy: 0.8421\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 3.167634986311896e-05.\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.58595\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4479 - accuracy: 0.8421 - val_loss: 0.5860 - val_accuracy: 0.7897\n",
      "Epoch 60/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4475 - accuracy: 0.8422\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 2.3757263079460245e-05.\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.58595\n",
      "98782/98782 [==============================] - 4s 39us/sample - loss: 0.4477 - accuracy: 0.8422 - val_loss: 0.5863 - val_accuracy: 0.7906\n",
      "Epoch 61/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.4476 - accuracy: 0.8426\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 1.781794799171621e-05.\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.58595\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4475 - accuracy: 0.8426 - val_loss: 0.5861 - val_accuracy: 0.7894\n",
      "Epoch 62/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.4477 - accuracy: 0.8421\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 1.3363460311666131e-05.\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.58595\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4474 - accuracy: 0.8423 - val_loss: 0.5861 - val_accuracy: 0.7894\n",
      "Epoch 63/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4474 - accuracy: 0.8424\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 1.0022595233749598e-05.\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.58595\n",
      "98782/98782 [==============================] - 4s 39us/sample - loss: 0.4473 - accuracy: 0.8425 - val_loss: 0.5862 - val_accuracy: 0.7906\n",
      "Epoch 64/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4471 - accuracy: 0.8424\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 7.516946425312199e-06.\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.58595\n",
      "98782/98782 [==============================] - 4s 39us/sample - loss: 0.4472 - accuracy: 0.8424 - val_loss: 0.5862 - val_accuracy: 0.7897\n",
      "Epoch 65/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4472 - accuracy: 0.8425\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 5.637709818984149e-06.\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.58595\n",
      "98782/98782 [==============================] - 4s 39us/sample - loss: 0.4472 - accuracy: 0.8426 - val_loss: 0.5861 - val_accuracy: 0.7897\n",
      "Epoch 66/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.4471 - accuracy: 0.8426\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 4.228282364238112e-06.\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.58595\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4471 - accuracy: 0.8426 - val_loss: 0.5862 - val_accuracy: 0.7899\n",
      "Epoch 67/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.4471 - accuracy: 0.8425\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 3.1712116879134555e-06.\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.58595\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4471 - accuracy: 0.8425 - val_loss: 0.5861 - val_accuracy: 0.7901\n",
      "... Iteration 9 ...\n",
      "... Preprocessing Data ... \n",
      "(98782, 256) (98782,)\n",
      "(5488, 256) (5488,)\n",
      "... Training Model by Validating on Fold 9 ...\n",
      "Train on 98782 samples, validate on 5488 samples\n",
      "Epoch 1/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 1.5610 - accuracy: 0.2748\n",
      "Epoch 00001: val_loss improved from inf to 1.53734, saving model to ./storage/writer_train_10/kfold9/epoch_001_val_1.537.h5\n",
      "98782/98782 [==============================] - 5s 50us/sample - loss: 1.5608 - accuracy: 0.2747 - val_loss: 1.5373 - val_accuracy: 0.2877\n",
      "Epoch 2/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 1.5100 - accuracy: 0.3552\n",
      "Epoch 00002: val_loss improved from 1.53734 to 1.46470, saving model to ./storage/writer_train_10/kfold9/epoch_002_val_1.465.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 1.5094 - accuracy: 0.3556 - val_loss: 1.4647 - val_accuracy: 0.3801\n",
      "Epoch 3/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 1.4294 - accuracy: 0.4472\n",
      "Epoch 00003: val_loss improved from 1.46470 to 1.36299, saving model to ./storage/writer_train_10/kfold9/epoch_003_val_1.363.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 1.4287 - accuracy: 0.4478 - val_loss: 1.3630 - val_accuracy: 0.5251\n",
      "Epoch 4/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 1.3385 - accuracy: 0.5009\n",
      "Epoch 00004: val_loss improved from 1.36299 to 1.26191, saving model to ./storage/writer_train_10/kfold9/epoch_004_val_1.262.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 1.3381 - accuracy: 0.5012 - val_loss: 1.2619 - val_accuracy: 0.5598\n",
      "Epoch 5/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 1.2530 - accuracy: 0.5427\n",
      "Epoch 00005: val_loss improved from 1.26191 to 1.17283, saving model to ./storage/writer_train_10/kfold9/epoch_005_val_1.173.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 1.2529 - accuracy: 0.5427 - val_loss: 1.1728 - val_accuracy: 0.5946\n",
      "Epoch 6/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 1.1784 - accuracy: 0.5749\n",
      "Epoch 00006: val_loss improved from 1.17283 to 1.09810, saving model to ./storage/writer_train_10/kfold9/epoch_006_val_1.098.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 1.1777 - accuracy: 0.5753 - val_loss: 1.0981 - val_accuracy: 0.6235\n",
      "Epoch 7/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 1.1131 - accuracy: 0.5996\n",
      "Epoch 00007: val_loss improved from 1.09810 to 1.03504, saving model to ./storage/writer_train_10/kfold9/epoch_007_val_1.035.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 1.1127 - accuracy: 0.5997 - val_loss: 1.0350 - val_accuracy: 0.6430\n",
      "Epoch 8/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 1.0566 - accuracy: 0.6205\n",
      "Epoch 00008: val_loss improved from 1.03504 to 0.98300, saving model to ./storage/writer_train_10/kfold9/epoch_008_val_0.983.h5\n",
      "98782/98782 [==============================] - 4s 44us/sample - loss: 1.0565 - accuracy: 0.6206 - val_loss: 0.9830 - val_accuracy: 0.6543\n",
      "Epoch 9/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 1.0072 - accuracy: 0.6383\n",
      "Epoch 00009: val_loss improved from 0.98300 to 0.93939, saving model to ./storage/writer_train_10/kfold9/epoch_009_val_0.939.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 1.0072 - accuracy: 0.6383 - val_loss: 0.9394 - val_accuracy: 0.6749\n",
      "Epoch 10/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.9640 - accuracy: 0.6548\n",
      "Epoch 00010: val_loss improved from 0.93939 to 0.89944, saving model to ./storage/writer_train_10/kfold9/epoch_010_val_0.899.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.9636 - accuracy: 0.6549 - val_loss: 0.8994 - val_accuracy: 0.6857\n",
      "Epoch 11/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.9245 - accuracy: 0.6706\n",
      "Epoch 00011: val_loss improved from 0.89944 to 0.86675, saving model to ./storage/writer_train_10/kfold9/epoch_011_val_0.867.h5\n",
      "98782/98782 [==============================] - 4s 44us/sample - loss: 0.9245 - accuracy: 0.6707 - val_loss: 0.8667 - val_accuracy: 0.6904\n",
      "Epoch 12/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.8894 - accuracy: 0.6850\n",
      "Epoch 00012: val_loss improved from 0.86675 to 0.83567, saving model to ./storage/writer_train_10/kfold9/epoch_012_val_0.836.h5\n",
      "98782/98782 [==============================] - 4s 44us/sample - loss: 0.8894 - accuracy: 0.6850 - val_loss: 0.8357 - val_accuracy: 0.7114\n",
      "Epoch 13/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.8578 - accuracy: 0.6972\n",
      "Epoch 00013: val_loss improved from 0.83567 to 0.80924, saving model to ./storage/writer_train_10/kfold9/epoch_013_val_0.809.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.8574 - accuracy: 0.6975 - val_loss: 0.8092 - val_accuracy: 0.7192\n",
      "Epoch 14/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.8281 - accuracy: 0.7092\n",
      "Epoch 00014: val_loss improved from 0.80924 to 0.78466, saving model to ./storage/writer_train_10/kfold9/epoch_014_val_0.785.h5\n",
      "98782/98782 [==============================] - 4s 44us/sample - loss: 0.8279 - accuracy: 0.7093 - val_loss: 0.7847 - val_accuracy: 0.7321\n",
      "Epoch 15/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.8014 - accuracy: 0.7197\n",
      "Epoch 00015: val_loss improved from 0.78466 to 0.76321, saving model to ./storage/writer_train_10/kfold9/epoch_015_val_0.763.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.8012 - accuracy: 0.7197 - val_loss: 0.7632 - val_accuracy: 0.7360\n",
      "Epoch 16/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.7763 - accuracy: 0.7295\n",
      "Epoch 00016: val_loss improved from 0.76321 to 0.74438, saving model to ./storage/writer_train_10/kfold9/epoch_016_val_0.744.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.7761 - accuracy: 0.7296 - val_loss: 0.7444 - val_accuracy: 0.7456\n",
      "Epoch 17/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.7533 - accuracy: 0.7373\n",
      "Epoch 00017: val_loss improved from 0.74438 to 0.72656, saving model to ./storage/writer_train_10/kfold9/epoch_017_val_0.727.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.7533 - accuracy: 0.7372 - val_loss: 0.7266 - val_accuracy: 0.7502\n",
      "Epoch 18/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.7324 - accuracy: 0.7446\n",
      "Epoch 00018: val_loss improved from 0.72656 to 0.71438, saving model to ./storage/writer_train_10/kfold9/epoch_018_val_0.714.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.7323 - accuracy: 0.7446 - val_loss: 0.7144 - val_accuracy: 0.7569\n",
      "Epoch 19/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.7125 - accuracy: 0.7519\n",
      "Epoch 00019: val_loss improved from 0.71438 to 0.69790, saving model to ./storage/writer_train_10/kfold9/epoch_019_val_0.698.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.7124 - accuracy: 0.7519 - val_loss: 0.6979 - val_accuracy: 0.7584\n",
      "Epoch 20/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.6940 - accuracy: 0.7581\n",
      "Epoch 00020: val_loss improved from 0.69790 to 0.68467, saving model to ./storage/writer_train_10/kfold9/epoch_020_val_0.685.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.6940 - accuracy: 0.7582 - val_loss: 0.6847 - val_accuracy: 0.7604\n",
      "Epoch 21/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.6771 - accuracy: 0.7635\n",
      "Epoch 00021: val_loss improved from 0.68467 to 0.67320, saving model to ./storage/writer_train_10/kfold9/epoch_021_val_0.673.h5\n",
      "98782/98782 [==============================] - 4s 45us/sample - loss: 0.6770 - accuracy: 0.7636 - val_loss: 0.6732 - val_accuracy: 0.7657\n",
      "Epoch 22/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.6614 - accuracy: 0.7691\n",
      "Epoch 00022: val_loss improved from 0.67320 to 0.66455, saving model to ./storage/writer_train_10/kfold9/epoch_022_val_0.665.h5\n",
      "98782/98782 [==============================] - 5s 47us/sample - loss: 0.6608 - accuracy: 0.7693 - val_loss: 0.6645 - val_accuracy: 0.7659\n",
      "Epoch 23/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.6455 - accuracy: 0.7738\n",
      "Epoch 00023: val_loss improved from 0.66455 to 0.65291, saving model to ./storage/writer_train_10/kfold9/epoch_023_val_0.653.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.6459 - accuracy: 0.7735 - val_loss: 0.6529 - val_accuracy: 0.7706\n",
      "Epoch 24/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.6317 - accuracy: 0.7798\n",
      "Epoch 00024: val_loss improved from 0.65291 to 0.64433, saving model to ./storage/writer_train_10/kfold9/epoch_024_val_0.644.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.6315 - accuracy: 0.7799 - val_loss: 0.6443 - val_accuracy: 0.7706\n",
      "Epoch 25/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.6183 - accuracy: 0.7835\n",
      "Epoch 00025: val_loss improved from 0.64433 to 0.63809, saving model to ./storage/writer_train_10/kfold9/epoch_025_val_0.638.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.6183 - accuracy: 0.7835 - val_loss: 0.6381 - val_accuracy: 0.7777\n",
      "Epoch 26/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.6058 - accuracy: 0.7878\n",
      "Epoch 00026: val_loss improved from 0.63809 to 0.62988, saving model to ./storage/writer_train_10/kfold9/epoch_026_val_0.630.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.6058 - accuracy: 0.7877 - val_loss: 0.6299 - val_accuracy: 0.7802\n",
      "Epoch 27/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.5934 - accuracy: 0.7911\n",
      "Epoch 00027: val_loss improved from 0.62988 to 0.62483, saving model to ./storage/writer_train_10/kfold9/epoch_027_val_0.625.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5936 - accuracy: 0.7910 - val_loss: 0.6248 - val_accuracy: 0.7790\n",
      "Epoch 28/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.5824 - accuracy: 0.7946\n",
      "Epoch 00028: val_loss improved from 0.62483 to 0.62052, saving model to ./storage/writer_train_10/kfold9/epoch_028_val_0.621.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5824 - accuracy: 0.7946 - val_loss: 0.6205 - val_accuracy: 0.7802\n",
      "Epoch 29/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.5718 - accuracy: 0.7989\n",
      "Epoch 00029: val_loss improved from 0.62052 to 0.61398, saving model to ./storage/writer_train_10/kfold9/epoch_029_val_0.614.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.5717 - accuracy: 0.7989 - val_loss: 0.6140 - val_accuracy: 0.7846\n",
      "Epoch 30/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.5611 - accuracy: 0.8024\n",
      "Epoch 00030: val_loss improved from 0.61398 to 0.61233, saving model to ./storage/writer_train_10/kfold9/epoch_030_val_0.612.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5614 - accuracy: 0.8023 - val_loss: 0.6123 - val_accuracy: 0.7833\n",
      "Epoch 31/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.5517 - accuracy: 0.8050\n",
      "Epoch 00031: val_loss improved from 0.61233 to 0.60470, saving model to ./storage/writer_train_10/kfold9/epoch_031_val_0.605.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5518 - accuracy: 0.8050 - val_loss: 0.6047 - val_accuracy: 0.7868\n",
      "Epoch 32/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.5422 - accuracy: 0.8091\n",
      "Epoch 00032: val_loss improved from 0.60470 to 0.60084, saving model to ./storage/writer_train_10/kfold9/epoch_032_val_0.601.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5426 - accuracy: 0.8089 - val_loss: 0.6008 - val_accuracy: 0.7884\n",
      "Epoch 33/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.5341 - accuracy: 0.8111\n",
      "Epoch 00033: val_loss improved from 0.60084 to 0.59888, saving model to ./storage/writer_train_10/kfold9/epoch_033_val_0.599.h5\n",
      "98782/98782 [==============================] - 4s 44us/sample - loss: 0.5342 - accuracy: 0.8111 - val_loss: 0.5989 - val_accuracy: 0.7879\n",
      "Epoch 34/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.5259 - accuracy: 0.8142\n",
      "Epoch 00034: val_loss improved from 0.59888 to 0.59582, saving model to ./storage/writer_train_10/kfold9/epoch_034_val_0.596.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5255 - accuracy: 0.8145 - val_loss: 0.5958 - val_accuracy: 0.7894\n",
      "Epoch 35/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.5180 - accuracy: 0.8169\n",
      "Epoch 00035: val_loss improved from 0.59582 to 0.59566, saving model to ./storage/writer_train_10/kfold9/epoch_035_val_0.596.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.5179 - accuracy: 0.8169 - val_loss: 0.5957 - val_accuracy: 0.7881\n",
      "Epoch 36/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.5103 - accuracy: 0.8195\n",
      "Epoch 00036: val_loss improved from 0.59566 to 0.58930, saving model to ./storage/writer_train_10/kfold9/epoch_036_val_0.589.h5\n",
      "98782/98782 [==============================] - 4s 44us/sample - loss: 0.5102 - accuracy: 0.8195 - val_loss: 0.5893 - val_accuracy: 0.7914\n",
      "Epoch 37/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.5022 - accuracy: 0.8226\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0007500000356230885.\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.58930\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.5027 - accuracy: 0.8223 - val_loss: 0.5895 - val_accuracy: 0.7914\n",
      "Epoch 38/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.4955 - accuracy: 0.8247\n",
      "Epoch 00038: val_loss improved from 0.58930 to 0.58838, saving model to ./storage/writer_train_10/kfold9/epoch_038_val_0.588.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.4954 - accuracy: 0.8247 - val_loss: 0.5884 - val_accuracy: 0.7925\n",
      "Epoch 39/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.4901 - accuracy: 0.8267\n",
      "Epoch 00039: val_loss improved from 0.58838 to 0.58681, saving model to ./storage/writer_train_10/kfold9/epoch_039_val_0.587.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.4903 - accuracy: 0.8267 - val_loss: 0.5868 - val_accuracy: 0.7917\n",
      "Epoch 40/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.4850 - accuracy: 0.8289\n",
      "Epoch 00040: val_loss improved from 0.58681 to 0.58504, saving model to ./storage/writer_train_10/kfold9/epoch_040_val_0.585.h5\n",
      "98782/98782 [==============================] - 4s 41us/sample - loss: 0.4854 - accuracy: 0.8287 - val_loss: 0.5850 - val_accuracy: 0.7923\n",
      "Epoch 41/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4807 - accuracy: 0.8300\n",
      "Epoch 00041: val_loss improved from 0.58504 to 0.58432, saving model to ./storage/writer_train_10/kfold9/epoch_041_val_0.584.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.4808 - accuracy: 0.8299 - val_loss: 0.5843 - val_accuracy: 0.7926\n",
      "Epoch 42/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.4759 - accuracy: 0.8314\n",
      "Epoch 00042: val_loss improved from 0.58432 to 0.58387, saving model to ./storage/writer_train_10/kfold9/epoch_042_val_0.584.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.4759 - accuracy: 0.8315 - val_loss: 0.5839 - val_accuracy: 0.7926\n",
      "Epoch 43/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.4716 - accuracy: 0.8330\n",
      "Epoch 00043: val_loss improved from 0.58387 to 0.58225, saving model to ./storage/writer_train_10/kfold9/epoch_043_val_0.582.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.4715 - accuracy: 0.8330 - val_loss: 0.5823 - val_accuracy: 0.7934\n",
      "Epoch 44/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4667 - accuracy: 0.8346\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0005625000048894435.\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.58225\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4668 - accuracy: 0.8346 - val_loss: 0.5839 - val_accuracy: 0.7915\n",
      "Epoch 45/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4616 - accuracy: 0.8369\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0004218749818392098.\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.58225\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4622 - accuracy: 0.8367 - val_loss: 0.5858 - val_accuracy: 0.7943\n",
      "Epoch 46/250\n",
      "98304/98782 [============================>.] - ETA: 0s - loss: 0.4592 - accuracy: 0.8378\n",
      "Epoch 00046: val_loss improved from 0.58225 to 0.58181, saving model to ./storage/writer_train_10/kfold9/epoch_046_val_0.582.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.4591 - accuracy: 0.8379 - val_loss: 0.5818 - val_accuracy: 0.7934\n",
      "Epoch 47/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.4560 - accuracy: 0.8389\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.00031640623637940735.\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.58181\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4566 - accuracy: 0.8387 - val_loss: 0.5833 - val_accuracy: 0.7926\n",
      "Epoch 48/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4544 - accuracy: 0.8397\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.00023730468819849193.\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.58181\n",
      "98782/98782 [==============================] - 4s 39us/sample - loss: 0.4542 - accuracy: 0.8397 - val_loss: 0.5821 - val_accuracy: 0.7935\n",
      "Epoch 49/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.4523 - accuracy: 0.8401\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.00017797851614886895.\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.58181\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4524 - accuracy: 0.8402 - val_loss: 0.5822 - val_accuracy: 0.7943\n",
      "Epoch 50/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4510 - accuracy: 0.8405\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0001334838816546835.\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.58181 to 0.58173, saving model to ./storage/writer_train_10/kfold9/epoch_050_val_0.582.h5\n",
      "98782/98782 [==============================] - 4s 43us/sample - loss: 0.4510 - accuracy: 0.8405 - val_loss: 0.5817 - val_accuracy: 0.7941\n",
      "Epoch 51/250\n",
      "97792/98782 [============================>.] - ETA: 0s - loss: 0.4496 - accuracy: 0.8411\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.00010011290578404441.\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.58173\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4499 - accuracy: 0.8410 - val_loss: 0.5817 - val_accuracy: 0.7941\n",
      "Epoch 52/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.4495 - accuracy: 0.8412\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 7.508467933803331e-05.\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.58173\n",
      "98782/98782 [==============================] - 4s 37us/sample - loss: 0.4492 - accuracy: 0.8414 - val_loss: 0.5826 - val_accuracy: 0.7935\n",
      "Epoch 53/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.4486 - accuracy: 0.8419\n",
      "Epoch 00053: val_loss improved from 0.58173 to 0.58150, saving model to ./storage/writer_train_10/kfold9/epoch_053_val_0.581.h5\n",
      "98782/98782 [==============================] - 4s 42us/sample - loss: 0.4486 - accuracy: 0.8417 - val_loss: 0.5815 - val_accuracy: 0.7939\n",
      "Epoch 54/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4482 - accuracy: 0.8416\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 5.6313510867767036e-05.\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.58150\n",
      "98782/98782 [==============================] - 4s 39us/sample - loss: 0.4482 - accuracy: 0.8417 - val_loss: 0.5820 - val_accuracy: 0.7937\n",
      "Epoch 55/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.4475 - accuracy: 0.8420\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 4.223513315082528e-05.\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.58150\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4478 - accuracy: 0.8417 - val_loss: 0.5818 - val_accuracy: 0.7935\n",
      "Epoch 56/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.4477 - accuracy: 0.8419\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 3.167634986311896e-05.\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.58150\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4475 - accuracy: 0.8419 - val_loss: 0.5819 - val_accuracy: 0.7932\n",
      "Epoch 57/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.4471 - accuracy: 0.8418\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 2.3757263079460245e-05.\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.58150\n",
      "98782/98782 [==============================] - 4s 39us/sample - loss: 0.4472 - accuracy: 0.8418 - val_loss: 0.5820 - val_accuracy: 0.7932\n",
      "Epoch 58/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4470 - accuracy: 0.8421\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1.781794799171621e-05.\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.58150\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4470 - accuracy: 0.8420 - val_loss: 0.5819 - val_accuracy: 0.7930\n",
      "Epoch 59/250\n",
      "97280/98782 [============================>.] - ETA: 0s - loss: 0.4467 - accuracy: 0.8420\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 1.3363460311666131e-05.\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.58150\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4469 - accuracy: 0.8421 - val_loss: 0.5819 - val_accuracy: 0.7932\n",
      "Epoch 60/250\n",
      "98560/98782 [============================>.] - ETA: 0s - loss: 0.4468 - accuracy: 0.8423\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 1.0022595233749598e-05.\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.58150\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4468 - accuracy: 0.8423 - val_loss: 0.5820 - val_accuracy: 0.7926\n",
      "Epoch 61/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.4467 - accuracy: 0.8423\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 7.516946425312199e-06.\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.58150\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4467 - accuracy: 0.8422 - val_loss: 0.5820 - val_accuracy: 0.7937\n",
      "Epoch 62/250\n",
      "98048/98782 [============================>.] - ETA: 0s - loss: 0.4468 - accuracy: 0.8422\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 5.637709818984149e-06.\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.58150\n",
      "98782/98782 [==============================] - 4s 40us/sample - loss: 0.4466 - accuracy: 0.8422 - val_loss: 0.5819 - val_accuracy: 0.7932\n",
      "Epoch 63/250\n",
      "97536/98782 [============================>.] - ETA: 0s - loss: 0.4469 - accuracy: 0.8421\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 4.228282364238112e-06.\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.58150\n",
      "98782/98782 [==============================] - 4s 38us/sample - loss: 0.4466 - accuracy: 0.8423 - val_loss: 0.5819 - val_accuracy: 0.7932\n",
      "... Iteration 10 ...\n",
      "... Preprocessing Data ... \n",
      "(98784, 256) (98784,)\n",
      "(5487, 256) (5487,)\n",
      "... Training Model by Validating on Fold 10 ...\n",
      "Train on 98784 samples, validate on 5487 samples\n",
      "Epoch 1/250\n",
      "98560/98784 [============================>.] - ETA: 0s - loss: 1.5617 - accuracy: 0.2717\n",
      "Epoch 00001: val_loss improved from inf to 1.54163, saving model to ./storage/writer_train_10/kfold10/epoch_001_val_1.542.h5\n",
      "98784/98784 [==============================] - 5s 48us/sample - loss: 1.5617 - accuracy: 0.2717 - val_loss: 1.5416 - val_accuracy: 0.2803\n",
      "Epoch 2/250\n",
      "98048/98784 [============================>.] - ETA: 0s - loss: 1.5184 - accuracy: 0.3056\n",
      "Epoch 00002: val_loss improved from 1.54163 to 1.48335, saving model to ./storage/writer_train_10/kfold10/epoch_002_val_1.483.h5\n",
      "98784/98784 [==============================] - 4s 42us/sample - loss: 1.5183 - accuracy: 0.3057 - val_loss: 1.4834 - val_accuracy: 0.3284\n",
      "Epoch 3/250\n",
      "98304/98784 [============================>.] - ETA: 0s - loss: 1.4479 - accuracy: 0.4092\n",
      "Epoch 00003: val_loss improved from 1.48335 to 1.39317, saving model to ./storage/writer_train_10/kfold10/epoch_003_val_1.393.h5\n",
      "98784/98784 [==============================] - 4s 44us/sample - loss: 1.4478 - accuracy: 0.4093 - val_loss: 1.3932 - val_accuracy: 0.5180\n",
      "Epoch 4/250\n",
      "97792/98784 [============================>.] - ETA: 0s - loss: 1.3599 - accuracy: 0.5013\n",
      "Epoch 00004: val_loss improved from 1.39317 to 1.29478, saving model to ./storage/writer_train_10/kfold10/epoch_004_val_1.295.h5\n",
      "98784/98784 [==============================] - 4s 42us/sample - loss: 1.3596 - accuracy: 0.5014 - val_loss: 1.2948 - val_accuracy: 0.5628\n",
      "Epoch 5/250\n",
      "98048/98784 [============================>.] - ETA: 0s - loss: 1.2715 - accuracy: 0.5542\n",
      "Epoch 00005: val_loss improved from 1.29478 to 1.20223, saving model to ./storage/writer_train_10/kfold10/epoch_005_val_1.202.h5\n",
      "98784/98784 [==============================] - 4s 42us/sample - loss: 1.2712 - accuracy: 0.5544 - val_loss: 1.2022 - val_accuracy: 0.6031\n",
      "Epoch 6/250\n",
      "98048/98784 [============================>.] - ETA: 0s - loss: 1.1910 - accuracy: 0.5859\n",
      "Epoch 00006: val_loss improved from 1.20223 to 1.12207, saving model to ./storage/writer_train_10/kfold10/epoch_006_val_1.122.h5\n",
      "98784/98784 [==============================] - 4s 42us/sample - loss: 1.1907 - accuracy: 0.5859 - val_loss: 1.1221 - val_accuracy: 0.6242\n",
      "Epoch 7/250\n",
      "97792/98784 [============================>.] - ETA: 0s - loss: 1.1205 - accuracy: 0.6111\n",
      "Epoch 00007: val_loss improved from 1.12207 to 1.05579, saving model to ./storage/writer_train_10/kfold10/epoch_007_val_1.056.h5\n",
      "98784/98784 [==============================] - 4s 42us/sample - loss: 1.1205 - accuracy: 0.6112 - val_loss: 1.0558 - val_accuracy: 0.6495\n",
      "Epoch 8/250\n",
      "98304/98784 [============================>.] - ETA: 0s - loss: 1.0599 - accuracy: 0.6321\n",
      "Epoch 00008: val_loss improved from 1.05579 to 0.99738, saving model to ./storage/writer_train_10/kfold10/epoch_008_val_0.997.h5\n",
      "98784/98784 [==============================] - 4s 44us/sample - loss: 1.0598 - accuracy: 0.6321 - val_loss: 0.9974 - val_accuracy: 0.6614\n",
      "Epoch 9/250\n",
      "98048/98784 [============================>.] - ETA: 0s - loss: 1.0075 - accuracy: 0.6502\n",
      "Epoch 00009: val_loss improved from 0.99738 to 0.94800, saving model to ./storage/writer_train_10/kfold10/epoch_009_val_0.948.h5\n",
      "98784/98784 [==============================] - 4s 43us/sample - loss: 1.0073 - accuracy: 0.6504 - val_loss: 0.9480 - val_accuracy: 0.6751\n",
      "Epoch 10/250\n",
      "97536/98784 [============================>.] - ETA: 0s - loss: 0.9621 - accuracy: 0.6661\n",
      "Epoch 00010: val_loss improved from 0.94800 to 0.90836, saving model to ./storage/writer_train_10/kfold10/epoch_010_val_0.908.h5\n",
      "98784/98784 [==============================] - 4s 41us/sample - loss: 0.9614 - accuracy: 0.6666 - val_loss: 0.9084 - val_accuracy: 0.6882\n",
      "Epoch 11/250\n",
      "98304/98784 [============================>.] - ETA: 0s - loss: 0.9205 - accuracy: 0.6817\n",
      "Epoch 00011: val_loss improved from 0.90836 to 0.87291, saving model to ./storage/writer_train_10/kfold10/epoch_011_val_0.873.h5\n",
      "98784/98784 [==============================] - 4s 42us/sample - loss: 0.9207 - accuracy: 0.6815 - val_loss: 0.8729 - val_accuracy: 0.7015\n",
      "Epoch 12/250\n",
      "97792/98784 [============================>.] - ETA: 0s - loss: 0.8854 - accuracy: 0.6947\n",
      "Epoch 00012: val_loss improved from 0.87291 to 0.84126, saving model to ./storage/writer_train_10/kfold10/epoch_012_val_0.841.h5\n",
      "98784/98784 [==============================] - 4s 42us/sample - loss: 0.8850 - accuracy: 0.6947 - val_loss: 0.8413 - val_accuracy: 0.7106\n",
      "Epoch 13/250\n",
      "98048/98784 [============================>.] - ETA: 0s - loss: 0.8526 - accuracy: 0.7063\n",
      "Epoch 00013: val_loss improved from 0.84126 to 0.81256, saving model to ./storage/writer_train_10/kfold10/epoch_013_val_0.813.h5\n",
      "98784/98784 [==============================] - 4s 42us/sample - loss: 0.8525 - accuracy: 0.7063 - val_loss: 0.8126 - val_accuracy: 0.7241\n",
      "Epoch 14/250\n",
      "98048/98784 [============================>.] - ETA: 0s - loss: 0.8232 - accuracy: 0.7161\n",
      "Epoch 00014: val_loss improved from 0.81256 to 0.78992, saving model to ./storage/writer_train_10/kfold10/epoch_014_val_0.790.h5\n",
      "98784/98784 [==============================] - 4s 42us/sample - loss: 0.8233 - accuracy: 0.7160 - val_loss: 0.7899 - val_accuracy: 0.7315\n",
      "Epoch 15/250\n",
      "98048/98784 [============================>.] - ETA: 0s - loss: 0.7967 - accuracy: 0.7259\n",
      "Epoch 00015: val_loss improved from 0.78992 to 0.76809, saving model to ./storage/writer_train_10/kfold10/epoch_015_val_0.768.h5\n",
      "98784/98784 [==============================] - 4s 42us/sample - loss: 0.7967 - accuracy: 0.7257 - val_loss: 0.7681 - val_accuracy: 0.7379\n",
      "Epoch 16/250\n",
      "98048/98784 [============================>.] - ETA: 0s - loss: 0.7723 - accuracy: 0.7338\n",
      "Epoch 00016: val_loss improved from 0.76809 to 0.75100, saving model to ./storage/writer_train_10/kfold10/epoch_016_val_0.751.h5\n",
      "98784/98784 [==============================] - 4s 43us/sample - loss: 0.7722 - accuracy: 0.7338 - val_loss: 0.7510 - val_accuracy: 0.7410\n",
      "Epoch 17/250\n",
      "98048/98784 [============================>.] - ETA: 0s - loss: 0.7502 - accuracy: 0.7412\n",
      "Epoch 00017: val_loss improved from 0.75100 to 0.73198, saving model to ./storage/writer_train_10/kfold10/epoch_017_val_0.732.h5\n",
      "98784/98784 [==============================] - 4s 41us/sample - loss: 0.7498 - accuracy: 0.7413 - val_loss: 0.7320 - val_accuracy: 0.7445\n",
      "Epoch 18/250\n",
      "98048/98784 [============================>.] - ETA: 0s - loss: 0.7295 - accuracy: 0.7471\n",
      "Epoch 00018: val_loss improved from 0.73198 to 0.71472, saving model to ./storage/writer_train_10/kfold10/epoch_018_val_0.715.h5\n",
      "98784/98784 [==============================] - 4s 42us/sample - loss: 0.7291 - accuracy: 0.7473 - val_loss: 0.7147 - val_accuracy: 0.7492\n",
      "Epoch 19/250\n",
      "97280/98784 [============================>.] - ETA: 0s - loss: 0.7098 - accuracy: 0.7534\n",
      "Epoch 00019: val_loss improved from 0.71472 to 0.70388, saving model to ./storage/writer_train_10/kfold10/epoch_019_val_0.704.h5\n",
      "98784/98784 [==============================] - 4s 43us/sample - loss: 0.7097 - accuracy: 0.7535 - val_loss: 0.7039 - val_accuracy: 0.7538\n",
      "Epoch 20/250\n",
      "97536/98784 [============================>.] - ETA: 0s - loss: 0.6921 - accuracy: 0.7595\n",
      "Epoch 00020: val_loss improved from 0.70388 to 0.68904, saving model to ./storage/writer_train_10/kfold10/epoch_020_val_0.689.h5\n",
      "98784/98784 [==============================] - 4s 44us/sample - loss: 0.6920 - accuracy: 0.7594 - val_loss: 0.6890 - val_accuracy: 0.7620\n",
      "Epoch 21/250\n",
      "98560/98784 [============================>.] - ETA: 0s - loss: 0.6751 - accuracy: 0.7653\n",
      "Epoch 00021: val_loss improved from 0.68904 to 0.68052, saving model to ./storage/writer_train_10/kfold10/epoch_021_val_0.681.h5\n",
      "98784/98784 [==============================] - 4s 42us/sample - loss: 0.6750 - accuracy: 0.7653 - val_loss: 0.6805 - val_accuracy: 0.7640\n",
      "Epoch 22/250\n",
      "98304/98784 [============================>.] - ETA: 0s - loss: 0.6597 - accuracy: 0.7711\n",
      "Epoch 00022: val_loss improved from 0.68052 to 0.67145, saving model to ./storage/writer_train_10/kfold10/epoch_022_val_0.671.h5\n",
      "98784/98784 [==============================] - 4s 42us/sample - loss: 0.6597 - accuracy: 0.7712 - val_loss: 0.6714 - val_accuracy: 0.7627\n",
      "Epoch 23/250\n",
      "97280/98784 [============================>.] - ETA: 0s - loss: 0.6452 - accuracy: 0.7753\n",
      "Epoch 00023: val_loss improved from 0.67145 to 0.65816, saving model to ./storage/writer_train_10/kfold10/epoch_023_val_0.658.h5\n",
      "98784/98784 [==============================] - 4s 42us/sample - loss: 0.6450 - accuracy: 0.7752 - val_loss: 0.6582 - val_accuracy: 0.7685\n",
      "Epoch 24/250\n",
      "98560/98784 [============================>.] - ETA: 0s - loss: 0.6312 - accuracy: 0.7796\n",
      "Epoch 00024: val_loss improved from 0.65816 to 0.65192, saving model to ./storage/writer_train_10/kfold10/epoch_024_val_0.652.h5\n",
      "98784/98784 [==============================] - 4s 43us/sample - loss: 0.6312 - accuracy: 0.7796 - val_loss: 0.6519 - val_accuracy: 0.7696\n",
      "Epoch 25/250\n",
      "98304/98784 [============================>.] - ETA: 0s - loss: 0.6184 - accuracy: 0.7836\n",
      "Epoch 00025: val_loss improved from 0.65192 to 0.64287, saving model to ./storage/writer_train_10/kfold10/epoch_025_val_0.643.h5\n",
      "98784/98784 [==============================] - 4s 43us/sample - loss: 0.6183 - accuracy: 0.7836 - val_loss: 0.6429 - val_accuracy: 0.7716\n",
      "Epoch 26/250\n",
      "98048/98784 [============================>.] - ETA: 0s - loss: 0.6057 - accuracy: 0.7878\n",
      "Epoch 00026: val_loss improved from 0.64287 to 0.63543, saving model to ./storage/writer_train_10/kfold10/epoch_026_val_0.635.h5\n",
      "98784/98784 [==============================] - 4s 43us/sample - loss: 0.6060 - accuracy: 0.7876 - val_loss: 0.6354 - val_accuracy: 0.7758\n",
      "Epoch 27/250\n",
      "97792/98784 [============================>.] - ETA: 0s - loss: 0.5945 - accuracy: 0.7916\n",
      "Epoch 00027: val_loss improved from 0.63543 to 0.62979, saving model to ./storage/writer_train_10/kfold10/epoch_027_val_0.630.h5\n",
      "98784/98784 [==============================] - 4s 41us/sample - loss: 0.5944 - accuracy: 0.7916 - val_loss: 0.6298 - val_accuracy: 0.7753\n",
      "Epoch 28/250\n",
      "97280/98784 [============================>.] - ETA: 0s - loss: 0.5837 - accuracy: 0.7954\n",
      "Epoch 00028: val_loss improved from 0.62979 to 0.62342, saving model to ./storage/writer_train_10/kfold10/epoch_028_val_0.623.h5\n",
      "98784/98784 [==============================] - 4s 45us/sample - loss: 0.5836 - accuracy: 0.7953 - val_loss: 0.6234 - val_accuracy: 0.7791\n",
      "Epoch 29/250\n",
      "97536/98784 [============================>.] - ETA: 0s - loss: 0.5733 - accuracy: 0.7989\n",
      "Epoch 00029: val_loss improved from 0.62342 to 0.61729, saving model to ./storage/writer_train_10/kfold10/epoch_029_val_0.617.h5\n",
      "98784/98784 [==============================] - 4s 44us/sample - loss: 0.5732 - accuracy: 0.7988 - val_loss: 0.6173 - val_accuracy: 0.7817\n",
      "Epoch 30/250\n",
      "97792/98784 [============================>.] - ETA: 0s - loss: 0.5633 - accuracy: 0.8021\n",
      "Epoch 00030: val_loss improved from 0.61729 to 0.61350, saving model to ./storage/writer_train_10/kfold10/epoch_030_val_0.613.h5\n",
      "98784/98784 [==============================] - 4s 43us/sample - loss: 0.5633 - accuracy: 0.8021 - val_loss: 0.6135 - val_accuracy: 0.7804\n",
      "Epoch 31/250\n",
      "98048/98784 [============================>.] - ETA: 0s - loss: 0.5538 - accuracy: 0.8052\n",
      "Epoch 00031: val_loss improved from 0.61350 to 0.60971, saving model to ./storage/writer_train_10/kfold10/epoch_031_val_0.610.h5\n",
      "98784/98784 [==============================] - 4s 42us/sample - loss: 0.5539 - accuracy: 0.8050 - val_loss: 0.6097 - val_accuracy: 0.7806\n",
      "Epoch 32/250\n",
      "97280/98784 [============================>.] - ETA: 0s - loss: 0.5445 - accuracy: 0.8085\n",
      "Epoch 00032: val_loss improved from 0.60971 to 0.60812, saving model to ./storage/writer_train_10/kfold10/epoch_032_val_0.608.h5\n",
      "98784/98784 [==============================] - 4s 43us/sample - loss: 0.5448 - accuracy: 0.8083 - val_loss: 0.6081 - val_accuracy: 0.7795\n",
      "Epoch 33/250\n",
      "97536/98784 [============================>.] - ETA: 0s - loss: 0.5364 - accuracy: 0.8110\n",
      "Epoch 00033: val_loss improved from 0.60812 to 0.60334, saving model to ./storage/writer_train_10/kfold10/epoch_033_val_0.603.h5\n",
      "98784/98784 [==============================] - 4s 45us/sample - loss: 0.5366 - accuracy: 0.8109 - val_loss: 0.6033 - val_accuracy: 0.7833\n",
      "Epoch 34/250\n",
      "97536/98784 [============================>.] - ETA: 0s - loss: 0.5278 - accuracy: 0.8138\n",
      "Epoch 00034: val_loss improved from 0.60334 to 0.60114, saving model to ./storage/writer_train_10/kfold10/epoch_034_val_0.601.h5\n",
      "98784/98784 [==============================] - 4s 42us/sample - loss: 0.5281 - accuracy: 0.8137 - val_loss: 0.6011 - val_accuracy: 0.7828\n",
      "Epoch 35/250\n",
      "98560/98784 [============================>.] - ETA: 0s - loss: 0.5205 - accuracy: 0.8168\n",
      "Epoch 00035: val_loss improved from 0.60114 to 0.59734, saving model to ./storage/writer_train_10/kfold10/epoch_035_val_0.597.h5\n",
      "98784/98784 [==============================] - 4s 44us/sample - loss: 0.5206 - accuracy: 0.8168 - val_loss: 0.5973 - val_accuracy: 0.7829\n",
      "Epoch 36/250\n",
      "97792/98784 [============================>.] - ETA: 0s - loss: 0.5129 - accuracy: 0.8190\n",
      "Epoch 00036: val_loss improved from 0.59734 to 0.59612, saving model to ./storage/writer_train_10/kfold10/epoch_036_val_0.596.h5\n",
      "98784/98784 [==============================] - 4s 42us/sample - loss: 0.5131 - accuracy: 0.8190 - val_loss: 0.5961 - val_accuracy: 0.7840\n",
      "Epoch 37/250\n",
      "97792/98784 [============================>.] - ETA: 0s - loss: 0.5060 - accuracy: 0.8211\n",
      "Epoch 00037: val_loss improved from 0.59612 to 0.59553, saving model to ./storage/writer_train_10/kfold10/epoch_037_val_0.596.h5\n",
      "98784/98784 [==============================] - 4s 42us/sample - loss: 0.5059 - accuracy: 0.8211 - val_loss: 0.5955 - val_accuracy: 0.7839\n",
      "Epoch 38/250\n",
      "97792/98784 [============================>.] - ETA: 0s - loss: 0.4988 - accuracy: 0.8239\n",
      "Epoch 00038: val_loss improved from 0.59553 to 0.59365, saving model to ./storage/writer_train_10/kfold10/epoch_038_val_0.594.h5\n",
      "98784/98784 [==============================] - 4s 43us/sample - loss: 0.4988 - accuracy: 0.8237 - val_loss: 0.5937 - val_accuracy: 0.7862\n",
      "Epoch 39/250\n",
      "98304/98784 [============================>.] - ETA: 0s - loss: 0.4921 - accuracy: 0.8263\n",
      "Epoch 00039: val_loss improved from 0.59365 to 0.59240, saving model to ./storage/writer_train_10/kfold10/epoch_039_val_0.592.h5\n",
      "98784/98784 [==============================] - 4s 42us/sample - loss: 0.4922 - accuracy: 0.8263 - val_loss: 0.5924 - val_accuracy: 0.7826\n",
      "Epoch 40/250\n",
      "98304/98784 [============================>.] - ETA: 0s - loss: 0.4863 - accuracy: 0.8280\n",
      "Epoch 00040: val_loss improved from 0.59240 to 0.58847, saving model to ./storage/writer_train_10/kfold10/epoch_040_val_0.588.h5\n",
      "98784/98784 [==============================] - 4s 44us/sample - loss: 0.4862 - accuracy: 0.8281 - val_loss: 0.5885 - val_accuracy: 0.7857\n",
      "Epoch 41/250\n",
      "97792/98784 [============================>.] - ETA: 0s - loss: 0.4798 - accuracy: 0.8307\n",
      "Epoch 00041: val_loss improved from 0.58847 to 0.58729, saving model to ./storage/writer_train_10/kfold10/epoch_041_val_0.587.h5\n",
      "98784/98784 [==============================] - 4s 42us/sample - loss: 0.4798 - accuracy: 0.8307 - val_loss: 0.5873 - val_accuracy: 0.7844\n",
      "Epoch 42/250\n",
      "97536/98784 [============================>.] - ETA: 0s - loss: 0.4745 - accuracy: 0.8325\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0007500000356230885.\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.58729\n",
      "98784/98784 [==============================] - 4s 39us/sample - loss: 0.4742 - accuracy: 0.8325 - val_loss: 0.5881 - val_accuracy: 0.7866\n",
      "Epoch 43/250\n",
      "98048/98784 [============================>.] - ETA: 0s - loss: 0.4682 - accuracy: 0.8344\n",
      "Epoch 00043: val_loss improved from 0.58729 to 0.58573, saving model to ./storage/writer_train_10/kfold10/epoch_043_val_0.586.h5\n",
      "98784/98784 [==============================] - 4s 42us/sample - loss: 0.4681 - accuracy: 0.8345 - val_loss: 0.5857 - val_accuracy: 0.7862\n",
      "Epoch 44/250\n",
      "98048/98784 [============================>.] - ETA: 0s - loss: 0.4642 - accuracy: 0.8354\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0005625000048894435.\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.58573\n",
      "98784/98784 [==============================] - 4s 38us/sample - loss: 0.4642 - accuracy: 0.8355 - val_loss: 0.5884 - val_accuracy: 0.7871\n",
      "Epoch 45/250\n",
      "97536/98784 [============================>.] - ETA: 0s - loss: 0.4597 - accuracy: 0.8373\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0004218749818392098.\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.58573\n",
      "98784/98784 [==============================] - 4s 39us/sample - loss: 0.4599 - accuracy: 0.8374 - val_loss: 0.5872 - val_accuracy: 0.7871\n",
      "Epoch 46/250\n",
      "98560/98784 [============================>.] - ETA: 0s - loss: 0.4568 - accuracy: 0.8388\n",
      "Epoch 00046: val_loss improved from 0.58573 to 0.58551, saving model to ./storage/writer_train_10/kfold10/epoch_046_val_0.586.h5\n",
      "98784/98784 [==============================] - 4s 41us/sample - loss: 0.4568 - accuracy: 0.8388 - val_loss: 0.5855 - val_accuracy: 0.7868\n",
      "Epoch 47/250\n",
      "98560/98784 [============================>.] - ETA: 0s - loss: 0.4546 - accuracy: 0.8395\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.00031640623637940735.\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.58551\n",
      "98784/98784 [==============================] - 4s 38us/sample - loss: 0.4545 - accuracy: 0.8396 - val_loss: 0.5867 - val_accuracy: 0.7875\n",
      "Epoch 48/250\n",
      "98560/98784 [============================>.] - ETA: 0s - loss: 0.4526 - accuracy: 0.8402\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.00023730468819849193.\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.58551\n",
      "98784/98784 [==============================] - 4s 38us/sample - loss: 0.4523 - accuracy: 0.8403 - val_loss: 0.5880 - val_accuracy: 0.7853\n",
      "Epoch 49/250\n",
      "97536/98784 [============================>.] - ETA: 0s - loss: 0.4503 - accuracy: 0.8412\n",
      "Epoch 00049: val_loss improved from 0.58551 to 0.58493, saving model to ./storage/writer_train_10/kfold10/epoch_049_val_0.585.h5\n",
      "98784/98784 [==============================] - 4s 42us/sample - loss: 0.4506 - accuracy: 0.8410 - val_loss: 0.5849 - val_accuracy: 0.7862\n",
      "Epoch 50/250\n",
      "97792/98784 [============================>.] - ETA: 0s - loss: 0.4493 - accuracy: 0.8409\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.00017797851614886895.\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.58493\n",
      "98784/98784 [==============================] - 4s 39us/sample - loss: 0.4493 - accuracy: 0.8410 - val_loss: 0.5855 - val_accuracy: 0.7877\n",
      "Epoch 51/250\n",
      "98048/98784 [============================>.] - ETA: 0s - loss: 0.4480 - accuracy: 0.8419\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0001334838816546835.\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.58493\n",
      "98784/98784 [==============================] - 4s 38us/sample - loss: 0.4480 - accuracy: 0.8419 - val_loss: 0.5867 - val_accuracy: 0.7857\n",
      "Epoch 52/250\n",
      "97280/98784 [============================>.] - ETA: 0s - loss: 0.4473 - accuracy: 0.8425\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.00010011290578404441.\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.58493\n",
      "98784/98784 [==============================] - 4s 38us/sample - loss: 0.4471 - accuracy: 0.8425 - val_loss: 0.5852 - val_accuracy: 0.7859\n",
      "Epoch 53/250\n",
      "98048/98784 [============================>.] - ETA: 0s - loss: 0.4461 - accuracy: 0.8427\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 7.508467933803331e-05.\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.58493\n",
      "98784/98784 [==============================] - 4s 38us/sample - loss: 0.4463 - accuracy: 0.8427 - val_loss: 0.5856 - val_accuracy: 0.7875\n",
      "Epoch 54/250\n",
      "97792/98784 [============================>.] - ETA: 0s - loss: 0.4459 - accuracy: 0.8429\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 5.6313510867767036e-05.\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.58493\n",
      "98784/98784 [==============================] - 4s 39us/sample - loss: 0.4458 - accuracy: 0.8428 - val_loss: 0.5855 - val_accuracy: 0.7879\n",
      "Epoch 55/250\n",
      "98048/98784 [============================>.] - ETA: 0s - loss: 0.4454 - accuracy: 0.8426\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 4.223513315082528e-05.\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.58493\n",
      "98784/98784 [==============================] - 4s 38us/sample - loss: 0.4454 - accuracy: 0.8426 - val_loss: 0.5853 - val_accuracy: 0.7871\n",
      "Epoch 56/250\n",
      "98560/98784 [============================>.] - ETA: 0s - loss: 0.4453 - accuracy: 0.8431\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 3.167634986311896e-05.\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.58493\n",
      "98784/98784 [==============================] - 4s 38us/sample - loss: 0.4451 - accuracy: 0.8431 - val_loss: 0.5851 - val_accuracy: 0.7870\n",
      "Epoch 57/250\n",
      "98304/98784 [============================>.] - ETA: 0s - loss: 0.4448 - accuracy: 0.8433\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 2.3757263079460245e-05.\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.58493\n",
      "98784/98784 [==============================] - 4s 38us/sample - loss: 0.4449 - accuracy: 0.8433 - val_loss: 0.5855 - val_accuracy: 0.7871\n",
      "Epoch 58/250\n",
      "97536/98784 [============================>.] - ETA: 0s - loss: 0.4444 - accuracy: 0.8435\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1.781794799171621e-05.\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.58493\n",
      "98784/98784 [==============================] - 4s 43us/sample - loss: 0.4447 - accuracy: 0.8434 - val_loss: 0.5854 - val_accuracy: 0.7873\n",
      "Epoch 59/250\n",
      "98560/98784 [============================>.] - ETA: 0s - loss: 0.4446 - accuracy: 0.8435\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 1.3363460311666131e-05.\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.58493\n",
      "98784/98784 [==============================] - 4s 38us/sample - loss: 0.4446 - accuracy: 0.8435 - val_loss: 0.5853 - val_accuracy: 0.7868\n"
     ]
    }
   ],
   "source": [
    "# conduct KFold Ensemble  \n",
    "kfold = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 777) \n",
    "for idx, (train_idx,val_idx) in enumerate(kfold.split(x_train, y_train)):\n",
    "    print(\"... Iteration {} ...\".format(idx+1))   \n",
    "    \n",
    "    print(\"... Preprocessing Data ... \")\n",
    "    \n",
    "    cur_x_train, cur_x_val = x_train[train_idx], x_train[val_idx] \n",
    "    cur_y_train, cur_y_val = y_train[train_idx], y_train[val_idx]\n",
    "    \n",
    "    cur_x_train = np.concatenate([cur_x_train, back_translated[train_idx]]) \n",
    "    cur_y_train = np.concatenate([cur_y_train, cur_y_train])     \n",
    "    \n",
    "    # create tokenizer instance \n",
    "    vocab_size = 25000\n",
    "    maxlength = 256 \n",
    "    embedding_dim = 20 \n",
    "\n",
    "    tokenizer = Tokenizer(num_words = vocab_size, lower = True)\n",
    "    tokenizer.fit_on_texts(cur_x_train) # fit on entire train data \n",
    "    \n",
    "    train_sequences = tokenizer.texts_to_sequences(cur_x_train)\n",
    "    train_padded = pad_sequences(train_sequences, padding='post', maxlen=maxlength)   \n",
    "    \n",
    "    val_sequences = tokenizer.texts_to_sequences(cur_x_val)\n",
    "    val_padded = pad_sequences(val_sequences, padding='post', maxlen=maxlength)\n",
    "    \n",
    "    # create padded sequence for test data  \n",
    "    test_sequences = tokenizer.texts_to_sequences(x_test)\n",
    "    test_padded = pad_sequences(test_sequences, padding='post', maxlen=maxlength)\n",
    "    np.save('./storage/test_padded_fold' + str(idx+1) + '.npy', test_padded)\n",
    "    \n",
    "    print(train_padded.shape, cur_y_train.shape) \n",
    "    print(val_padded.shape, cur_y_val.shape)\n",
    "\n",
    "    \n",
    "    print(\"... Training Model by Validating on Fold {} ...\".format(idx+1))\n",
    "\n",
    "    # build model, define callbacks and train  \n",
    "    model_path = './storage/writer_train_10/kfold' + str(idx+1) + '/epoch_{epoch:03d}_val_{val_loss:.3f}.h5'\n",
    "    model = build_model() \n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_loss', patience = 1, verbose = 1, factor = 0.75)\n",
    "    checkpoint = ModelCheckpoint(filepath = model_path, monitor = 'val_loss', verbose = 1, save_best_only = True)\n",
    "    early_stopping = EarlyStopping(monitor = 'val_loss', patience = 10) \n",
    "    history = model.fit(train_padded,\n",
    "                        cur_y_train,\n",
    "                        validation_data = (val_padded,cur_y_val),\n",
    "                        shuffle = True,\n",
    "                        batch_size = 256, \n",
    "                        epochs = 250,\n",
    "                        verbose = 1,\n",
    "                        callbacks = [learning_rate_reduction, checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_model('./storage/writer_train_10/kfold1/epoch_053_val_0.577.h5') \n",
    "model2 = load_model('./storage/writer_train_10/kfold2/epoch_046_val_0.593.h5') \n",
    "model3 = load_model('./storage/writer_train_10/kfold3/epoch_046_val_0.594.h5')\n",
    "model4 = load_model('./storage/writer_train_10/kfold4/epoch_048_val_0.608.h5')\n",
    "model5 = load_model('./storage/writer_train_10/kfold5/epoch_057_val_0.574.h5')\n",
    "model6 = load_model('./storage/writer_train_10/kfold6/epoch_056_val_0.571.h5')\n",
    "model7 = load_model('./storage/writer_train_10/kfold7/epoch_051_val_0.620.h5') \n",
    "model8 = load_model('./storage/writer_train_10/kfold8/epoch_057_val_0.586.h5')\n",
    "model9 = load_model('./storage/writer_train_10/kfold9/epoch_053_val_0.581.h5') \n",
    "model10 = load_model('./storage/writer_train_10/kfold10/epoch_049_val_0.585.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_padded1 = np.load('./storage/test_padded_fold1.npy') \n",
    "test_padded2 = np.load('./storage/test_padded_fold2.npy')\n",
    "test_padded3 = np.load('./storage/test_padded_fold3.npy')\n",
    "test_padded4 = np.load('./storage/test_padded_fold4.npy')\n",
    "test_padded5 = np.load('./storage/test_padded_fold5.npy')\n",
    "test_padded6 = np.load('./storage/test_padded_fold6.npy')\n",
    "test_padded7 = np.load('./storage/test_padded_fold7.npy')\n",
    "test_padded8 = np.load('./storage/test_padded_fold8.npy')\n",
    "test_padded9 = np.load('./storage/test_padded_fold9.npy')\n",
    "test_padded10 = np.load('./storage/test_padded_fold10.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = model1.predict_proba(test_padded1)\n",
    "pred2 = model2.predict_proba(test_padded2)\n",
    "pred3 = model3.predict_proba(test_padded3)\n",
    "pred4 = model4.predict_proba(test_padded4)\n",
    "pred5 = model5.predict_proba(test_padded5) \n",
    "pred6 = model6.predict_proba(test_padded6) \n",
    "pred7 = model7.predict_proba(test_padded7) \n",
    "pred8 = model8.predict_proba(test_padded8) \n",
    "pred9 = model9.predict_proba(test_padded9) \n",
    "pred10 = model10.predict_proba(test_padded10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.025932e-04</td>\n",
       "      <td>9.215701e-01</td>\n",
       "      <td>0.071175</td>\n",
       "      <td>6.643879e-03</td>\n",
       "      <td>0.000108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.035134e-01</td>\n",
       "      <td>2.883886e-01</td>\n",
       "      <td>0.124170</td>\n",
       "      <td>3.474397e-02</td>\n",
       "      <td>0.449185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9.987903e-01</td>\n",
       "      <td>4.544915e-04</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>7.052136e-06</td>\n",
       "      <td>0.000498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.482904e-07</td>\n",
       "      <td>1.043416e-16</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>4.155700e-17</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9.481353e-01</td>\n",
       "      <td>2.229575e-02</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>2.760762e-02</td>\n",
       "      <td>0.000911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index             0             1         2             3         4\n",
       "0      0  5.025932e-04  9.215701e-01  0.071175  6.643879e-03  0.000108\n",
       "1      1  1.035134e-01  2.883886e-01  0.124170  3.474397e-02  0.449185\n",
       "2      2  9.987903e-01  4.544915e-04  0.000250  7.052136e-06  0.000498\n",
       "3      3  1.482904e-07  1.043416e-16  0.999989  4.155700e-17  0.000011\n",
       "4      4  9.481353e-01  2.229575e-02  0.001050  2.760762e-02  0.000911"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_avg = (pred1 + pred2 + pred3 + pred4 + pred5 + pred6 + pred7 + pred8 + pred9 + pred10)/10.0 \n",
    "ss[['0','1','2','3','4']] = pred_avg\n",
    "ss.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.to_csv('./storage/MarianNMT_augmented.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
